{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdea0012-7b13-44ca-bf01-dac6cc92eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "import requests\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import csv \n",
    "import psycopg2\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1912ec53-d232-41f0-9926-c414e7d485bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Session and Retry object to manage the quota Craigslist imposes on HTTP get requests within a certain time period \n",
    "session = requests.Session()\n",
    "retry = Retry(connect=5, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba00c0-7b51-478a-8720-48940971bc4c",
   "metadata": {},
   "source": [
    "# Extracting Craigslist Data\n",
    "## Get all state/region names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9f8229-77d3-471d-9ea9-8dc4b134260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse URL that contains all regions of Craigslist\n",
    "all_sites_response = session.get('https://craigslist.org/about/sites')\n",
    "all_sites_soup = BeautifulSoup(all_sites_response.text, 'html.parser')\n",
    "\n",
    "# Extract part of webpage corresponding to regions in the US\n",
    "us_sites = all_sites_soup.body.section.div.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling\n",
    "\n",
    "# Extract HTML tags corresponding to the state name and region\n",
    "states_tags = us_sites.find_all('h4')\n",
    "regions_tags = us_sites.find_all('ul')\n",
    "\n",
    "states_and_regions = list(zip(states_tags, regions_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a8ddf0-62f7-44cc-9d00-494f9807a94d",
   "metadata": {},
   "source": [
    "## Get URL for each region of Craigslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df75c464-c95f-4562-bcaa-ee6db0a4aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the HTML tags, we get the text of which state the region belonged to and the text of the region's name.  We now have a dictionary with keys as states that map to a list of regions in that state\n",
    "state_dict = {}\n",
    "\n",
    "for ele in states_and_regions:\n",
    "    current_state = ele[0].text\n",
    "    href_list = ele[1].find_all('li')\n",
    "    temp_region_list = []\n",
    "    for href in href_list:\n",
    "        region = href.a['href'].replace('https://','').replace('.craigslist.org/','')\n",
    "        temp_region_list.append(region)\n",
    "        state_dict[current_state]=temp_region_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fff7c9-da51-45c8-a7d2-3b1030b313da",
   "metadata": {},
   "source": [
    "## Crawl each state/region of Craigslist\n",
    "Get the URL that corresponds to a search of the services section for \"math tutor.\"  Craigslist is limited to showing 120 results per page, so if a region has more than 120 postings, we extract URLs corresponding to the next page of results, until there is no next button anymore and we've extracted all URLs for that region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8dd7bb-6675-4a70-bef5-9803df93d6af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response #1 for Alabama: auburn received.\n",
      "Last response for auburn received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: bham received.\n",
      "Last response for bham received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: dothan received.\n",
      "Last response for dothan received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: shoals received.\n",
      "Last response for shoals received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: gadsden received.\n",
      "Last response for gadsden received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: huntsville received.\n",
      "Last response for huntsville received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: mobile received.\n",
      "Last response for mobile received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: montgomery received.\n",
      "Last response for montgomery received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: tuscaloosa received.\n",
      "Last response for tuscaloosa received.  Process completed.\n",
      "\n",
      "Response #1 for Alaska: anchorage received.\n",
      "Last response for anchorage received.  Process completed.\n",
      "\n",
      "Response #1 for Alaska: fairbanks received.\n",
      "Last response for fairbanks received.  Process completed.\n",
      "\n",
      "Response #1 for Alaska: kenai received.\n",
      "Last response for kenai received.  Process completed.\n",
      "\n",
      "Response #1 for Alaska: juneau received.\n",
      "Last response for juneau received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: flagstaff received.\n",
      "Last response for flagstaff received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: mohave received.\n",
      "Last response for mohave received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: phoenix received.\n",
      "Last response for phoenix received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: prescott received.\n",
      "Last response for prescott received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: showlow received.\n",
      "Last response for showlow received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: sierravista received.\n",
      "Last response for sierravista received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: tucson received.\n",
      "Last response for tucson received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: yuma received.\n",
      "Last response for yuma received.  Process completed.\n",
      "\n",
      "Response #1 for Arkansas: fayar received.\n",
      "Last response for fayar received.  Process completed.\n",
      "\n",
      "Response #1 for Arkansas: fortsmith received.\n",
      "Last response for fortsmith received.  Process completed.\n",
      "\n",
      "Response #1 for Arkansas: jonesboro received.\n",
      "Last response for jonesboro received.  Process completed.\n",
      "\n",
      "Response #1 for Arkansas: littlerock received.\n",
      "Last response for littlerock received.  Process completed.\n",
      "\n",
      "Response #1 for Arkansas: texarkana received.\n",
      "Last response for texarkana received.  Process completed.\n",
      "\n",
      "Response #1 for California: bakersfield received.\n",
      "Last response for bakersfield received.  Process completed.\n",
      "\n",
      "Response #1 for California: chico received.\n",
      "Last response for chico received.  Process completed.\n",
      "\n",
      "Response #1 for California: fresno received.\n",
      "Last response for fresno received.  Process completed.\n",
      "\n",
      "Response #1 for California: goldcountry received.\n",
      "Last response for goldcountry received.  Process completed.\n",
      "\n",
      "Response #1 for California: hanford received.\n",
      "Last response for hanford received.  Process completed.\n",
      "\n",
      "Response #1 for California: humboldt received.\n",
      "Last response for humboldt received.  Process completed.\n",
      "\n",
      "Response #1 for California: imperial received.\n",
      "Last response for imperial received.  Process completed.\n",
      "\n",
      "Response #1 for California: inlandempire received.\n",
      "Last response for inlandempire received.  Process completed.\n",
      "\n",
      "Response #1 for California: losangeles received.\n",
      "losangeles 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "losangeles 3 response received.\n",
      "Waiting 3 seconds...\n",
      "\n",
      "Last response for losangeles received.  Process completed.\n",
      "\n",
      "Response #1 for California: mendocino received.\n",
      "Last response for mendocino received.  Process completed.\n",
      "\n",
      "Response #1 for California: merced received.\n",
      "Last response for merced received.  Process completed.\n",
      "\n",
      "Response #1 for California: modesto received.\n",
      "Last response for modesto received.  Process completed.\n",
      "\n",
      "Response #1 for California: monterey received.\n",
      "Last response for monterey received.  Process completed.\n",
      "\n",
      "Response #1 for California: orangecounty received.\n",
      "orangecounty 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for orangecounty received.  Process completed.\n",
      "\n",
      "Response #1 for California: palmsprings received.\n",
      "Last response for palmsprings received.  Process completed.\n",
      "\n",
      "Response #1 for California: redding received.\n",
      "Last response for redding received.  Process completed.\n",
      "\n",
      "Response #1 for California: sacramento received.\n",
      "Last response for sacramento received.  Process completed.\n",
      "\n",
      "Response #1 for California: sandiego received.\n",
      "sandiego 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for sandiego received.  Process completed.\n",
      "\n",
      "Response #1 for California: sfbay received.\n",
      "sfbay 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "sfbay 3 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "sfbay 4 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for sfbay received.  Process completed.\n",
      "\n",
      "Response #1 for California: slo received.\n",
      "Last response for slo received.  Process completed.\n",
      "\n",
      "Response #1 for California: santabarbara received.\n",
      "Last response for santabarbara received.  Process completed.\n",
      "\n",
      "Response #1 for California: santamaria received.\n",
      "Last response for santamaria received.  Process completed.\n",
      "\n",
      "Response #1 for California: siskiyou received.\n",
      "Last response for siskiyou received.  Process completed.\n",
      "\n",
      "Response #1 for California: stockton received.\n",
      "Last response for stockton received.  Process completed.\n",
      "\n",
      "Response #1 for California: susanville received.\n",
      "Last response for susanville received.  Process completed.\n",
      "\n",
      "Response #1 for California: ventura received.\n",
      "Last response for ventura received.  Process completed.\n",
      "\n",
      "Response #1 for California: visalia received.\n",
      "Last response for visalia received.  Process completed.\n",
      "\n",
      "Response #1 for California: yubasutter received.\n",
      "Last response for yubasutter received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: boulder received.\n",
      "Last response for boulder received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: cosprings received.\n",
      "Last response for cosprings received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: denver received.\n",
      "Last response for denver received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: eastco received.\n",
      "Last response for eastco received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: fortcollins received.\n",
      "Last response for fortcollins received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: rockies received.\n",
      "Last response for rockies received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: pueblo received.\n",
      "Last response for pueblo received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: westslope received.\n",
      "Last response for westslope received.  Process completed.\n",
      "\n",
      "Response #1 for Connecticut: newlondon received.\n",
      "Last response for newlondon received.  Process completed.\n",
      "\n",
      "Response #1 for Connecticut: hartford received.\n",
      "Last response for hartford received.  Process completed.\n",
      "\n",
      "Response #1 for Connecticut: newhaven received.\n",
      "Last response for newhaven received.  Process completed.\n",
      "\n",
      "Response #1 for Connecticut: nwct received.\n",
      "Last response for nwct received.  Process completed.\n",
      "\n",
      "Response #1 for Delaware: delaware received.\n",
      "Last response for delaware received.  Process completed.\n",
      "\n",
      "Response #1 for District of Columbia: washingtondc received.\n",
      "washingtondc 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for washingtondc received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: miami received.\n",
      "miami 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for miami received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: daytona received.\n",
      "Last response for daytona received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: keys received.\n",
      "Last response for keys received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: miami received.\n",
      "miami 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for miami received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: fortmyers received.\n",
      "Last response for fortmyers received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: gainesville received.\n",
      "Last response for gainesville received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: cfl received.\n",
      "Last response for cfl received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: jacksonville received.\n",
      "Last response for jacksonville received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: lakeland received.\n",
      "Last response for lakeland received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: miami received.\n",
      "miami 2 response received.\n",
      "Waiting 3 seconds...\n",
      "\n",
      "Last response for miami received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: lakecity received.\n",
      "Last response for lakecity received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: ocala received.\n",
      "Last response for ocala received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: okaloosa received.\n",
      "Last response for okaloosa received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: orlando received.\n",
      "Last response for orlando received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: panamacity received.\n",
      "Last response for panamacity received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: pensacola received.\n",
      "Last response for pensacola received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: sarasota received.\n",
      "Last response for sarasota received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: miami received.\n",
      "miami 2 response received.\n",
      "Waiting 3 seconds...\n",
      "\n",
      "Last response for miami received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: spacecoast received.\n",
      "Last response for spacecoast received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: staugustine received.\n",
      "Last response for staugustine received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: tallahassee received.\n",
      "Last response for tallahassee received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: tampa received.\n",
      "Last response for tampa received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: treasure received.\n",
      "Last response for treasure received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: miami received.\n",
      "miami 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "Last response for miami received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: albanyga received.\n",
      "Last response for albanyga received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: athensga received.\n",
      "Last response for athensga received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: atlanta received.\n",
      "atlanta 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "Last response for atlanta received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: augusta received.\n",
      "Last response for augusta received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: brunswick received.\n",
      "Last response for brunswick received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: columbusga received.\n",
      "Last response for columbusga received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: macon received.\n",
      "Last response for macon received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: nwga received.\n",
      "Last response for nwga received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: savannah received.\n",
      "Last response for savannah received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: statesboro received.\n",
      "Last response for statesboro received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: valdosta received.\n",
      "Last response for valdosta received.  Process completed.\n",
      "\n",
      "Response #1 for Hawaii: honolulu received.\n",
      "Last response for honolulu received.  Process completed.\n",
      "\n",
      "Response #1 for Idaho: boise received.\n",
      "Last response for boise received.  Process completed.\n",
      "\n",
      "Response #1 for Idaho: eastidaho received.\n",
      "Last response for eastidaho received.  Process completed.\n",
      "\n",
      "Response #1 for Idaho: lewiston received.\n",
      "Last response for lewiston received.  Process completed.\n",
      "\n",
      "Response #1 for Idaho: twinfalls received.\n",
      "Last response for twinfalls received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: bn received.\n",
      "Last response for bn received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: chambana received.\n",
      "Last response for chambana received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: chicago received.\n",
      "Last response for chicago received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: decatur received.\n",
      "Last response for decatur received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: lasalle received.\n",
      "Last response for lasalle received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: mattoon received.\n",
      "Last response for mattoon received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: peoria received.\n",
      "Last response for peoria received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: rockford received.\n",
      "Last response for rockford received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: carbondale received.\n",
      "Last response for carbondale received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: springfieldil received.\n",
      "Last response for springfieldil received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: quincy received.\n",
      "Last response for quincy received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: bloomington received.\n",
      "Last response for bloomington received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: evansville received.\n",
      "Last response for evansville received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: fortwayne received.\n",
      "Last response for fortwayne received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: indianapolis received.\n",
      "Last response for indianapolis received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: kokomo received.\n",
      "Last response for kokomo received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: tippecanoe received.\n",
      "Last response for tippecanoe received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: muncie received.\n",
      "Last response for muncie received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: richmondin received.\n",
      "Last response for richmondin received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: southbend received.\n",
      "Last response for southbend received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: terrehaute received.\n",
      "Last response for terrehaute received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: ames received.\n",
      "Last response for ames received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: cedarrapids received.\n",
      "Last response for cedarrapids received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: desmoines received.\n",
      "Last response for desmoines received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: dubuque received.\n",
      "Last response for dubuque received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: fortdodge received.\n",
      "Last response for fortdodge received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: iowacity received.\n",
      "Last response for iowacity received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: masoncity received.\n",
      "Last response for masoncity received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: quadcities received.\n",
      "Last response for quadcities received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: siouxcity received.\n",
      "Last response for siouxcity received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: ottumwa received.\n",
      "Last response for ottumwa received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: waterloo received.\n",
      "Last response for waterloo received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: lawrence received.\n",
      "Last response for lawrence received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: ksu received.\n",
      "Last response for ksu received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: nwks received.\n",
      "Last response for nwks received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: salina received.\n",
      "Last response for salina received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: seks received.\n",
      "Last response for seks received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: swks received.\n",
      "Last response for swks received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: topeka received.\n",
      "Last response for topeka received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: wichita received.\n",
      "Last response for wichita received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: bgky received.\n",
      "Last response for bgky received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: eastky received.\n",
      "Last response for eastky received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: lexington received.\n",
      "Last response for lexington received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: louisville received.\n",
      "Last response for louisville received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: owensboro received.\n",
      "Last response for owensboro received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: westky received.\n",
      "Last response for westky received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: batonrouge received.\n",
      "Last response for batonrouge received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: cenla received.\n",
      "Last response for cenla received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: houma received.\n",
      "Last response for houma received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: lafayette received.\n",
      "Last response for lafayette received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: lakecharles received.\n",
      "Last response for lakecharles received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: monroe received.\n",
      "Last response for monroe received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: neworleans received.\n",
      "Last response for neworleans received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: shreveport received.\n",
      "Last response for shreveport received.  Process completed.\n",
      "\n",
      "Response #1 for Maine: maine received.\n",
      "Last response for maine received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: annapolis received.\n",
      "Last response for annapolis received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: baltimore received.\n",
      "Last response for baltimore received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: easternshore received.\n",
      "Last response for easternshore received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: frederick received.\n",
      "Last response for frederick received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: smd received.\n",
      "Last response for smd received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: westmd received.\n",
      "Last response for westmd received.  Process completed.\n",
      "\n",
      "Response #1 for Massachusetts: boston received.\n",
      "boston 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "Last response for boston received.  Process completed.\n",
      "\n",
      "Response #1 for Massachusetts: capecod received.\n",
      "Last response for capecod received.  Process completed.\n",
      "\n",
      "Response #1 for Massachusetts: southcoast received.\n",
      "Last response for southcoast received.  Process completed.\n",
      "\n",
      "Response #1 for Massachusetts: westernmass received.\n",
      "Last response for westernmass received.  Process completed.\n",
      "\n",
      "Response #1 for Massachusetts: worcester received.\n",
      "Last response for worcester received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: annarbor received.\n",
      "Last response for annarbor received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: battlecreek received.\n",
      "Last response for battlecreek received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: centralmich received.\n",
      "Last response for centralmich received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: detroit received.\n",
      "Last response for detroit received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: flint received.\n",
      "Last response for flint received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: grandrapids received.\n",
      "Last response for grandrapids received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: holland received.\n",
      "Last response for holland received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: jxn received.\n",
      "Last response for jxn received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: kalamazoo received.\n",
      "Last response for kalamazoo received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: lansing received.\n",
      "Last response for lansing received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: monroemi received.\n",
      "Last response for monroemi received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: muskegon received.\n",
      "Last response for muskegon received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: nmi received.\n",
      "Last response for nmi received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: porthuron received.\n",
      "Last response for porthuron received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: saginaw received.\n",
      "Last response for saginaw received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: swmi received.\n",
      "Last response for swmi received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: thumb received.\n",
      "Last response for thumb received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: up received.\n",
      "Last response for up received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: bemidji received.\n",
      "Last response for bemidji received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: brainerd received.\n",
      "Last response for brainerd received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: duluth received.\n",
      "Last response for duluth received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: mankato received.\n",
      "Last response for mankato received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: minneapolis received.\n",
      "Last response for minneapolis received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: rmn received.\n",
      "Last response for rmn received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: marshall received.\n",
      "Last response for marshall received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: stcloud received.\n",
      "Last response for stcloud received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: gulfport received.\n",
      "Last response for gulfport received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: hattiesburg received.\n",
      "Last response for hattiesburg received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: jackson received.\n",
      "Last response for jackson received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: meridian received.\n",
      "Last response for meridian received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: northmiss received.\n",
      "Last response for northmiss received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: natchez received.\n",
      "Last response for natchez received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: columbiamo received.\n",
      "Last response for columbiamo received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: joplin received.\n",
      "Last response for joplin received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: kansascity received.\n",
      "Last response for kansascity received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: kirksville received.\n",
      "Last response for kirksville received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: loz received.\n",
      "Last response for loz received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: semo received.\n",
      "Last response for semo received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: springfield received.\n",
      "Last response for springfield received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: stjoseph received.\n",
      "Last response for stjoseph received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: stlouis received.\n",
      "Last response for stlouis received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: billings received.\n",
      "Last response for billings received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: bozeman received.\n",
      "Last response for bozeman received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: butte received.\n",
      "Last response for butte received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: greatfalls received.\n",
      "Last response for greatfalls received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: helena received.\n",
      "Last response for helena received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: kalispell received.\n",
      "Last response for kalispell received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: missoula received.\n",
      "Last response for missoula received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: montana received.\n",
      "Last response for montana received.  Process completed.\n",
      "\n",
      "Response #1 for Nebraska: grandisland received.\n",
      "Last response for grandisland received.  Process completed.\n",
      "\n",
      "Response #1 for Nebraska: lincoln received.\n",
      "Last response for lincoln received.  Process completed.\n",
      "\n",
      "Response #1 for Nebraska: northplatte received.\n",
      "Last response for northplatte received.  Process completed.\n",
      "\n",
      "Response #1 for Nebraska: omaha received.\n",
      "Last response for omaha received.  Process completed.\n",
      "\n",
      "Response #1 for Nebraska: scottsbluff received.\n",
      "Last response for scottsbluff received.  Process completed.\n",
      "\n",
      "Response #1 for Nevada: elko received.\n",
      "Last response for elko received.  Process completed.\n",
      "\n",
      "Response #1 for Nevada: lasvegas received.\n",
      "Last response for lasvegas received.  Process completed.\n",
      "\n",
      "Response #1 for Nevada: reno received.\n",
      "Last response for reno received.  Process completed.\n",
      "\n",
      "Response #1 for New Hampshire: nh received.\n",
      "Last response for nh received.  Process completed.\n",
      "\n",
      "Response #1 for New Jersey: cnj received.\n",
      "Last response for cnj received.  Process completed.\n",
      "\n",
      "Response #1 for New Jersey: jerseyshore received.\n",
      "Last response for jerseyshore received.  Process completed.\n",
      "\n",
      "Response #1 for New Jersey: newjersey received.\n",
      "Last response for newjersey received.  Process completed.\n",
      "\n",
      "Response #1 for New Jersey: southjersey received.\n",
      "Last response for southjersey received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: albuquerque received.\n",
      "Last response for albuquerque received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: clovis received.\n",
      "Last response for clovis received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: farmington received.\n",
      "Last response for farmington received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: lascruces received.\n",
      "Last response for lascruces received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: roswell received.\n",
      "Last response for roswell received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: santafe received.\n",
      "Last response for santafe received.  Process completed.\n",
      "\n",
      "Response #1 for New York: albany received.\n",
      "Last response for albany received.  Process completed.\n",
      "\n",
      "Response #1 for New York: binghamton received.\n",
      "Last response for binghamton received.  Process completed.\n",
      "\n",
      "Response #1 for New York: buffalo received.\n",
      "Last response for buffalo received.  Process completed.\n",
      "\n",
      "Response #1 for New York: catskills received.\n",
      "Last response for catskills received.  Process completed.\n",
      "\n",
      "Response #1 for New York: chautauqua received.\n",
      "Last response for chautauqua received.  Process completed.\n",
      "\n",
      "Response #1 for New York: elmira received.\n",
      "Last response for elmira received.  Process completed.\n",
      "\n",
      "Response #1 for New York: fingerlakes received.\n",
      "Last response for fingerlakes received.  Process completed.\n",
      "\n",
      "Response #1 for New York: glensfalls received.\n",
      "Last response for glensfalls received.  Process completed.\n",
      "\n",
      "Response #1 for New York: hudsonvalley received.\n",
      "Last response for hudsonvalley received.  Process completed.\n",
      "\n",
      "Response #1 for New York: ithaca received.\n",
      "Last response for ithaca received.  Process completed.\n",
      "\n",
      "Response #1 for New York: longisland received.\n",
      "Last response for longisland received.  Process completed.\n",
      "\n",
      "Response #1 for New York: newyork received.\n",
      "newyork 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "newyork 3 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "newyork 4 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for newyork received.  Process completed.\n",
      "\n",
      "Response #1 for New York: oneonta received.\n",
      "Last response for oneonta received.  Process completed.\n",
      "\n",
      "Response #1 for New York: plattsburgh received.\n",
      "Last response for plattsburgh received.  Process completed.\n",
      "\n",
      "Response #1 for New York: potsdam received.\n",
      "Last response for potsdam received.  Process completed.\n",
      "\n",
      "Response #1 for New York: rochester received.\n",
      "Last response for rochester received.  Process completed.\n",
      "\n",
      "Response #1 for New York: syracuse received.\n",
      "Last response for syracuse received.  Process completed.\n",
      "\n",
      "Response #1 for New York: twintiers received.\n",
      "Last response for twintiers received.  Process completed.\n",
      "\n",
      "Response #1 for New York: utica received.\n",
      "Last response for utica received.  Process completed.\n",
      "\n",
      "Response #1 for New York: watertown received.\n",
      "Last response for watertown received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: asheville received.\n",
      "Last response for asheville received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: boone received.\n",
      "Last response for boone received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: charlotte received.\n",
      "Last response for charlotte received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: eastnc received.\n",
      "Last response for eastnc received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: fayetteville received.\n",
      "Last response for fayetteville received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: greensboro received.\n",
      "Last response for greensboro received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: hickory received.\n",
      "Last response for hickory received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: onslow received.\n",
      "Last response for onslow received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: outerbanks received.\n",
      "Last response for outerbanks received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: raleigh received.\n",
      "Last response for raleigh received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: wilmington received.\n",
      "Last response for wilmington received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: winstonsalem received.\n",
      "Last response for winstonsalem received.  Process completed.\n",
      "\n",
      "Response #1 for North Dakota: bismarck received.\n",
      "Last response for bismarck received.  Process completed.\n",
      "\n",
      "Response #1 for North Dakota: fargo received.\n",
      "Last response for fargo received.  Process completed.\n",
      "\n",
      "Response #1 for North Dakota: grandforks received.\n",
      "Last response for grandforks received.  Process completed.\n",
      "\n",
      "Response #1 for North Dakota: nd received.\n",
      "Last response for nd received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: akroncanton received.\n",
      "Last response for akroncanton received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: ashtabula received.\n",
      "Last response for ashtabula received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: athensohio received.\n",
      "Last response for athensohio received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: chillicothe received.\n",
      "Last response for chillicothe received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: cincinnati received.\n",
      "Last response for cincinnati received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: cleveland received.\n",
      "Last response for cleveland received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: columbus received.\n",
      "Last response for columbus received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: dayton received.\n",
      "Last response for dayton received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: limaohio received.\n",
      "Last response for limaohio received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: mansfield received.\n",
      "Last response for mansfield received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: sandusky received.\n",
      "Last response for sandusky received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: toledo received.\n",
      "Last response for toledo received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: tuscarawas received.\n",
      "Last response for tuscarawas received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: youngstown received.\n",
      "Last response for youngstown received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: zanesville received.\n",
      "Last response for zanesville received.  Process completed.\n",
      "\n",
      "Response #1 for Oklahoma: lawton received.\n",
      "Last response for lawton received.  Process completed.\n",
      "\n",
      "Response #1 for Oklahoma: enid received.\n",
      "Last response for enid received.  Process completed.\n",
      "\n",
      "Response #1 for Oklahoma: oklahomacity received.\n",
      "Last response for oklahomacity received.  Process completed.\n",
      "\n",
      "Response #1 for Oklahoma: stillwater received.\n",
      "Last response for stillwater received.  Process completed.\n",
      "\n",
      "Response #1 for Oklahoma: tulsa received.\n",
      "Last response for tulsa received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: bend received.\n",
      "Last response for bend received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: corvallis received.\n",
      "Last response for corvallis received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: eastoregon received.\n",
      "Last response for eastoregon received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: eugene received.\n",
      "Last response for eugene received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: klamath received.\n",
      "Last response for klamath received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: medford received.\n",
      "Last response for medford received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: oregoncoast received.\n",
      "Last response for oregoncoast received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: portland received.\n",
      "Last response for portland received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: roseburg received.\n",
      "Last response for roseburg received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: salem received.\n",
      "Last response for salem received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: altoona received.\n",
      "Last response for altoona received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: chambersburg received.\n",
      "Last response for chambersburg received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: erie received.\n",
      "Last response for erie received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: harrisburg received.\n",
      "Last response for harrisburg received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: lancaster received.\n",
      "Last response for lancaster received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: allentown received.\n",
      "Last response for allentown received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: meadville received.\n",
      "Last response for meadville received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: philadelphia received.\n",
      "Last response for philadelphia received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: pittsburgh received.\n",
      "Last response for pittsburgh received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: poconos received.\n",
      "Last response for poconos received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: reading received.\n",
      "Last response for reading received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: scranton received.\n",
      "Last response for scranton received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: pennstate received.\n",
      "Last response for pennstate received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: williamsport received.\n",
      "Last response for williamsport received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: york received.\n",
      "Last response for york received.  Process completed.\n",
      "\n",
      "Response #1 for Rhode Island: providence received.\n",
      "Last response for providence received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: charleston received.\n",
      "Last response for charleston received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: columbia received.\n",
      "Last response for columbia received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: florencesc received.\n",
      "Last response for florencesc received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: greenville received.\n",
      "Last response for greenville received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: hiltonhead received.\n",
      "Last response for hiltonhead received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: myrtlebeach received.\n",
      "Last response for myrtlebeach received.  Process completed.\n",
      "\n",
      "Response #1 for South Dakota: nesd received.\n",
      "Last response for nesd received.  Process completed.\n",
      "\n",
      "Response #1 for South Dakota: csd received.\n",
      "Last response for csd received.  Process completed.\n",
      "\n",
      "Response #1 for South Dakota: rapidcity received.\n",
      "Last response for rapidcity received.  Process completed.\n",
      "\n",
      "Response #1 for South Dakota: siouxfalls received.\n",
      "Last response for siouxfalls received.  Process completed.\n",
      "\n",
      "Response #1 for South Dakota: sd received.\n",
      "Last response for sd received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: chattanooga received.\n",
      "Last response for chattanooga received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: clarksville received.\n",
      "Last response for clarksville received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: cookeville received.\n",
      "Last response for cookeville received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: jacksontn received.\n",
      "Last response for jacksontn received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: knoxville received.\n",
      "Last response for knoxville received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: memphis received.\n",
      "Last response for memphis received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: nashville received.\n",
      "Last response for nashville received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: tricities received.\n",
      "Last response for tricities received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: abilene received.\n",
      "Last response for abilene received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: amarillo received.\n",
      "Last response for amarillo received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: austin received.\n",
      "Last response for austin received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: beaumont received.\n",
      "Last response for beaumont received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: brownsville received.\n",
      "Last response for brownsville received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: collegestation received.\n",
      "Last response for collegestation received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: corpuschristi received.\n",
      "Last response for corpuschristi received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: dallas received.\n",
      "dallas 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "Last response for dallas received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: nacogdoches received.\n",
      "Last response for nacogdoches received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: delrio received.\n",
      "Last response for delrio received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: elpaso received.\n",
      "Last response for elpaso received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: galveston received.\n",
      "Last response for galveston received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: houston received.\n",
      "Last response for houston received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: killeen received.\n",
      "Last response for killeen received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: laredo received.\n",
      "Last response for laredo received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: lubbock received.\n",
      "Last response for lubbock received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: mcallen received.\n",
      "Last response for mcallen received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: odessa received.\n",
      "Last response for odessa received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: sanangelo received.\n",
      "Last response for sanangelo received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: sanantonio received.\n",
      "Last response for sanantonio received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: sanmarcos received.\n",
      "Last response for sanmarcos received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: bigbend received.\n",
      "Last response for bigbend received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: texoma received.\n",
      "Last response for texoma received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: easttexas received.\n",
      "Last response for easttexas received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: victoriatx received.\n",
      "Last response for victoriatx received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: waco received.\n",
      "Last response for waco received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: wichitafalls received.\n",
      "Last response for wichitafalls received.  Process completed.\n",
      "\n",
      "Response #1 for Utah: logan received.\n",
      "Last response for logan received.  Process completed.\n",
      "\n",
      "Response #1 for Utah: ogden received.\n",
      "Last response for ogden received.  Process completed.\n",
      "\n",
      "Response #1 for Utah: provo received.\n",
      "Last response for provo received.  Process completed.\n",
      "\n",
      "Response #1 for Utah: saltlakecity received.\n",
      "Last response for saltlakecity received.  Process completed.\n",
      "\n",
      "Response #1 for Utah: stgeorge received.\n",
      "Last response for stgeorge received.  Process completed.\n",
      "\n",
      "Response #1 for Vermont: vermont received.\n",
      "Last response for vermont received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: charlottesville received.\n",
      "Last response for charlottesville received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: danville received.\n",
      "Last response for danville received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: fredericksburg received.\n",
      "Last response for fredericksburg received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: norfolk received.\n",
      "Last response for norfolk received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: harrisonburg received.\n",
      "Last response for harrisonburg received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: lynchburg received.\n",
      "Last response for lynchburg received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: blacksburg received.\n",
      "Last response for blacksburg received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: richmond received.\n",
      "Last response for richmond received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: roanoke received.\n",
      "Last response for roanoke received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: swva received.\n",
      "Last response for swva received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: winchester received.\n",
      "Last response for winchester received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: bellingham received.\n",
      "Last response for bellingham received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: kpr received.\n",
      "Last response for kpr received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: moseslake received.\n",
      "Last response for moseslake received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: olympic received.\n",
      "Last response for olympic received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: pullman received.\n",
      "Last response for pullman received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: seattle received.\n",
      "seattle 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "Last response for seattle received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: skagit received.\n",
      "Last response for skagit received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: spokane received.\n",
      "Last response for spokane received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: wenatchee received.\n",
      "Last response for wenatchee received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: yakima received.\n",
      "Last response for yakima received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: charlestonwv received.\n",
      "Last response for charlestonwv received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: martinsburg received.\n",
      "Last response for martinsburg received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: huntington received.\n",
      "Last response for huntington received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: morgantown received.\n",
      "Last response for morgantown received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: wheeling received.\n",
      "Last response for wheeling received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: parkersburg received.\n",
      "Last response for parkersburg received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: swv received.\n",
      "Last response for swv received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: wv received.\n",
      "Last response for wv received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: appleton received.\n",
      "Last response for appleton received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: eauclaire received.\n",
      "Last response for eauclaire received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: greenbay received.\n",
      "Last response for greenbay received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: janesville received.\n",
      "Last response for janesville received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: racine received.\n",
      "Last response for racine received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: lacrosse received.\n",
      "Last response for lacrosse received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: madison received.\n",
      "Last response for madison received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: milwaukee received.\n",
      "Last response for milwaukee received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: northernwi received.\n",
      "Last response for northernwi received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: sheboygan received.\n",
      "Last response for sheboygan received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: wausau received.\n",
      "Last response for wausau received.  Process completed.\n",
      "\n",
      "Response #1 for Wyoming: wyoming received.\n",
      "Last response for wyoming received.  Process completed.\n",
      "\n",
      "Response #1 for Territories: micronesia received.\n",
      "Last response for micronesia received.  Process completed.\n",
      "\n",
      "Response #1 for Territories: puertorico received.\n",
      "Last response for puertorico received.  Process completed.\n",
      "\n",
      "Response #1 for Territories: virgin received.\n",
      "Last response for virgin received.  Process completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Walk through each state in our state_Dict to get the HTML page corresponding to a search for \"math tutor\" in the services section\n",
    "response_dict = {}\n",
    "\n",
    "for state in state_dict.keys():\n",
    "\n",
    "    for region in state_dict[state]:\n",
    "        # This gets the first page of search results\n",
    "        i=1\n",
    "        \n",
    "        current_response = session.get('https://' + region + '.craigslist.org/d/services/search/bbb?query=math%20tutor&sort=rel')\n",
    "        \n",
    "        sleep_timer = random.randint(2,4)\n",
    "        time.sleep(sleep_timer)\n",
    "        \n",
    "        print(F\"Response #{i} for {state}: {region} received.\")\n",
    "        #print(F\"Waiting {sleep_timer} seconds...\")\n",
    "        #print()\n",
    "        \n",
    "        region_response_list = []\n",
    "        region_response_list.append(current_response)\n",
    "\n",
    "        # This gets all subsequent pages, using the next button from the search page\n",
    "        is_next_button = True\n",
    "        while is_next_button:\n",
    "            try:\n",
    "                next_response = current_response\n",
    "                next_soup = BeautifulSoup(next_response.text, 'html.parser')\n",
    "                \n",
    "# CL search pages have one of the following:\n",
    "    # 1) A next button:\n",
    "        # - when the region contains more than 120 posts for a given search\n",
    "    # 2) A greyed out next button:\n",
    "        # - when you've reached the last page of search results and there are no more\n",
    "        # OR\n",
    "        # - when a page has less than 120 results.\n",
    "    # 3) No next button:\n",
    "        # - when a page has less than 120 results\n",
    "# html suffix is None type when a next button isn't shown\n",
    "# html suffix is '' when the next button is greyed out.  This can happen in either case 2) or 3) from above\n",
    "# The while loop only needs to be peformed in case 1) when there is a next button you can click\n",
    "                html_suffix = next_soup.find(class_='button next')\n",
    "                #print(html_suffix)\n",
    "                if html_suffix is not None:\n",
    "                    html_suffix = html_suffix.get('href')\n",
    "                    #print(\"html_suffix is not none\")\n",
    "                    if html_suffix != '':\n",
    "                        i += 1\n",
    "                        #print(i, html_suffix)\n",
    "                        #print('html_suffix is not blank')\n",
    "                        new_button = 'https://' + region + '.craigslist.org' + html_suffix\n",
    "                        current_response = session.get(new_button)\n",
    "                        region_response_list.append(current_response)\n",
    "\n",
    "                        sleep_timer = random.randint(2,4)\n",
    "                        time.sleep(sleep_timer)\n",
    "                        print(F\"{region} {i} response received.\")\n",
    "                        print(F\"Waiting {sleep_timer} seconds...\")\n",
    "                        print()\n",
    "                    else:\n",
    "                        is_next_button = False\n",
    "                        #print('html_suffix is blank')\n",
    "                        print(F\"Last response for {region} received.  Process completed.\")\n",
    "                        print()\n",
    "                else:\n",
    "                    is_next_button = False\n",
    "                    #print('next_button is None')\n",
    "                    print(F\"Last response for {region} received.  Process completed.\")\n",
    "                    print()\n",
    "                    pass\n",
    "            except:\n",
    "                is_next_button = False\n",
    "                pass\n",
    "\n",
    "        # Store all search pages for math tutor\n",
    "        response_dict[(state, region)] = region_response_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb10f8b-f041-4af6-affb-ac25ba061207",
   "metadata": {},
   "source": [
    "## Get URL for each individual posting in a state/region combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0510527-c07e-4dc9-8401-62b375917a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk through each state/region combo to get a list of all individual postings for math tutoring in the results pages we searched up earlier.\n",
    "posts_dict = {}\n",
    "for key, responses in response_dict.items():\n",
    "    state = key[0]\n",
    "    region = key[1]\n",
    "    #current_region = region\n",
    "    region_posts = []\n",
    "    for response in responses:\n",
    "        current_html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        current_posts = current_html_soup.find_all('li', class_='result-row')\n",
    "        wanted_posts = []\n",
    "        for post in current_posts:\n",
    "# Many CL pages have \"results from nearby areas\", for instance some results for sandiego.craigslist.org show up in the losangeles.craigslist.org.  By comparing the region that we're currently scraping from against the URL of the posts, we can detect if it's from a nearby region or not.  To avoid duplicates and make the script finish more quickly, We only want to include posts where the URL of the post matches the region we're scraping from\n",
    "            if post.a.get('href').replace('https://','').split('.')[0] == region:\n",
    "                wanted_posts.append(post)\n",
    "        region_posts.extend(wanted_posts)\n",
    "    posts_dict[(state,region)] = region_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec63701-abcd-4878-af83-fc7c3a38c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many posts in total are to be scraped for countdown timer\n",
    "\n",
    "num_regions = len(posts_dict)\n",
    "\n",
    "num_posts = 0\n",
    "for region in posts_dict:\n",
    "    num_posts += len(posts_dict[region])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef209c4b-6e29-4707-8b69-d1cea179b9a9",
   "metadata": {},
   "source": [
    "## Getting soup object response for each individual post in a state/region combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e60e4c-018d-4599-9eae-41604def20d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time is 23:13:10\n",
      "Process estimated to finish before 04:07:46\n",
      "\n",
      "Soup objects for Alabama:auburn acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:25\n",
      "\n",
      "Soup objects for Alabama:bham acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:20\n",
      "\n",
      "Soup objects for Alabama:dothan acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:20\n",
      "\n",
      "Soup objects for Alabama:shoals acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:20\n",
      "\n",
      "Soup objects for Alabama:gadsden acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:20\n",
      "\n",
      "Soup objects for Alabama:huntsville acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:18\n",
      "\n",
      "Soup objects for Alabama:mobile acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:18\n",
      "\n",
      "Soup objects for Alabama:montgomery acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:16\n",
      "\n",
      "Soup objects for Alabama:tuscaloosa acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:16\n",
      "\n",
      "Soup objects for Alaska:anchorage acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:08\n",
      "\n",
      "Soup objects for Alaska:fairbanks acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:08\n",
      "\n",
      "Soup objects for Alaska:kenai acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:08\n",
      "\n",
      "Soup objects for Alaska:juneau acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:08\n",
      "\n",
      "Soup objects for Arizona:flagstaff acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:01\n",
      "\n",
      "Soup objects for Arizona:mohave acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:01\n",
      "\n",
      "Post number 10 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 20 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 30 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 40 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 50 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 60 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 70 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 80 in ('Arizona', 'phoenix') is being extracted.\n",
      "Soup objects for Arizona:phoenix acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:23\n",
      "\n",
      "Soup objects for Arizona:prescott acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:23\n",
      "\n",
      "Soup objects for Arizona:showlow acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:23\n",
      "\n",
      "Soup objects for Arizona:sierravista acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:23\n",
      "\n",
      "Post number 10 in ('Arizona', 'tucson') is being extracted.\n",
      "Soup objects for Arizona:tucson acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:02\n",
      "\n",
      "Soup objects for Arizona:yuma acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:00\n",
      "\n",
      "Soup objects for Arkansas:fayar acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:57\n",
      "\n",
      "Soup objects for Arkansas:fortsmith acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:57\n",
      "\n",
      "Soup objects for Arkansas:jonesboro acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:55\n",
      "\n",
      "Soup objects for Arkansas:littlerock acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:55\n",
      "\n",
      "Soup objects for Arkansas:texarkana acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:55\n",
      "\n",
      "Soup objects for California:bakersfield acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:47\n",
      "\n",
      "Soup objects for California:chico acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:40\n",
      "\n",
      "Soup objects for California:fresno acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:28\n",
      "\n",
      "Soup objects for California:goldcountry acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:25\n",
      "\n",
      "Soup objects for California:hanford acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:25\n",
      "\n",
      "Soup objects for California:humboldt acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:23\n",
      "\n",
      "Soup objects for California:imperial acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:23\n",
      "\n",
      "Post number 10 in ('California', 'inlandempire') is being extracted.\n",
      "Post number 20 in ('California', 'inlandempire') is being extracted.\n",
      "Post number 30 in ('California', 'inlandempire') is being extracted.\n",
      "Post number 40 in ('California', 'inlandempire') is being extracted.\n",
      "Post number 50 in ('California', 'inlandempire') is being extracted.\n",
      "Soup objects for California:inlandempire acquired.  Waiting for next region...\n",
      "Process will now finish by 05:15:45\n",
      "\n",
      "Post number 10 in ('California', 'losangeles') is being extracted.\n",
      "Post number 20 in ('California', 'losangeles') is being extracted.\n",
      "Post number 30 in ('California', 'losangeles') is being extracted.\n",
      "Post number 40 in ('California', 'losangeles') is being extracted.\n",
      "Post number 50 in ('California', 'losangeles') is being extracted.\n",
      "Post number 60 in ('California', 'losangeles') is being extracted.\n",
      "Post number 70 in ('California', 'losangeles') is being extracted.\n",
      "Post number 80 in ('California', 'losangeles') is being extracted.\n",
      "Post number 90 in ('California', 'losangeles') is being extracted.\n",
      "Post number 100 in ('California', 'losangeles') is being extracted.\n",
      "Post number 110 in ('California', 'losangeles') is being extracted.\n",
      "Post number 120 in ('California', 'losangeles') is being extracted.\n",
      "Post number 130 in ('California', 'losangeles') is being extracted.\n",
      "Post number 140 in ('California', 'losangeles') is being extracted.\n",
      "Post number 150 in ('California', 'losangeles') is being extracted.\n",
      "Post number 160 in ('California', 'losangeles') is being extracted.\n",
      "Post number 170 in ('California', 'losangeles') is being extracted.\n",
      "Post number 180 in ('California', 'losangeles') is being extracted.\n",
      "Post number 190 in ('California', 'losangeles') is being extracted.\n",
      "Post number 200 in ('California', 'losangeles') is being extracted.\n",
      "Post number 210 in ('California', 'losangeles') is being extracted.\n",
      "Post number 220 in ('California', 'losangeles') is being extracted.\n",
      "Post number 230 in ('California', 'losangeles') is being extracted.\n",
      "Post number 240 in ('California', 'losangeles') is being extracted.\n",
      "Post number 250 in ('California', 'losangeles') is being extracted.\n",
      "Post number 260 in ('California', 'losangeles') is being extracted.\n",
      "Post number 270 in ('California', 'losangeles') is being extracted.\n",
      "Post number 280 in ('California', 'losangeles') is being extracted.\n",
      "Post number 290 in ('California', 'losangeles') is being extracted.\n",
      "Post number 300 in ('California', 'losangeles') is being extracted.\n",
      "Post number 310 in ('California', 'losangeles') is being extracted.\n",
      "Post number 320 in ('California', 'losangeles') is being extracted.\n",
      "Post number 330 in ('California', 'losangeles') is being extracted.\n",
      "Soup objects for California:losangeles acquired.  Waiting for next region...\n",
      "Process will now finish by 05:04:53\n",
      "\n",
      "Soup objects for California:mendocino acquired.  Waiting for next region...\n",
      "Process will now finish by 05:04:53\n",
      "\n",
      "Soup objects for California:merced acquired.  Waiting for next region...\n",
      "Process will now finish by 05:04:50\n",
      "\n",
      "Soup objects for California:modesto acquired.  Waiting for next region...\n",
      "Process will now finish by 05:04:44\n",
      "\n",
      "Soup objects for California:monterey acquired.  Waiting for next region...\n",
      "Process will now finish by 05:04:42\n",
      "\n",
      "Post number 10 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 20 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 30 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 40 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 50 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 60 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 70 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 80 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 90 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 100 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 110 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 120 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 130 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 140 in ('California', 'orangecounty') is being extracted.\n",
      "Soup objects for California:orangecounty acquired.  Waiting for next region...\n",
      "Process will now finish by 04:59:55\n",
      "\n",
      "Soup objects for California:palmsprings acquired.  Waiting for next region...\n",
      "Process will now finish by 04:59:46\n",
      "\n",
      "Soup objects for California:redding acquired.  Waiting for next region...\n",
      "Process will now finish by 04:59:44\n",
      "\n",
      "Post number 10 in ('California', 'sacramento') is being extracted.\n",
      "Post number 20 in ('California', 'sacramento') is being extracted.\n",
      "Post number 30 in ('California', 'sacramento') is being extracted.\n",
      "Post number 40 in ('California', 'sacramento') is being extracted.\n",
      "Post number 50 in ('California', 'sacramento') is being extracted.\n",
      "Post number 60 in ('California', 'sacramento') is being extracted.\n",
      "Post number 70 in ('California', 'sacramento') is being extracted.\n",
      "Post number 80 in ('California', 'sacramento') is being extracted.\n",
      "Soup objects for California:sacramento acquired.  Waiting for next region...\n",
      "Process will now finish by 04:56:54\n",
      "\n",
      "Post number 10 in ('California', 'sandiego') is being extracted.\n",
      "Post number 20 in ('California', 'sandiego') is being extracted.\n",
      "Post number 30 in ('California', 'sandiego') is being extracted.\n",
      "Post number 40 in ('California', 'sandiego') is being extracted.\n",
      "Post number 50 in ('California', 'sandiego') is being extracted.\n",
      "Post number 60 in ('California', 'sandiego') is being extracted.\n",
      "Post number 70 in ('California', 'sandiego') is being extracted.\n",
      "Post number 80 in ('California', 'sandiego') is being extracted.\n",
      "Post number 90 in ('California', 'sandiego') is being extracted.\n",
      "Post number 100 in ('California', 'sandiego') is being extracted.\n",
      "Post number 110 in ('California', 'sandiego') is being extracted.\n",
      "Post number 120 in ('California', 'sandiego') is being extracted.\n",
      "Post number 130 in ('California', 'sandiego') is being extracted.\n",
      "Post number 140 in ('California', 'sandiego') is being extracted.\n",
      "Post number 150 in ('California', 'sandiego') is being extracted.\n",
      "Post number 160 in ('California', 'sandiego') is being extracted.\n",
      "Soup objects for California:sandiego acquired.  Waiting for next region...\n",
      "Process will now finish by 04:51:43\n",
      "\n",
      "Post number 10 in ('California', 'sfbay') is being extracted.\n",
      "Post number 20 in ('California', 'sfbay') is being extracted.\n",
      "Post number 30 in ('California', 'sfbay') is being extracted.\n",
      "Post number 40 in ('California', 'sfbay') is being extracted.\n",
      "Post number 50 in ('California', 'sfbay') is being extracted.\n",
      "Post number 60 in ('California', 'sfbay') is being extracted.\n",
      "Post number 70 in ('California', 'sfbay') is being extracted.\n",
      "Post number 80 in ('California', 'sfbay') is being extracted.\n",
      "Post number 90 in ('California', 'sfbay') is being extracted.\n",
      "Post number 100 in ('California', 'sfbay') is being extracted.\n",
      "Post number 110 in ('California', 'sfbay') is being extracted.\n",
      "Post number 120 in ('California', 'sfbay') is being extracted.\n",
      "Post number 130 in ('California', 'sfbay') is being extracted.\n",
      "Post number 140 in ('California', 'sfbay') is being extracted.\n",
      "Post number 150 in ('California', 'sfbay') is being extracted.\n",
      "Post number 160 in ('California', 'sfbay') is being extracted.\n",
      "Post number 170 in ('California', 'sfbay') is being extracted.\n",
      "Post number 180 in ('California', 'sfbay') is being extracted.\n",
      "Post number 190 in ('California', 'sfbay') is being extracted.\n",
      "Post number 200 in ('California', 'sfbay') is being extracted.\n",
      "Post number 210 in ('California', 'sfbay') is being extracted.\n",
      "Post number 220 in ('California', 'sfbay') is being extracted.\n",
      "Post number 230 in ('California', 'sfbay') is being extracted.\n",
      "Post number 240 in ('California', 'sfbay') is being extracted.\n",
      "Post number 250 in ('California', 'sfbay') is being extracted.\n",
      "Post number 260 in ('California', 'sfbay') is being extracted.\n",
      "Post number 270 in ('California', 'sfbay') is being extracted.\n",
      "Post number 280 in ('California', 'sfbay') is being extracted.\n",
      "Post number 290 in ('California', 'sfbay') is being extracted.\n",
      "Post number 300 in ('California', 'sfbay') is being extracted.\n",
      "Post number 310 in ('California', 'sfbay') is being extracted.\n",
      "Post number 320 in ('California', 'sfbay') is being extracted.\n",
      "Post number 330 in ('California', 'sfbay') is being extracted.\n",
      "Post number 340 in ('California', 'sfbay') is being extracted.\n",
      "Post number 350 in ('California', 'sfbay') is being extracted.\n",
      "Post number 360 in ('California', 'sfbay') is being extracted.\n",
      "Post number 370 in ('California', 'sfbay') is being extracted.\n",
      "Post number 380 in ('California', 'sfbay') is being extracted.\n",
      "Post number 390 in ('California', 'sfbay') is being extracted.\n",
      "Post number 400 in ('California', 'sfbay') is being extracted.\n",
      "Soup objects for California:sfbay acquired.  Waiting for next region...\n",
      "Process will now finish by 04:38:43\n",
      "\n",
      "Soup objects for California:slo acquired.  Waiting for next region...\n",
      "Process will now finish by 04:38:37\n",
      "\n",
      "Post number 10 in ('California', 'santabarbara') is being extracted.\n",
      "Soup objects for California:santabarbara acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:58\n",
      "\n",
      "Soup objects for California:santamaria acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:58\n",
      "\n",
      "Soup objects for California:siskiyou acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:58\n",
      "\n",
      "Soup objects for California:stockton acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:56\n",
      "\n",
      "Soup objects for California:susanville acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:56\n",
      "\n",
      "Post number 10 in ('California', 'ventura') is being extracted.\n",
      "Soup objects for California:ventura acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:36\n",
      "\n",
      "Soup objects for California:visalia acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:36\n",
      "\n",
      "Soup objects for California:yubasutter acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:35\n",
      "\n",
      "Post number 10 in ('Colorado', 'boulder') is being extracted.\n",
      "Post number 20 in ('Colorado', 'boulder') is being extracted.\n",
      "Soup objects for Colorado:boulder acquired.  Waiting for next region...\n",
      "Process will now finish by 04:36:56\n",
      "\n",
      "Soup objects for Colorado:cosprings acquired.  Waiting for next region...\n",
      "Process will now finish by 04:36:37\n",
      "\n",
      "Post number 10 in ('Colorado', 'denver') is being extracted.\n",
      "Post number 20 in ('Colorado', 'denver') is being extracted.\n",
      "Post number 30 in ('Colorado', 'denver') is being extracted.\n",
      "Post number 40 in ('Colorado', 'denver') is being extracted.\n",
      "Post number 50 in ('Colorado', 'denver') is being extracted.\n",
      "Post number 60 in ('Colorado', 'denver') is being extracted.\n",
      "Soup objects for Colorado:denver acquired.  Waiting for next region...\n",
      "Process will now finish by 04:34:40\n",
      "\n",
      "Soup objects for Colorado:eastco acquired.  Waiting for next region...\n",
      "Process will now finish by 04:34:40\n",
      "\n",
      "Soup objects for Colorado:fortcollins acquired.  Waiting for next region...\n",
      "Process will now finish by 04:34:24\n",
      "\n",
      "Soup objects for Colorado:rockies acquired.  Waiting for next region...\n",
      "Process will now finish by 04:34:24\n",
      "\n",
      "Soup objects for Colorado:pueblo acquired.  Waiting for next region...\n",
      "Process will now finish by 04:34:22\n",
      "\n",
      "Soup objects for Colorado:westslope acquired.  Waiting for next region...\n",
      "Process will now finish by 04:34:20\n",
      "\n",
      "Soup objects for Connecticut:newlondon acquired.  Waiting for next region...\n",
      "Process will now finish by 04:34:17\n",
      "\n",
      "Post number 10 in ('Connecticut', 'hartford') is being extracted.\n",
      "Soup objects for Connecticut:hartford acquired.  Waiting for next region...\n",
      "Process will now finish by 04:33:50\n",
      "\n",
      "Soup objects for Connecticut:newhaven acquired.  Waiting for next region...\n",
      "Process will now finish by 04:33:44\n",
      "\n",
      "Soup objects for Connecticut:nwct acquired.  Waiting for next region...\n",
      "Process will now finish by 04:33:44\n",
      "\n",
      "Post number 10 in ('Delaware', 'delaware') is being extracted.\n",
      "Soup objects for Delaware:delaware acquired.  Waiting for next region...\n",
      "Process will now finish by 04:33:17\n",
      "\n",
      "Post number 10 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 20 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 30 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 40 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 50 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 60 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 70 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 80 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 90 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 100 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 110 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 120 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 130 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 140 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 150 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 160 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Post number 170 in ('District of Columbia', 'washingtondc') is being extracted.\n",
      "Soup objects for District of Columbia:washingtondc acquired.  Waiting for next region...\n",
      "Process will now finish by 04:27:50\n",
      "\n",
      "Post number 10 in ('Florida', 'miami') is being extracted.\n",
      "Post number 20 in ('Florida', 'miami') is being extracted.\n",
      "Post number 30 in ('Florida', 'miami') is being extracted.\n",
      "Post number 40 in ('Florida', 'miami') is being extracted.\n",
      "Post number 50 in ('Florida', 'miami') is being extracted.\n",
      "Post number 60 in ('Florida', 'miami') is being extracted.\n",
      "Post number 70 in ('Florida', 'miami') is being extracted.\n",
      "Post number 80 in ('Florida', 'miami') is being extracted.\n",
      "Post number 90 in ('Florida', 'miami') is being extracted.\n",
      "Post number 100 in ('Florida', 'miami') is being extracted.\n",
      "Post number 110 in ('Florida', 'miami') is being extracted.\n",
      "Post number 120 in ('Florida', 'miami') is being extracted.\n",
      "Post number 130 in ('Florida', 'miami') is being extracted.\n",
      "Post number 140 in ('Florida', 'miami') is being extracted.\n",
      "Post number 150 in ('Florida', 'miami') is being extracted.\n",
      "Soup objects for Florida:miami acquired.  Waiting for next region...\n",
      "Process will now finish by 04:23:01\n",
      "\n",
      "Soup objects for Florida:daytona acquired.  Waiting for next region...\n",
      "Process will now finish by 04:22:58\n",
      "\n",
      "Soup objects for Florida:keys acquired.  Waiting for next region...\n",
      "Process will now finish by 04:22:58\n",
      "\n",
      "Soup objects for Florida:fortmyers acquired.  Waiting for next region...\n",
      "Process will now finish by 04:22:43\n",
      "\n",
      "Soup objects for Florida:gainesville acquired.  Waiting for next region...\n",
      "Process will now finish by 04:22:41\n",
      "\n",
      "Soup objects for Florida:cfl acquired.  Waiting for next region...\n",
      "Process will now finish by 04:22:41\n",
      "\n",
      "Post number 10 in ('Florida', 'jacksonville') is being extracted.\n",
      "Post number 20 in ('Florida', 'jacksonville') is being extracted.\n",
      "Soup objects for Florida:jacksonville acquired.  Waiting for next region...\n",
      "Process will now finish by 04:22:03\n",
      "\n",
      "Soup objects for Florida:lakeland acquired.  Waiting for next region...\n",
      "Process will now finish by 04:21:46\n",
      "\n",
      "Soup objects for Florida:lakecity acquired.  Waiting for next region...\n",
      "Process will now finish by 04:21:45\n",
      "\n",
      "Soup objects for Florida:ocala acquired.  Waiting for next region...\n",
      "Process will now finish by 04:21:44\n",
      "\n",
      "Soup objects for Florida:okaloosa acquired.  Waiting for next region...\n",
      "Process will now finish by 04:21:41\n",
      "\n",
      "Post number 10 in ('Florida', 'orlando') is being extracted.\n",
      "Post number 20 in ('Florida', 'orlando') is being extracted.\n",
      "Post number 30 in ('Florida', 'orlando') is being extracted.\n",
      "Soup objects for Florida:orlando acquired.  Waiting for next region...\n",
      "Process will now finish by 04:20:30\n",
      "\n",
      "Soup objects for Florida:panamacity acquired.  Waiting for next region...\n",
      "Process will now finish by 04:20:30\n",
      "\n",
      "Soup objects for Florida:pensacola acquired.  Waiting for next region...\n",
      "Process will now finish by 04:20:30\n",
      "\n",
      "Soup objects for Florida:sarasota acquired.  Waiting for next region...\n",
      "Process will now finish by 04:20:22\n",
      "\n",
      "Soup objects for Florida:spacecoast acquired.  Waiting for next region...\n",
      "Process will now finish by 04:20:18\n",
      "\n",
      "Soup objects for Florida:staugustine acquired.  Waiting for next region...\n",
      "Process will now finish by 04:20:10\n",
      "\n",
      "Soup objects for Florida:tallahassee acquired.  Waiting for next region...\n",
      "Process will now finish by 04:19:53\n",
      "\n",
      "Post number 10 in ('Florida', 'tampa') is being extracted.\n",
      "Post number 20 in ('Florida', 'tampa') is being extracted.\n",
      "Post number 30 in ('Florida', 'tampa') is being extracted.\n",
      "Soup objects for Florida:tampa acquired.  Waiting for next region...\n",
      "Process will now finish by 04:18:44\n",
      "\n",
      "Soup objects for Florida:treasure acquired.  Waiting for next region...\n",
      "Process will now finish by 04:18:40\n",
      "\n",
      "Soup objects for Georgia:albanyga acquired.  Waiting for next region...\n",
      "Process will now finish by 04:18:40\n",
      "\n",
      "Soup objects for Georgia:athensga acquired.  Waiting for next region...\n",
      "Process will now finish by 04:18:39\n",
      "\n",
      "Post number 10 in ('Georgia', 'atlanta') is being extracted.\n",
      "Post number 20 in ('Georgia', 'atlanta') is being extracted.\n",
      "Post number 30 in ('Georgia', 'atlanta') is being extracted.\n",
      "Post number 40 in ('Georgia', 'atlanta') is being extracted.\n",
      "Post number 50 in ('Georgia', 'atlanta') is being extracted.\n",
      "Post number 60 in ('Georgia', 'atlanta') is being extracted.\n",
      "Post number 70 in ('Georgia', 'atlanta') is being extracted.\n",
      "Post number 80 in ('Georgia', 'atlanta') is being extracted.\n",
      "Post number 90 in ('Georgia', 'atlanta') is being extracted.\n",
      "Post number 100 in ('Georgia', 'atlanta') is being extracted.\n",
      "Post number 110 in ('Georgia', 'atlanta') is being extracted.\n",
      "Post number 120 in ('Georgia', 'atlanta') is being extracted.\n",
      "Soup objects for Georgia:atlanta acquired.  Waiting for next region...\n",
      "Process will now finish by 04:14:30\n",
      "\n",
      "Soup objects for Georgia:augusta acquired.  Waiting for next region...\n",
      "Process will now finish by 04:14:30\n",
      "\n",
      "Soup objects for Georgia:brunswick acquired.  Waiting for next region...\n",
      "Process will now finish by 04:14:30\n",
      "\n",
      "Soup objects for Georgia:columbusga acquired.  Waiting for next region...\n",
      "Process will now finish by 04:14:30\n",
      "\n",
      "Soup objects for Georgia:macon acquired.  Waiting for next region...\n",
      "Process will now finish by 04:14:30\n",
      "\n",
      "Soup objects for Georgia:nwga acquired.  Waiting for next region...\n",
      "Process will now finish by 04:14:20\n",
      "\n",
      "Soup objects for Georgia:savannah acquired.  Waiting for next region...\n",
      "Process will now finish by 04:14:19\n",
      "\n",
      "Soup objects for Georgia:statesboro acquired.  Waiting for next region...\n",
      "Process will now finish by 04:14:19\n",
      "\n",
      "Soup objects for Georgia:valdosta acquired.  Waiting for next region...\n",
      "Process will now finish by 04:14:19\n",
      "\n",
      "Post number 10 in ('Hawaii', 'honolulu') is being extracted.\n",
      "Post number 20 in ('Hawaii', 'honolulu') is being extracted.\n",
      "Soup objects for Hawaii:honolulu acquired.  Waiting for next region...\n",
      "Process will now finish by 04:13:38\n",
      "\n",
      "Soup objects for Idaho:boise acquired.  Waiting for next region...\n",
      "Process will now finish by 04:13:18\n",
      "\n",
      "Soup objects for Idaho:eastidaho acquired.  Waiting for next region...\n",
      "Process will now finish by 04:13:18\n",
      "\n",
      "Soup objects for Idaho:lewiston acquired.  Waiting for next region...\n",
      "Process will now finish by 04:13:18\n",
      "\n",
      "Soup objects for Idaho:twinfalls acquired.  Waiting for next region...\n",
      "Process will now finish by 04:13:14\n",
      "\n",
      "Soup objects for Illinois:bn acquired.  Waiting for next region...\n",
      "Process will now finish by 04:13:14\n",
      "\n",
      "Soup objects for Illinois:chambana acquired.  Waiting for next region...\n",
      "Process will now finish by 04:13:13\n",
      "\n",
      "Post number 10 in ('Illinois', 'chicago') is being extracted.\n",
      "Post number 20 in ('Illinois', 'chicago') is being extracted.\n",
      "Post number 30 in ('Illinois', 'chicago') is being extracted.\n",
      "Post number 40 in ('Illinois', 'chicago') is being extracted.\n",
      "Post number 50 in ('Illinois', 'chicago') is being extracted.\n",
      "Post number 60 in ('Illinois', 'chicago') is being extracted.\n",
      "Post number 70 in ('Illinois', 'chicago') is being extracted.\n",
      "Post number 80 in ('Illinois', 'chicago') is being extracted.\n",
      "Soup objects for Illinois:chicago acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:14\n",
      "\n",
      "Soup objects for Illinois:decatur acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:14\n",
      "\n",
      "Soup objects for Illinois:lasalle acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:14\n",
      "\n",
      "Soup objects for Illinois:mattoon acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:14\n",
      "\n",
      "Soup objects for Illinois:peoria acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:10\n",
      "\n",
      "Soup objects for Illinois:rockford acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:10\n",
      "\n",
      "Soup objects for Illinois:carbondale acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:10\n",
      "\n",
      "Soup objects for Illinois:springfieldil acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:10\n",
      "\n",
      "Soup objects for Illinois:quincy acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:10\n",
      "\n",
      "Soup objects for Indiana:bloomington acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:10\n",
      "\n",
      "Soup objects for Indiana:evansville acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:09\n",
      "\n",
      "Soup objects for Indiana:fortwayne acquired.  Waiting for next region...\n",
      "Process will now finish by 04:10:07\n",
      "\n",
      "Soup objects for Indiana:indianapolis acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:52\n",
      "\n",
      "Soup objects for Indiana:kokomo acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:52\n",
      "\n",
      "Soup objects for Indiana:tippecanoe acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:50\n",
      "\n",
      "Soup objects for Indiana:muncie acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:50\n",
      "\n",
      "Soup objects for Indiana:richmondin acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:50\n",
      "\n",
      "Soup objects for Indiana:southbend acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:49\n",
      "\n",
      "Soup objects for Indiana:terrehaute acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:49\n",
      "\n",
      "Soup objects for Iowa:ames acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:49\n",
      "\n",
      "Soup objects for Iowa:cedarrapids acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:47\n",
      "\n",
      "Soup objects for Iowa:desmoines acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:43\n",
      "\n",
      "Soup objects for Iowa:dubuque acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:43\n",
      "\n",
      "Soup objects for Iowa:fortdodge acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:43\n",
      "\n",
      "Soup objects for Iowa:iowacity acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:43\n",
      "\n",
      "Soup objects for Iowa:masoncity acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:43\n",
      "\n",
      "Soup objects for Iowa:quadcities acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:43\n",
      "\n",
      "Soup objects for Iowa:siouxcity acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:43\n",
      "\n",
      "Soup objects for Iowa:ottumwa acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:40\n",
      "\n",
      "Soup objects for Iowa:waterloo acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:40\n",
      "\n",
      "Soup objects for Kansas:lawrence acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:36\n",
      "\n",
      "Soup objects for Kansas:ksu acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:34\n",
      "\n",
      "Soup objects for Kansas:nwks acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:33\n",
      "\n",
      "Soup objects for Kansas:salina acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:33\n",
      "\n",
      "Soup objects for Kansas:seks acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:33\n",
      "\n",
      "Soup objects for Kansas:swks acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:33\n",
      "\n",
      "Soup objects for Kansas:topeka acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:33\n",
      "\n",
      "Soup objects for Kansas:wichita acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:30\n",
      "\n",
      "Soup objects for Kentucky:bgky acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:30\n",
      "\n",
      "Soup objects for Kentucky:eastky acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:30\n",
      "\n",
      "Soup objects for Kentucky:lexington acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:30\n",
      "\n",
      "Soup objects for Kentucky:louisville acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:17\n",
      "\n",
      "Soup objects for Kentucky:owensboro acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:17\n",
      "\n",
      "Soup objects for Kentucky:westky acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:17\n",
      "\n",
      "Soup objects for Louisiana:batonrouge acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:12\n",
      "\n",
      "Soup objects for Louisiana:cenla acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:12\n",
      "\n",
      "Soup objects for Louisiana:houma acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:11\n",
      "\n",
      "Soup objects for Louisiana:lafayette acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:11\n",
      "\n",
      "Soup objects for Louisiana:lakecharles acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:11\n",
      "\n",
      "Soup objects for Louisiana:monroe acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:11\n",
      "\n",
      "Soup objects for Louisiana:neworleans acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:02\n",
      "\n",
      "Soup objects for Louisiana:shreveport acquired.  Waiting for next region...\n",
      "Process will now finish by 04:09:02\n",
      "\n",
      "Soup objects for Maine:maine acquired.  Waiting for next region...\n",
      "Process will now finish by 04:08:49\n",
      "\n",
      "Soup objects for Maryland:annapolis acquired.  Waiting for next region...\n",
      "Process will now finish by 04:08:30\n",
      "\n",
      "Post number 10 in ('Maryland', 'baltimore') is being extracted.\n",
      "Post number 20 in ('Maryland', 'baltimore') is being extracted.\n",
      "Post number 30 in ('Maryland', 'baltimore') is being extracted.\n",
      "Post number 40 in ('Maryland', 'baltimore') is being extracted.\n",
      "Soup objects for Maryland:baltimore acquired.  Waiting for next region...\n",
      "Process will now finish by 04:06:50\n",
      "\n",
      "Soup objects for Maryland:easternshore acquired.  Waiting for next region...\n",
      "Process will now finish by 04:06:50\n",
      "\n",
      "Soup objects for Maryland:frederick acquired.  Waiting for next region...\n",
      "Process will now finish by 04:06:50\n",
      "\n",
      "Soup objects for Maryland:smd acquired.  Waiting for next region...\n",
      "Process will now finish by 04:06:46\n",
      "\n",
      "Soup objects for Maryland:westmd acquired.  Waiting for next region...\n",
      "Process will now finish by 04:06:46\n",
      "\n",
      "Post number 10 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 20 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 30 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 40 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 50 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 60 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 70 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 80 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 90 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 100 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 110 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 120 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 130 in ('Massachusetts', 'boston') is being extracted.\n",
      "Post number 140 in ('Massachusetts', 'boston') is being extracted.\n",
      "Soup objects for Massachusetts:boston acquired.  Waiting for next region...\n",
      "Process will now finish by 04:02:10\n",
      "\n",
      "Soup objects for Massachusetts:capecod acquired.  Waiting for next region...\n",
      "Process will now finish by 04:02:10\n",
      "\n",
      "Soup objects for Massachusetts:southcoast acquired.  Waiting for next region...\n",
      "Process will now finish by 04:02:10\n",
      "\n",
      "Soup objects for Massachusetts:westernmass acquired.  Waiting for next region...\n",
      "Process will now finish by 04:02:10\n",
      "\n",
      "Soup objects for Massachusetts:worcester acquired.  Waiting for next region...\n",
      "Process will now finish by 04:01:59\n",
      "\n",
      "Post number 10 in ('Michigan', 'annarbor') is being extracted.\n",
      "Soup objects for Michigan:annarbor acquired.  Waiting for next region...\n",
      "Process will now finish by 04:01:30\n",
      "\n",
      "Soup objects for Michigan:battlecreek acquired.  Waiting for next region...\n",
      "Process will now finish by 04:01:30\n",
      "\n",
      "Soup objects for Michigan:centralmich acquired.  Waiting for next region...\n",
      "Process will now finish by 04:01:30\n",
      "\n",
      "Post number 10 in ('Michigan', 'detroit') is being extracted.\n",
      "Post number 20 in ('Michigan', 'detroit') is being extracted.\n",
      "Soup objects for Michigan:detroit acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:41\n",
      "\n",
      "Soup objects for Michigan:flint acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:41\n",
      "\n",
      "Soup objects for Michigan:grandrapids acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:holland acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:jxn acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:kalamazoo acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:lansing acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:monroemi acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:muskegon acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:nmi acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:porthuron acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:saginaw acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:swmi acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:thumb acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Michigan:up acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Minnesota:bemidji acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Minnesota:brainerd acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Minnesota:duluth acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Soup objects for Minnesota:mankato acquired.  Waiting for next region...\n",
      "Process will now finish by 04:00:40\n",
      "\n",
      "Post number 10 in ('Minnesota', 'minneapolis') is being extracted.\n",
      "Post number 20 in ('Minnesota', 'minneapolis') is being extracted.\n",
      "Post number 30 in ('Minnesota', 'minneapolis') is being extracted.\n",
      "Soup objects for Minnesota:minneapolis acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:34\n",
      "\n",
      "Soup objects for Minnesota:rmn acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:34\n",
      "\n",
      "Soup objects for Minnesota:marshall acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:34\n",
      "\n",
      "Soup objects for Minnesota:stcloud acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:34\n",
      "\n",
      "Soup objects for Mississippi:gulfport acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:34\n",
      "\n",
      "Soup objects for Mississippi:hattiesburg acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:34\n",
      "\n",
      "Soup objects for Mississippi:jackson acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:34\n",
      "\n",
      "Soup objects for Mississippi:meridian acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:34\n",
      "\n",
      "Soup objects for Mississippi:northmiss acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:32\n",
      "\n",
      "Soup objects for Mississippi:natchez acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:32\n",
      "\n",
      "Soup objects for Missouri:columbiamo acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:32\n",
      "\n",
      "Soup objects for Missouri:joplin acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:32\n",
      "\n",
      "Soup objects for Missouri:kansascity acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:28\n",
      "\n",
      "Soup objects for Missouri:kirksville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:28\n",
      "\n",
      "Soup objects for Missouri:loz acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:28\n",
      "\n",
      "Soup objects for Missouri:semo acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:28\n",
      "\n",
      "Soup objects for Missouri:springfield acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:26\n",
      "\n",
      "Soup objects for Missouri:stjoseph acquired.  Waiting for next region...\n",
      "Process will now finish by 03:59:26\n",
      "\n",
      "Post number 10 in ('Missouri', 'stlouis') is being extracted.\n",
      "Soup objects for Missouri:stlouis acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:58\n",
      "\n",
      "Soup objects for Montana:billings acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:58\n",
      "\n",
      "Soup objects for Montana:bozeman acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:58\n",
      "\n",
      "Soup objects for Montana:butte acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:58\n",
      "\n",
      "Soup objects for Montana:greatfalls acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:58\n",
      "\n",
      "Soup objects for Montana:helena acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:58\n",
      "\n",
      "Soup objects for Montana:kalispell acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:58\n",
      "\n",
      "Soup objects for Montana:missoula acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:56\n",
      "\n",
      "Soup objects for Montana:montana acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:56\n",
      "\n",
      "Soup objects for Nebraska:grandisland acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:56\n",
      "\n",
      "Soup objects for Nebraska:lincoln acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:53\n",
      "\n",
      "Soup objects for Nebraska:northplatte acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:52\n",
      "\n",
      "Soup objects for Nebraska:omaha acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:47\n",
      "\n",
      "Soup objects for Nebraska:scottsbluff acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:47\n",
      "\n",
      "Soup objects for Nevada:elko acquired.  Waiting for next region...\n",
      "Process will now finish by 03:58:47\n",
      "\n",
      "Post number 10 in ('Nevada', 'lasvegas') is being extracted.\n",
      "Post number 20 in ('Nevada', 'lasvegas') is being extracted.\n",
      "Post number 30 in ('Nevada', 'lasvegas') is being extracted.\n",
      "Post number 40 in ('Nevada', 'lasvegas') is being extracted.\n",
      "Soup objects for Nevada:lasvegas acquired.  Waiting for next region...\n",
      "Process will now finish by 03:57:07\n",
      "\n",
      "Soup objects for Nevada:reno acquired.  Waiting for next region...\n",
      "Process will now finish by 03:56:56\n",
      "\n",
      "Post number 10 in ('New Hampshire', 'nh') is being extracted.\n",
      "Post number 20 in ('New Hampshire', 'nh') is being extracted.\n",
      "Soup objects for New Hampshire:nh acquired.  Waiting for next region...\n",
      "Process will now finish by 03:56:09\n",
      "\n",
      "Post number 10 in ('New Jersey', 'cnj') is being extracted.\n",
      "Post number 20 in ('New Jersey', 'cnj') is being extracted.\n",
      "Post number 30 in ('New Jersey', 'cnj') is being extracted.\n",
      "Post number 40 in ('New Jersey', 'cnj') is being extracted.\n",
      "Post number 50 in ('New Jersey', 'cnj') is being extracted.\n",
      "Post number 60 in ('New Jersey', 'cnj') is being extracted.\n",
      "Soup objects for New Jersey:cnj acquired.  Waiting for next region...\n",
      "Process will now finish by 03:53:54\n",
      "\n",
      "Soup objects for New Jersey:jerseyshore acquired.  Waiting for next region...\n",
      "Process will now finish by 03:53:48\n",
      "\n",
      "Post number 10 in ('New Jersey', 'newjersey') is being extracted.\n",
      "Post number 20 in ('New Jersey', 'newjersey') is being extracted.\n",
      "Post number 30 in ('New Jersey', 'newjersey') is being extracted.\n",
      "Post number 40 in ('New Jersey', 'newjersey') is being extracted.\n",
      "Soup objects for New Jersey:newjersey acquired.  Waiting for next region...\n",
      "Process will now finish by 03:52:17\n",
      "\n",
      "Soup objects for New Jersey:southjersey acquired.  Waiting for next region...\n",
      "Process will now finish by 03:52:04\n",
      "\n",
      "Soup objects for New Mexico:albuquerque acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:50\n",
      "\n",
      "Soup objects for New Mexico:clovis acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:50\n",
      "\n",
      "Soup objects for New Mexico:farmington acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:50\n",
      "\n",
      "Soup objects for New Mexico:lascruces acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:50\n",
      "\n",
      "Soup objects for New Mexico:roswell acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:47\n",
      "\n",
      "Soup objects for New Mexico:santafe acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:40\n",
      "\n",
      "Soup objects for New York:albany acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:31\n",
      "\n",
      "Soup objects for New York:binghamton acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:31\n",
      "\n",
      "Soup objects for New York:buffalo acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:18\n",
      "\n",
      "Soup objects for New York:catskills acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:18\n",
      "\n",
      "Soup objects for New York:chautauqua acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:18\n",
      "\n",
      "Soup objects for New York:elmira acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:18\n",
      "\n",
      "Soup objects for New York:fingerlakes acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:18\n",
      "\n",
      "Soup objects for New York:glensfalls acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:18\n",
      "\n",
      "Soup objects for New York:hudsonvalley acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:09\n",
      "\n",
      "Soup objects for New York:ithaca acquired.  Waiting for next region...\n",
      "Process will now finish by 03:51:07\n",
      "\n",
      "Post number 10 in ('New York', 'longisland') is being extracted.\n",
      "Post number 20 in ('New York', 'longisland') is being extracted.\n",
      "Post number 30 in ('New York', 'longisland') is being extracted.\n",
      "Post number 40 in ('New York', 'longisland') is being extracted.\n",
      "Soup objects for New York:longisland acquired.  Waiting for next region...\n",
      "Process will now finish by 03:49:38\n",
      "\n",
      "Post number 10 in ('New York', 'newyork') is being extracted.\n",
      "Post number 20 in ('New York', 'newyork') is being extracted.\n",
      "Post number 30 in ('New York', 'newyork') is being extracted.\n",
      "Post number 40 in ('New York', 'newyork') is being extracted.\n",
      "Post number 50 in ('New York', 'newyork') is being extracted.\n",
      "Post number 60 in ('New York', 'newyork') is being extracted.\n",
      "Post number 70 in ('New York', 'newyork') is being extracted.\n",
      "Post number 80 in ('New York', 'newyork') is being extracted.\n",
      "Post number 90 in ('New York', 'newyork') is being extracted.\n",
      "Post number 100 in ('New York', 'newyork') is being extracted.\n",
      "Post number 110 in ('New York', 'newyork') is being extracted.\n",
      "Post number 120 in ('New York', 'newyork') is being extracted.\n",
      "Post number 130 in ('New York', 'newyork') is being extracted.\n",
      "Post number 140 in ('New York', 'newyork') is being extracted.\n",
      "Post number 150 in ('New York', 'newyork') is being extracted.\n",
      "Post number 160 in ('New York', 'newyork') is being extracted.\n",
      "Post number 170 in ('New York', 'newyork') is being extracted.\n",
      "Post number 180 in ('New York', 'newyork') is being extracted.\n",
      "Post number 190 in ('New York', 'newyork') is being extracted.\n",
      "Post number 200 in ('New York', 'newyork') is being extracted.\n",
      "Post number 210 in ('New York', 'newyork') is being extracted.\n",
      "Post number 220 in ('New York', 'newyork') is being extracted.\n",
      "Post number 230 in ('New York', 'newyork') is being extracted.\n",
      "Post number 240 in ('New York', 'newyork') is being extracted.\n",
      "Post number 250 in ('New York', 'newyork') is being extracted.\n",
      "Post number 260 in ('New York', 'newyork') is being extracted.\n",
      "Post number 270 in ('New York', 'newyork') is being extracted.\n",
      "Post number 280 in ('New York', 'newyork') is being extracted.\n",
      "Post number 290 in ('New York', 'newyork') is being extracted.\n",
      "Post number 300 in ('New York', 'newyork') is being extracted.\n",
      "Post number 310 in ('New York', 'newyork') is being extracted.\n",
      "Post number 320 in ('New York', 'newyork') is being extracted.\n",
      "Post number 330 in ('New York', 'newyork') is being extracted.\n",
      "Post number 340 in ('New York', 'newyork') is being extracted.\n",
      "Post number 350 in ('New York', 'newyork') is being extracted.\n",
      "Post number 360 in ('New York', 'newyork') is being extracted.\n",
      "Post number 370 in ('New York', 'newyork') is being extracted.\n",
      "Post number 380 in ('New York', 'newyork') is being extracted.\n",
      "Post number 390 in ('New York', 'newyork') is being extracted.\n",
      "Post number 400 in ('New York', 'newyork') is being extracted.\n",
      "Post number 410 in ('New York', 'newyork') is being extracted.\n",
      "Post number 420 in ('New York', 'newyork') is being extracted.\n",
      "Post number 430 in ('New York', 'newyork') is being extracted.\n",
      "Soup objects for New York:newyork acquired.  Waiting for next region...\n",
      "Process will now finish by 03:35:21\n",
      "\n",
      "Soup objects for New York:oneonta acquired.  Waiting for next region...\n",
      "Process will now finish by 03:35:21\n",
      "\n",
      "Soup objects for New York:plattsburgh acquired.  Waiting for next region...\n",
      "Process will now finish by 03:35:21\n",
      "\n",
      "Soup objects for New York:potsdam acquired.  Waiting for next region...\n",
      "Process will now finish by 03:35:21\n",
      "\n",
      "Soup objects for New York:rochester acquired.  Waiting for next region...\n",
      "Process will now finish by 03:35:09\n",
      "\n",
      "Soup objects for New York:syracuse acquired.  Waiting for next region...\n",
      "Process will now finish by 03:35:08\n",
      "\n",
      "Soup objects for New York:twintiers acquired.  Waiting for next region...\n",
      "Process will now finish by 03:35:08\n",
      "\n",
      "Soup objects for New York:utica acquired.  Waiting for next region...\n",
      "Process will now finish by 03:35:08\n",
      "\n",
      "Soup objects for New York:watertown acquired.  Waiting for next region...\n",
      "Process will now finish by 03:35:08\n",
      "\n",
      "Soup objects for North Carolina:asheville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:35:06\n",
      "\n",
      "Soup objects for North Carolina:boone acquired.  Waiting for next region...\n",
      "Process will now finish by 03:35:06\n",
      "\n",
      "Post number 10 in ('North Carolina', 'charlotte') is being extracted.\n",
      "Post number 20 in ('North Carolina', 'charlotte') is being extracted.\n",
      "Post number 30 in ('North Carolina', 'charlotte') is being extracted.\n",
      "Soup objects for North Carolina:charlotte acquired.  Waiting for next region...\n",
      "Process will now finish by 03:34:45\n",
      "\n",
      "Soup objects for North Carolina:eastnc acquired.  Waiting for next region...\n",
      "Process will now finish by 03:34:45\n",
      "\n",
      "Soup objects for North Carolina:fayetteville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:34:42\n",
      "\n",
      "Soup objects for North Carolina:greensboro acquired.  Waiting for next region...\n",
      "Process will now finish by 03:34:40\n",
      "\n",
      "Soup objects for North Carolina:hickory acquired.  Waiting for next region...\n",
      "Process will now finish by 03:34:40\n",
      "\n",
      "Soup objects for North Carolina:onslow acquired.  Waiting for next region...\n",
      "Process will now finish by 03:34:40\n",
      "\n",
      "Soup objects for North Carolina:outerbanks acquired.  Waiting for next region...\n",
      "Process will now finish by 03:34:40\n",
      "\n",
      "Post number 10 in ('North Carolina', 'raleigh') is being extracted.\n",
      "Post number 20 in ('North Carolina', 'raleigh') is being extracted.\n",
      "Post number 30 in ('North Carolina', 'raleigh') is being extracted.\n",
      "Post number 40 in ('North Carolina', 'raleigh') is being extracted.\n",
      "Post number 50 in ('North Carolina', 'raleigh') is being extracted.\n",
      "Post number 60 in ('North Carolina', 'raleigh') is being extracted.\n",
      "Soup objects for North Carolina:raleigh acquired.  Waiting for next region...\n",
      "Process will now finish by 03:32:31\n",
      "\n",
      "Soup objects for North Carolina:wilmington acquired.  Waiting for next region...\n",
      "Process will now finish by 03:32:21\n",
      "\n",
      "Soup objects for North Carolina:winstonsalem acquired.  Waiting for next region...\n",
      "Process will now finish by 03:32:16\n",
      "\n",
      "Soup objects for North Dakota:bismarck acquired.  Waiting for next region...\n",
      "Process will now finish by 03:32:16\n",
      "\n",
      "Soup objects for North Dakota:fargo acquired.  Waiting for next region...\n",
      "Process will now finish by 03:32:14\n",
      "\n",
      "Soup objects for North Dakota:grandforks acquired.  Waiting for next region...\n",
      "Process will now finish by 03:32:14\n",
      "\n",
      "Soup objects for North Dakota:nd acquired.  Waiting for next region...\n",
      "Process will now finish by 03:32:14\n",
      "\n",
      "Soup objects for Ohio:akroncanton acquired.  Waiting for next region...\n",
      "Process will now finish by 03:32:06\n",
      "\n",
      "Soup objects for Ohio:ashtabula acquired.  Waiting for next region...\n",
      "Process will now finish by 03:32:06\n",
      "\n",
      "Soup objects for Ohio:athensohio acquired.  Waiting for next region...\n",
      "Process will now finish by 03:32:06\n",
      "\n",
      "Soup objects for Ohio:chillicothe acquired.  Waiting for next region...\n",
      "Process will now finish by 03:32:06\n",
      "\n",
      "Post number 10 in ('Ohio', 'cincinnati') is being extracted.\n",
      "Soup objects for Ohio:cincinnati acquired.  Waiting for next region...\n",
      "Process will now finish by 03:31:44\n",
      "\n",
      "Post number 10 in ('Ohio', 'cleveland') is being extracted.\n",
      "Post number 20 in ('Ohio', 'cleveland') is being extracted.\n",
      "Soup objects for Ohio:cleveland acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:56\n",
      "\n",
      "Post number 10 in ('Ohio', 'columbus') is being extracted.\n",
      "Soup objects for Ohio:columbus acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:25\n",
      "\n",
      "Soup objects for Ohio:dayton acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:20\n",
      "\n",
      "Soup objects for Ohio:limaohio acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:20\n",
      "\n",
      "Soup objects for Ohio:mansfield acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:20\n",
      "\n",
      "Soup objects for Ohio:sandusky acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:20\n",
      "\n",
      "Soup objects for Ohio:toledo acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:18\n",
      "\n",
      "Soup objects for Ohio:tuscarawas acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:18\n",
      "\n",
      "Soup objects for Ohio:youngstown acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:18\n",
      "\n",
      "Soup objects for Ohio:zanesville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:18\n",
      "\n",
      "Soup objects for Oklahoma:lawton acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:18\n",
      "\n",
      "Soup objects for Oklahoma:enid acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:18\n",
      "\n",
      "Soup objects for Oklahoma:oklahomacity acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:14\n",
      "\n",
      "Soup objects for Oklahoma:stillwater acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:14\n",
      "\n",
      "Soup objects for Oklahoma:tulsa acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:11\n",
      "\n",
      "Soup objects for Oregon:bend acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:08\n",
      "\n",
      "Soup objects for Oregon:corvallis acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:00\n",
      "\n",
      "Soup objects for Oregon:eastoregon acquired.  Waiting for next region...\n",
      "Process will now finish by 03:30:00\n",
      "\n",
      "Soup objects for Oregon:eugene acquired.  Waiting for next region...\n",
      "Process will now finish by 03:29:49\n",
      "\n",
      "Soup objects for Oregon:klamath acquired.  Waiting for next region...\n",
      "Process will now finish by 03:29:49\n",
      "\n",
      "Soup objects for Oregon:medford acquired.  Waiting for next region...\n",
      "Process will now finish by 03:29:45\n",
      "\n",
      "Soup objects for Oregon:oregoncoast acquired.  Waiting for next region...\n",
      "Process will now finish by 03:29:45\n",
      "\n",
      "Post number 10 in ('Oregon', 'portland') is being extracted.\n",
      "Post number 20 in ('Oregon', 'portland') is being extracted.\n",
      "Post number 30 in ('Oregon', 'portland') is being extracted.\n",
      "Post number 40 in ('Oregon', 'portland') is being extracted.\n",
      "Post number 50 in ('Oregon', 'portland') is being extracted.\n",
      "Post number 60 in ('Oregon', 'portland') is being extracted.\n",
      "Post number 70 in ('Oregon', 'portland') is being extracted.\n",
      "Post number 80 in ('Oregon', 'portland') is being extracted.\n",
      "Soup objects for Oregon:portland acquired.  Waiting for next region...\n",
      "Process will now finish by 03:27:18\n",
      "\n",
      "Soup objects for Oregon:roseburg acquired.  Waiting for next region...\n",
      "Process will now finish by 03:27:18\n",
      "\n",
      "Soup objects for Oregon:salem acquired.  Waiting for next region...\n",
      "Process will now finish by 03:27:14\n",
      "\n",
      "Soup objects for Pennsylvania:altoona acquired.  Waiting for next region...\n",
      "Process will now finish by 03:27:14\n",
      "\n",
      "Soup objects for Pennsylvania:chambersburg acquired.  Waiting for next region...\n",
      "Process will now finish by 03:27:14\n",
      "\n",
      "Soup objects for Pennsylvania:erie acquired.  Waiting for next region...\n",
      "Process will now finish by 03:27:14\n",
      "\n",
      "Soup objects for Pennsylvania:harrisburg acquired.  Waiting for next region...\n",
      "Process will now finish by 03:27:10\n",
      "\n",
      "Soup objects for Pennsylvania:lancaster acquired.  Waiting for next region...\n",
      "Process will now finish by 03:27:10\n",
      "\n",
      "Soup objects for Pennsylvania:allentown acquired.  Waiting for next region...\n",
      "Process will now finish by 03:27:08\n",
      "\n",
      "Soup objects for Pennsylvania:meadville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:27:08\n",
      "\n",
      "Post number 10 in ('Pennsylvania', 'philadelphia') is being extracted.\n",
      "Post number 20 in ('Pennsylvania', 'philadelphia') is being extracted.\n",
      "Post number 30 in ('Pennsylvania', 'philadelphia') is being extracted.\n",
      "Post number 40 in ('Pennsylvania', 'philadelphia') is being extracted.\n",
      "Post number 50 in ('Pennsylvania', 'philadelphia') is being extracted.\n",
      "Post number 60 in ('Pennsylvania', 'philadelphia') is being extracted.\n",
      "Post number 70 in ('Pennsylvania', 'philadelphia') is being extracted.\n",
      "Post number 80 in ('Pennsylvania', 'philadelphia') is being extracted.\n",
      "Post number 90 in ('Pennsylvania', 'philadelphia') is being extracted.\n",
      "Post number 100 in ('Pennsylvania', 'philadelphia') is being extracted.\n",
      "Post number 110 in ('Pennsylvania', 'philadelphia') is being extracted.\n",
      "Soup objects for Pennsylvania:philadelphia acquired.  Waiting for next region...\n",
      "Process will now finish by 03:23:27\n",
      "\n",
      "Post number 10 in ('Pennsylvania', 'pittsburgh') is being extracted.\n",
      "Soup objects for Pennsylvania:pittsburgh acquired.  Waiting for next region...\n",
      "Process will now finish by 03:23:03\n",
      "\n",
      "Soup objects for Pennsylvania:poconos acquired.  Waiting for next region...\n",
      "Process will now finish by 03:23:01\n",
      "\n",
      "Soup objects for Pennsylvania:reading acquired.  Waiting for next region...\n",
      "Process will now finish by 03:23:01\n",
      "\n",
      "Soup objects for Pennsylvania:scranton acquired.  Waiting for next region...\n",
      "Process will now finish by 03:23:01\n",
      "\n",
      "Soup objects for Pennsylvania:pennstate acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:57\n",
      "\n",
      "Soup objects for Pennsylvania:williamsport acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:57\n",
      "\n",
      "Soup objects for Pennsylvania:york acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:57\n",
      "\n",
      "Post number 10 in ('Rhode Island', 'providence') is being extracted.\n",
      "Soup objects for Rhode Island:providence acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:36\n",
      "\n",
      "Soup objects for South Carolina:charleston acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:34\n",
      "\n",
      "Soup objects for South Carolina:columbia acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:32\n",
      "\n",
      "Soup objects for South Carolina:florencesc acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:32\n",
      "\n",
      "Soup objects for South Carolina:greenville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:26\n",
      "\n",
      "Soup objects for South Carolina:hiltonhead acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:24\n",
      "\n",
      "Soup objects for South Carolina:myrtlebeach acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:22\n",
      "\n",
      "Soup objects for South Dakota:nesd acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:22\n",
      "\n",
      "Soup objects for South Dakota:csd acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:22\n",
      "\n",
      "Soup objects for South Dakota:rapidcity acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:22\n",
      "\n",
      "Soup objects for South Dakota:siouxfalls acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:22\n",
      "\n",
      "Soup objects for South Dakota:sd acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:17\n",
      "\n",
      "Soup objects for Tennessee:chattanooga acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:17\n",
      "\n",
      "Soup objects for Tennessee:clarksville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:17\n",
      "\n",
      "Soup objects for Tennessee:cookeville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:17\n",
      "\n",
      "Soup objects for Tennessee:jacksontn acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:17\n",
      "\n",
      "Soup objects for Tennessee:knoxville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:17\n",
      "\n",
      "Soup objects for Tennessee:memphis acquired.  Waiting for next region...\n",
      "Process will now finish by 03:22:09\n",
      "\n",
      "Post number 10 in ('Tennessee', 'nashville') is being extracted.\n",
      "Soup objects for Tennessee:nashville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:21:40\n",
      "\n",
      "Soup objects for Tennessee:tricities acquired.  Waiting for next region...\n",
      "Process will now finish by 03:21:40\n",
      "\n",
      "Soup objects for Texas:abilene acquired.  Waiting for next region...\n",
      "Process will now finish by 03:21:40\n",
      "\n",
      "Soup objects for Texas:amarillo acquired.  Waiting for next region...\n",
      "Process will now finish by 03:21:40\n",
      "\n",
      "Post number 10 in ('Texas', 'austin') is being extracted.\n",
      "Post number 20 in ('Texas', 'austin') is being extracted.\n",
      "Post number 30 in ('Texas', 'austin') is being extracted.\n",
      "Post number 40 in ('Texas', 'austin') is being extracted.\n",
      "Post number 50 in ('Texas', 'austin') is being extracted.\n",
      "Post number 60 in ('Texas', 'austin') is being extracted.\n",
      "Post number 70 in ('Texas', 'austin') is being extracted.\n",
      "Soup objects for Texas:austin acquired.  Waiting for next region...\n",
      "Process will now finish by 03:19:12\n",
      "\n",
      "Soup objects for Texas:beaumont acquired.  Waiting for next region...\n",
      "Process will now finish by 03:19:12\n",
      "\n",
      "Soup objects for Texas:brownsville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:19:12\n",
      "\n",
      "Soup objects for Texas:collegestation acquired.  Waiting for next region...\n",
      "Process will now finish by 03:19:06\n",
      "\n",
      "Soup objects for Texas:corpuschristi acquired.  Waiting for next region...\n",
      "Process will now finish by 03:19:06\n",
      "\n",
      "Post number 10 in ('Texas', 'dallas') is being extracted.\n",
      "Post number 20 in ('Texas', 'dallas') is being extracted.\n",
      "Post number 30 in ('Texas', 'dallas') is being extracted.\n",
      "Post number 40 in ('Texas', 'dallas') is being extracted.\n",
      "Post number 50 in ('Texas', 'dallas') is being extracted.\n",
      "Post number 60 in ('Texas', 'dallas') is being extracted.\n",
      "Post number 70 in ('Texas', 'dallas') is being extracted.\n",
      "Post number 80 in ('Texas', 'dallas') is being extracted.\n",
      "Post number 90 in ('Texas', 'dallas') is being extracted.\n",
      "Post number 100 in ('Texas', 'dallas') is being extracted.\n",
      "Post number 110 in ('Texas', 'dallas') is being extracted.\n",
      "Post number 120 in ('Texas', 'dallas') is being extracted.\n",
      "Soup objects for Texas:dallas acquired.  Waiting for next region...\n",
      "Process will now finish by 03:15:18\n",
      "\n",
      "Soup objects for Texas:nacogdoches acquired.  Waiting for next region...\n",
      "Process will now finish by 03:15:18\n",
      "\n",
      "Soup objects for Texas:delrio acquired.  Waiting for next region...\n",
      "Process will now finish by 03:15:18\n",
      "\n",
      "Soup objects for Texas:elpaso acquired.  Waiting for next region...\n",
      "Process will now finish by 03:15:13\n",
      "\n",
      "Soup objects for Texas:galveston acquired.  Waiting for next region...\n",
      "Process will now finish by 03:15:13\n",
      "\n",
      "Post number 10 in ('Texas', 'houston') is being extracted.\n",
      "Post number 20 in ('Texas', 'houston') is being extracted.\n",
      "Post number 30 in ('Texas', 'houston') is being extracted.\n",
      "Post number 40 in ('Texas', 'houston') is being extracted.\n",
      "Post number 50 in ('Texas', 'houston') is being extracted.\n",
      "Post number 60 in ('Texas', 'houston') is being extracted.\n",
      "Post number 70 in ('Texas', 'houston') is being extracted.\n",
      "Post number 80 in ('Texas', 'houston') is being extracted.\n",
      "Post number 90 in ('Texas', 'houston') is being extracted.\n",
      "Post number 100 in ('Texas', 'houston') is being extracted.\n",
      "Post number 110 in ('Texas', 'houston') is being extracted.\n",
      "Soup objects for Texas:houston acquired.  Waiting for next region...\n",
      "Process will now finish by 03:11:25\n",
      "\n",
      "Soup objects for Texas:killeen acquired.  Waiting for next region...\n",
      "Process will now finish by 03:11:22\n",
      "\n",
      "Soup objects for Texas:laredo acquired.  Waiting for next region...\n",
      "Process will now finish by 03:11:22\n",
      "\n",
      "Soup objects for Texas:lubbock acquired.  Waiting for next region...\n",
      "Process will now finish by 03:11:22\n",
      "\n",
      "Soup objects for Texas:mcallen acquired.  Waiting for next region...\n",
      "Process will now finish by 03:11:22\n",
      "\n",
      "Soup objects for Texas:odessa acquired.  Waiting for next region...\n",
      "Process will now finish by 03:11:20\n",
      "\n",
      "Soup objects for Texas:sanangelo acquired.  Waiting for next region...\n",
      "Process will now finish by 03:11:20\n",
      "\n",
      "Post number 10 in ('Texas', 'sanantonio') is being extracted.\n",
      "Post number 20 in ('Texas', 'sanantonio') is being extracted.\n",
      "Post number 30 in ('Texas', 'sanantonio') is being extracted.\n",
      "Post number 40 in ('Texas', 'sanantonio') is being extracted.\n",
      "Post number 50 in ('Texas', 'sanantonio') is being extracted.\n",
      "Soup objects for Texas:sanantonio acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:35\n",
      "\n",
      "Soup objects for Texas:sanmarcos acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:35\n",
      "\n",
      "Soup objects for Texas:bigbend acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:35\n",
      "\n",
      "Soup objects for Texas:texoma acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:35\n",
      "\n",
      "Soup objects for Texas:easttexas acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:35\n",
      "\n",
      "Soup objects for Texas:victoriatx acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:35\n",
      "\n",
      "Soup objects for Texas:waco acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:35\n",
      "\n",
      "Soup objects for Texas:wichitafalls acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:35\n",
      "\n",
      "Soup objects for Utah:logan acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:35\n",
      "\n",
      "Soup objects for Utah:ogden acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:35\n",
      "\n",
      "Soup objects for Utah:provo acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:26\n",
      "\n",
      "Soup objects for Utah:saltlakecity acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:06\n",
      "\n",
      "Soup objects for Utah:stgeorge acquired.  Waiting for next region...\n",
      "Process will now finish by 03:09:03\n",
      "\n",
      "Soup objects for Vermont:vermont acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:54\n",
      "\n",
      "Soup objects for Virginia:charlottesville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:45\n",
      "\n",
      "Soup objects for Virginia:danville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:45\n",
      "\n",
      "Soup objects for Virginia:fredericksburg acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:45\n",
      "\n",
      "Soup objects for Virginia:norfolk acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:35\n",
      "\n",
      "Soup objects for Virginia:harrisonburg acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:35\n",
      "\n",
      "Soup objects for Virginia:lynchburg acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:35\n",
      "\n",
      "Soup objects for Virginia:blacksburg acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:35\n",
      "\n",
      "Soup objects for Virginia:richmond acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:18\n",
      "\n",
      "Soup objects for Virginia:roanoke acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:12\n",
      "\n",
      "Soup objects for Virginia:swva acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:12\n",
      "\n",
      "Soup objects for Virginia:winchester acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:12\n",
      "\n",
      "Soup objects for Washington:bellingham acquired.  Waiting for next region...\n",
      "Process will now finish by 03:08:07\n",
      "\n",
      "Post number 10 in ('Washington', 'kpr') is being extracted.\n",
      "Soup objects for Washington:kpr acquired.  Waiting for next region...\n",
      "Process will now finish by 03:07:34\n",
      "\n",
      "Soup objects for Washington:moseslake acquired.  Waiting for next region...\n",
      "Process will now finish by 03:07:34\n",
      "\n",
      "Soup objects for Washington:olympic acquired.  Waiting for next region...\n",
      "Process will now finish by 03:07:34\n",
      "\n",
      "Soup objects for Washington:pullman acquired.  Waiting for next region...\n",
      "Process will now finish by 03:07:33\n",
      "\n",
      "Post number 10 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 20 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 30 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 40 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 50 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 60 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 70 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 80 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 90 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 100 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 110 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 120 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 130 in ('Washington', 'seattle') is being extracted.\n",
      "Post number 140 in ('Washington', 'seattle') is being extracted.\n",
      "Soup objects for Washington:seattle acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:38\n",
      "\n",
      "Soup objects for Washington:skagit acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:37\n",
      "\n",
      "Post number 10 in ('Washington', 'spokane') is being extracted.\n",
      "Soup objects for Washington:spokane acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:18\n",
      "\n",
      "Soup objects for Washington:wenatchee acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:17\n",
      "\n",
      "Soup objects for Washington:yakima acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for West Virginia:charlestonwv acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for West Virginia:martinsburg acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for West Virginia:huntington acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for West Virginia:morgantown acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for West Virginia:wheeling acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for West Virginia:parkersburg acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for West Virginia:swv acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for West Virginia:wv acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for Wisconsin:appleton acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for Wisconsin:eauclaire acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for Wisconsin:greenbay acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for Wisconsin:janesville acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for Wisconsin:racine acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for Wisconsin:lacrosse acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:15\n",
      "\n",
      "Soup objects for Wisconsin:madison acquired.  Waiting for next region...\n",
      "Process will now finish by 03:02:00\n",
      "\n",
      "Soup objects for Wisconsin:milwaukee acquired.  Waiting for next region...\n",
      "Process will now finish by 03:01:44\n",
      "\n",
      "Soup objects for Wisconsin:northernwi acquired.  Waiting for next region...\n",
      "Process will now finish by 03:01:44\n",
      "\n",
      "Soup objects for Wisconsin:sheboygan acquired.  Waiting for next region...\n",
      "Process will now finish by 03:01:44\n",
      "\n",
      "Soup objects for Wisconsin:wausau acquired.  Waiting for next region...\n",
      "Process will now finish by 03:01:44\n",
      "\n",
      "Soup objects for Wyoming:wyoming acquired.  Waiting for next region...\n",
      "Process will now finish by 03:01:44\n",
      "\n",
      "Soup objects for Territories:micronesia acquired.  Waiting for next region...\n",
      "Process will now finish by 03:01:44\n",
      "\n",
      "Soup objects for Territories:puertorico acquired.  Waiting for next region...\n",
      "Process will now finish by 03:01:44\n",
      "\n",
      "\n",
      "Soup objects for ('Territories', 'virgin') acquired.  Process complete.\n"
     ]
    }
   ],
   "source": [
    "soup_objects_dict = {}\n",
    "\n",
    "num_posts_remaining = num_posts\n",
    "current_time = dt.datetime.now()\n",
    "max_seconds_until_finish = num_posts * 4\n",
    "max_finish_time = current_time + dt.timedelta(seconds=max_seconds_until_finish)\n",
    "\n",
    "print(F\"Current time is {current_time.strftime('%H:%M:%S')}\")\n",
    "print(F\"Process estimated to finish before {max_finish_time.strftime('%H:%M:%S')}\")\n",
    "print()\n",
    "\n",
    "for count, key in enumerate(posts_dict, start=1):\n",
    "    # Walk through each region and create a list of soup_objects to scrape from by storing them into memory.  This way we only have to send these get requests once and Craigslist doesn't ban us for sending the same https requests over and over\n",
    "    soup_objects_list = []\n",
    "    for i, post in enumerate(posts_dict[key]):\n",
    "        \n",
    "        # Impose a timer to help prevent from getting banned for too many HTTP requests in too short a time period.\n",
    "        random_int = random.randint(2,4)\n",
    "        time.sleep(random_int)\n",
    "        current_link = post.a.get('href')\n",
    "        response_object = session.get(current_link)\n",
    "        soup_object = BeautifulSoup(response_object.text, 'html.parser')\n",
    "        soup_objects_list.append(soup_object) \n",
    "        \n",
    "        # Impose condition that every 10th post will trigger something printed to the screen.  This part of the code is a long process and I wanted something to help keep track of how much progress has been made\n",
    "        if (i !=0) and ((i-1) % 10 == 9):\n",
    "            print(F\"Post number {i} in {key} is being extracted.\")\n",
    "    \n",
    "    soup_objects_dict[key] = soup_objects_list\n",
    "    if count != len(posts_dict):\n",
    "        num_posts_remaining -= len(posts_dict[key])\n",
    "        current_time = dt.datetime.now()\n",
    "        new_seconds_until_finish = num_posts_remaining * 5\n",
    "        new_max_finish_time = current_time + dt.timedelta(seconds=new_seconds_until_finish)\n",
    "        \n",
    "        state = key[0]\n",
    "        region = key[1]\n",
    "        \n",
    "        print(F\"Soup objects for {state}: {region} acquired.  Waiting for next region...\")\n",
    "        print(F\"Process will now finish by {new_max_finish_time.strftime('%H:%M:%S')}\")\n",
    "        print()\n",
    "    else:\n",
    "        print()\n",
    "        print(F\"Soup objects for {key} acquired.  Process complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde867cd-6852-41e5-ab1b-33894c159a75",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "### Extracting information from each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e0923e6-8d92-46f9-afd5-fcde738a3803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "error_list_text = []\n",
    "error_list_links = []\n",
    "\n",
    "# Walk through lists of soup objects corresponding to an individual posting for a math tutor in a given search_region.\n",
    "for search_region in soup_objects_dict:\n",
    "    # Initialize several lists to store relevant information for analysis\n",
    "    price_list = []\n",
    "    city_list = []\n",
    "    datetime_list = []\n",
    "    body_text_list = []\n",
    "    subregion_list = []\n",
    "    region_list = []\n",
    "    link_list = []\n",
    "    search_region_price_list = []\n",
    "    state_list = []\n",
    "    \n",
    "    # Walk through each soup object in the list corresponding to the search region\n",
    "    for soup in soup_objects_dict[search_region]:\n",
    "        try:\n",
    "            # Get link of post\n",
    "            link = soup.find(\"meta\", property=\"og:url\")['content']\n",
    "        except:\n",
    "            # In case a link can't be found, we add the soup object to a list to inspect later and set link to 'None', which we'll use as a filter later so Python doesn't try to scrape from them.  Without a link, we don't want to scrape though, so we pass to the next iteration of the loop.\n",
    "            link = 'None'\n",
    "            error_list_links.append(soup)\n",
    "            pass\n",
    "            #print(\"Couldn't get link\")\n",
    "            \n",
    "        try:\n",
    "            # Extract region of post from Craigslist\n",
    "            post_region = soup.find_all('li',class_='crumb area')[0].find('a').get_text()\n",
    "            if post_region=='sf bay area':\n",
    "                post_region = 'sfbay'\n",
    "            else:\n",
    "                post_region = post_region.replace(' ', '')\n",
    "            post_region = post_region.lower()\n",
    "            \n",
    "        except:\n",
    "            post_region = 'region not found'\n",
    "        \n",
    "        # Get text of postingbody of the post and remove unwanted text.\n",
    "        try:\n",
    "            text = soup.find('section', id='postingbody').get_text()\n",
    "            text = text.replace(u'\\xa0', u' ')\n",
    "            # We do this so that we can use ; as a delimiter when copying data from a CSV file into a SQL database later.\n",
    "            text = text.replace(';', ',') \n",
    "            # We do this because one post in particular had this text and was giving me trouble.  The best way I could find to handle it was to remove the text.\n",
    "            text = text.replace('QR Code Link to This Post', '') \n",
    "\n",
    "        except:\n",
    "            error_list_text.append(soup)\n",
    "            text = 'text not found'\n",
    "            #body_text_list.append(text)\n",
    "            #print(\"Couldn't get text\")\n",
    "            \n",
    "        state = search_region[0]\n",
    "        state_list.append(state)\n",
    "        region_list.append(post_region)\n",
    "        link_list.append(link)\n",
    "        body_text_list.append(text)\n",
    "\n",
    "        # Use regular expressions to find all instances of prices in the text\n",
    "        #old_prices = re.findall('(?:[\\$]{1}[,\\d]+.?\\d*)', text)\n",
    "        old_prices = re.findall('(?:[\\$]{1}[,\\d]+\\d*)', text)\n",
    "        # Alternative, if trying to capture decimals \n",
    "        # ^(?:\\${1}\\d+(?:,\\d{3})*(?:\\.{1}\\d{2}){0,1})?$\n",
    "\n",
    "        # Intialize empty list to store the new prices after processing old prices.\n",
    "        new_prices = []\n",
    "        #print(F\"Initialized new_prices: {new_prices}\")\n",
    "        \n",
    "        #Walk through each price in the post.\n",
    "        for price in old_prices:\n",
    "            # Clean unwanted characters.\n",
    "            price = price.replace('$', '')\n",
    "            price = price.replace('/', '')\n",
    "            price = price.replace('!', '')\n",
    "            price = price.replace('h', '')\n",
    "            price = price.replace('.', '')\n",
    "            price = price.replace(')', '')\n",
    "            price = price.replace(',', '')\n",
    "            price = price.replace('>', '')\n",
    "            price = price.rstrip()   \n",
    "            # Some tutors give prices as a range ie '$30-40'.  In order to work with this data, I split based on the hyphen, then I can use each price individually.\n",
    "            split_prices = price.split('-')\n",
    "        #print(F\"Here are the old_prices: {old_prices}\")\n",
    "        #print(F\"Here are the split_prices: {split_prices}\")\n",
    "\n",
    "            # Walk through the split price, if a price had no hypen, the split_prices has one price in it that we perform processing on.  If a hyphen was present, then we have multiple prices that we iterate over and process\n",
    "            for p in split_prices:\n",
    "                # Only proceed if the post contained prices, ie if p is a non-empty string.\n",
    "                if len(p)!=0:\n",
    "                    try:\n",
    "                        # Convert string price to int.\n",
    "                        new_int = int(p)\n",
    "                        # Ignore prices which are too high to be reasonable.  Some posts included scholarship amounts as ways for a tutor to boast about their abilities, but this will only allow dollar amounts that are reasonable through.\n",
    "                        if new_int <= 200:\n",
    "                            new_prices.append(new_int)\n",
    "\n",
    "                    except:\n",
    "                        # Show which prices aren't able to convert to an int and the post they came from so we can isolate and fix the issue if need be.\n",
    "                        print(F'Error converting this price: {p}')\n",
    "                        print(split_prices)\n",
    "                        print()\n",
    "                        print('Here is the text of the post:')\n",
    "                        print()\n",
    "                        print(text)\n",
    "                        print('-'*50)\n",
    "                        print()\n",
    "                        # Set prices that can't be covered to NaN so the process can finish.\n",
    "                        new_prices.append(np.nan) \n",
    "        #print(F\"Here are the processed new_prices: {new_prices}\")\n",
    "                #print(len(new_prices))\n",
    "\n",
    "\n",
    "        # Append all prices from the post to a separate list, in case we need to isolate issues and fix them later.\n",
    "\n",
    "        search_region_price_list.append(new_prices)\n",
    "\n",
    "        # For posts that had no prices listed, we use null\n",
    "        if len(new_prices)==0:\n",
    "            price_list.append(np.nan)\n",
    "        # For posts that had a single price, we use it.\n",
    "        elif len(new_prices)==1:\n",
    "            price_list.append(new_prices[0])\n",
    "        # For posts that contained two prices, we average them.  This isn't a perfect system but is mainly targeted to posts that give a range of prices (ie $25-30).\n",
    "        elif len(new_prices)==2:\n",
    "            avg_price_2 = np.average(new_prices)\n",
    "            price_list.append(avg_price_2)\n",
    "        # If a post has more than 3 prices, we append null.  We'll have to inspect these posts manually and deal with them later.\n",
    "        else:\n",
    "            price_list.append(np.nan)\n",
    "        #print(price_list)\n",
    "\n",
    "\n",
    "        # Get city information for each posting.\n",
    "        try:\n",
    "            city = soup.find(class_='postingtitletext').small.get_text()\n",
    "\n",
    "            # Because of the way CL operates, one has to choose a city from a radio button list, that CL provides, when one creates a post to offer a service, however later, there's a field where they can type in any city they want.  Many people will randomly choose a city from the radio button list, but then  post their city as \"online\".  This makes sure we capture them. \n",
    "            re_pattern = re.compile('online')\n",
    "            online_flag = re.search(re_pattern, city.lower())\n",
    "            if online_flag:\n",
    "                city_list.append('Online')\n",
    "            else:\n",
    "                # Strip out leading and trailing white spaces, replace parentheses, and capitalize each word in the str.\n",
    "                city = city.strip()\n",
    "                city = city.replace('(', '').replace(')', '')        \n",
    "                city = city.title()\n",
    "                city_list.append(city)\n",
    "        except:\n",
    "            # If a post has no city information, use None\n",
    "            city_list.append('no city found')\n",
    "\n",
    "        # Extract subregion of Craigslist that the post was made in. This will allow for comparison of prices across different cities within the same metropolitan sub_region.\n",
    "        try:\n",
    "            subregion = soup.find_all('li', class_='crumb subarea')[0].find('a').get_text()\n",
    "            subregion = subregion.title()\n",
    "            subregion_list.append(subregion)\n",
    "        except:\n",
    "            subregion_list.append('no subregion found')\n",
    "\n",
    "\n",
    "        # Extract time the posting was made.\n",
    "        try:\n",
    "            dt_object = soup.find('time')['datetime']\n",
    "            datetime_list.append(dt_object)\n",
    "        except:\n",
    "            datetime_list.append('time of post unavailable')\n",
    "    # else:\n",
    "    #     pass\n",
    "    #print(price_list)\n",
    "    # Create temporary df to store results for each region\n",
    "    temp_df = pd.DataFrame(data=zip(datetime_list,\n",
    "                                    link_list, \n",
    "                                    price_list, \n",
    "                                    city_list, \n",
    "                                    subregion_list, \n",
    "                                    region_list,\n",
    "                                    state_list,\n",
    "                                    body_text_list,\n",
    "                                    search_region_price_list),\n",
    "                        columns=['date_posted', \n",
    "                                 'link', \n",
    "                                 'price', \n",
    "                                 'city', \n",
    "                                 'subregion', \n",
    "                                 'region',\n",
    "                                 'state',\n",
    "                                 'post_text',\n",
    "                                 'price_list']\n",
    "                          )\n",
    "    df_list.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nearby-california",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 149)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for errors in getting text from a post, or from getting the URL of a post.\n",
    "len(error_list_text), len(error_list_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "endangered-premiere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4419, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the dfs for each region into one larger df and check its shape.\n",
    "concat_df = pd.concat(df_list, ignore_index=True)\n",
    "concat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7db54325-023a-4406-b057-2950069c50ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_posted</th>\n",
       "      <th>link</th>\n",
       "      <th>price</th>\n",
       "      <th>city</th>\n",
       "      <th>subregion</th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>post_text</th>\n",
       "      <th>price_list</th>\n",
       "      <th>posts_scraped_on</th>\n",
       "      <th>US_region</th>\n",
       "      <th>Division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03T14:09:30-0600</td>\n",
       "      <td>https://bham.craigslist.org/lss/d/birmingham-m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>no subregion found</td>\n",
       "      <td>birmingham,al</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>\\n\\n\\n\\n\\nHi Im Tiffany and I along with 3 of...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>South</td>\n",
       "      <td>East South Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-17T06:46:21-0600</td>\n",
       "      <td>https://bham.craigslist.org/lss/d/birmingham-t...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>no city found</td>\n",
       "      <td>no subregion found</td>\n",
       "      <td>birmingham,al</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>\\n\\n\\n\\n\\nAt OmniKen Edu. we offer many differ...</td>\n",
       "      <td>[25]</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>South</td>\n",
       "      <td>East South Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03T14:03:45-0600</td>\n",
       "      <td>https://bham.craigslist.org/lss/d/adger-12-all...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no city found</td>\n",
       "      <td>no subregion found</td>\n",
       "      <td>birmingham,al</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>\\n\\n\\n\\n\\nOur tutors are real full-time teache...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>South</td>\n",
       "      <td>East South Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-24T15:52:41-0600</td>\n",
       "      <td>https://shoals.craigslist.org/lss/d/anderson-1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no city found</td>\n",
       "      <td>no subregion found</td>\n",
       "      <td>theshoals</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>\\n\\n\\n\\n\\nOur tutors are real full-time teache...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>South</td>\n",
       "      <td>East South Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-03T14:07:09-0600</td>\n",
       "      <td>https://huntsville.craigslist.org/lss/d/owens-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>no subregion found</td>\n",
       "      <td>huntsville</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>\\n\\n\\n\\n\\nHi Im Tiffany and I along with 3 of...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>South</td>\n",
       "      <td>East South Central</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_posted  \\\n",
       "0  2022-01-03T14:09:30-0600   \n",
       "1  2022-01-17T06:46:21-0600   \n",
       "2  2022-01-03T14:03:45-0600   \n",
       "3  2022-01-24T15:52:41-0600   \n",
       "4  2022-01-03T14:07:09-0600   \n",
       "\n",
       "                                                link  price           city  \\\n",
       "0  https://bham.craigslist.org/lss/d/birmingham-m...    NaN     Birmingham   \n",
       "1  https://bham.craigslist.org/lss/d/birmingham-t...   25.0  no city found   \n",
       "2  https://bham.craigslist.org/lss/d/adger-12-all...    NaN  no city found   \n",
       "3  https://shoals.craigslist.org/lss/d/anderson-1...    NaN  no city found   \n",
       "4  https://huntsville.craigslist.org/lss/d/owens-...    NaN     Huntsville   \n",
       "\n",
       "            subregion         region    state  \\\n",
       "0  no subregion found  birmingham,al  Alabama   \n",
       "1  no subregion found  birmingham,al  Alabama   \n",
       "2  no subregion found  birmingham,al  Alabama   \n",
       "3  no subregion found      theshoals  Alabama   \n",
       "4  no subregion found     huntsville  Alabama   \n",
       "\n",
       "                                           post_text price_list  \\\n",
       "0  \\n\\n\\n\\n\\nHi Im Tiffany and I along with 3 of...         []   \n",
       "1  \\n\\n\\n\\n\\nAt OmniKen Edu. we offer many differ...       [25]   \n",
       "2  \\n\\n\\n\\n\\nOur tutors are real full-time teache...         []   \n",
       "3  \\n\\n\\n\\n\\nOur tutors are real full-time teache...         []   \n",
       "4  \\n\\n\\n\\n\\nHi Im Tiffany and I along with 3 of...         []   \n",
       "\n",
       "  posts_scraped_on US_region            Division  \n",
       "0       2022-02-03     South  East South Central  \n",
       "1       2022-02-03     South  East South Central  \n",
       "2       2022-02-03     South  East South Central  \n",
       "3       2022-02-03     South  East South Central  \n",
       "4       2022-02-03     South  East South Central  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_regions = pd.read_csv('../craigslist_web_scraper/census-regions/us_census_regions.csv')\n",
    "concat_df_w_regions = concat_df.merge(right=census_regions[['State','Region','Division']], how='left', left_on='state', right_on='State')\n",
    "\n",
    "concat_df_w_regions.drop(labels='State', axis=1, inplace=True)\n",
    "concat_df_w_regions.rename(columns={'Region':'US_region'}, inplace=True)\n",
    "\n",
    "concat_df_w_regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "01a419d7-d825-425b-bc68-859af9d786a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_posted</th>\n",
       "      <th>link</th>\n",
       "      <th>price</th>\n",
       "      <th>city</th>\n",
       "      <th>subregion</th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>post_text</th>\n",
       "      <th>price_list</th>\n",
       "      <th>posts_scraped_on</th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "      <th>Division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4418</th>\n",
       "      <td>2022-01-31T13:42:05-0400</td>\n",
       "      <td>https://virgin.craigslist.org/sks/d/michael-ch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Thomas</td>\n",
       "      <td>no subregion found</td>\n",
       "      <td>virginislands</td>\n",
       "      <td>Territories</td>\n",
       "      <td>\\n\\n\\n\\n\\nTutor for high school, middle school...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date_posted  \\\n",
       "4418  2022-01-31T13:42:05-0400   \n",
       "\n",
       "                                                   link  price        city  \\\n",
       "4418  https://virgin.craigslist.org/sks/d/michael-ch...    NaN  St. Thomas   \n",
       "\n",
       "               subregion         region        state  \\\n",
       "4418  no subregion found  virginislands  Territories   \n",
       "\n",
       "                                              post_text price_list  \\\n",
       "4418  \\n\\n\\n\\n\\nTutor for high school, middle school...         []   \n",
       "\n",
       "     posts_scraped_on State Region Division  \n",
       "4418       2022-02-03   NaN    NaN      NaN  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df_w_regions[concat_df_w_regions['Region'].isna()==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb5866-a4e4-452f-821d-274763fd9a45",
   "metadata": {},
   "source": [
    "### Dropping Duplicate posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spanish-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     2875\n",
       "False    1544\n",
       "Name: post_text, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get date of html request to label our output with.\n",
    "date_of_html_request = str(dt.date.today())\n",
    "\n",
    "# Include the date posts were scraped on to track tutoring prices over time.\n",
    "concat_df['posts_scraped_on'] = date_of_html_request\n",
    "\n",
    "# Count duplicates.\n",
    "concat_df['post_text'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52774d13-f298-4586-be24-e5f33cf0e8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1544, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find indices of rows that have exactly the same post_text, then drop them and reset indices.\n",
    "duplicate_indices = concat_df[concat_df['post_text'].duplicated()==True].index\n",
    "df_exact_txt_dropped = concat_df.drop(index=duplicate_indices)\n",
    "df_exact_txt_dropped = df_exact_txt_dropped.reset_index(drop=True)\n",
    "df_exact_txt_dropped['len_of_price_list']=df_exact_txt_dropped['price_list'].apply(lambda x: len(x))\n",
    "df_exact_txt_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e30cd031-8c4b-4907-86b5-77467325ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize each posts' text and calculate the cosine similarity of each post against all other posts to determine which are duplicates\n",
    "## https://kanoki.org/2018/12/27/text-matching-cosine-similarity/\n",
    "text_for_comparison = df_exact_txt_dropped['post_text']\n",
    "vect = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "tfidf = vect.fit_transform(text_for_comparison)\n",
    "pairwise_similarity = tfidf * tfidf.T\n",
    "\n",
    "# Store results in a 2D NumPy array\n",
    "pairwise_array = pairwise_similarity.toarray()\n",
    "\n",
    "# The diagonal of our array is the similarity of a post to itself, which we fill will null so that these are essentially ignored\n",
    "np.fill_diagonal(pairwise_array, np.nan)\n",
    "\n",
    "# Many people on CL will change their posting in ways to avoid CL flagging them as duplicates for removal.  This finds all posts above a certain similarity threshold.\n",
    "argwhere_array = np.argwhere(pairwise_array > 0.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b6737df-7701-4f01-a968-898e60b48476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In order to remove the duplicates, we need to restructure our 2D NumPy array in such a way that the first column is the index of the post that has a duplicate and the second column contains a list of the indices of the duplicate post(s).\n",
    "df_row_idx = []\n",
    "dup_row_idx = []\n",
    "for row in argwhere_array:\n",
    "    current_idx = row[0]\n",
    "    #print(F\"Current row: {row}, Current idx: {current_idx}\")\n",
    "    duplicate_list = []\n",
    "    if current_idx in df_row_idx:\n",
    "        continue\n",
    "    else:\n",
    "        df_row_idx.append(current_idx)\n",
    "    for other_row in argwhere_array:\n",
    "        other_idx = other_row[1]\n",
    "        #print(F\"Here's the other_row: {other_row}, Other idx: {other_idx}\")\n",
    "        if current_idx == other_row[0]:\n",
    "            duplicate_list.append(other_idx)\n",
    "    #print(F\"This is the current dup_list: {duplicate_list}\")\n",
    "    #print()\n",
    "    dup_row_idx.append(duplicate_list)\n",
    "#list(zip(df_row_idx, dup_row_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48949840-611f-496c-b1a3-adf81253b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rancher/opt/anaconda3/envs/ox/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "/Users/rancher/opt/anaconda3/envs/ox/lib/python3.9/site-packages/pandas/core/internals/blocks.py:937: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr_value = np.asarray(value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                    [4, 11, 30]\n",
       "1                    [884, 1025]\n",
       "2       [3, 7, 8, 624, 842, 936]\n",
       "3       [2, 7, 8, 624, 842, 936]\n",
       "4                    [0, 11, 30]\n",
       "                  ...           \n",
       "1539                      [1539]\n",
       "1540                      [1540]\n",
       "1541            [712, 713, 1537]\n",
       "1542                      [1542]\n",
       "1543                      [1543]\n",
       "Name: match, Length: 1544, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create match column in our df, which is initialized as a list of all indices in our df.  This means for each row, the value of the match column is the row index.  Convert that index value to a list, so we can iterate over it in future steps\n",
    "df_exact_txt_dropped['match'] = np.array(df_exact_txt_dropped.index.values, dtype='object')\n",
    "df_exact_txt_dropped['match'] = df_exact_txt_dropped['match'].apply(lambda x: [x])\n",
    "\n",
    "# For rows that are duplicate postings, we overwrite the value of match column to contain the indices of all other rows that contain duplicated text\n",
    "match_col_idx = df_exact_txt_dropped.columns.get_loc('match')\n",
    "df_exact_txt_dropped.iloc[df_row_idx, match_col_idx] = dup_row_idx\n",
    "#df_exact_txt_dropped['match'] = df_exact_txt_dropped['match'].apply(lambda x: [x])\n",
    "\n",
    "df_exact_txt_dropped['match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ae76bd3-20ac-443b-b254-ad184673580b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "\n",
    "df_no_dups = df_exact_txt_dropped.copy()\n",
    "\n",
    "# Iterate over each row and remove all rows that have duplicated text\n",
    "for i, row in df_no_dups.iterrows():\n",
    "    indices.append(i)\n",
    "    drop_idx = []\n",
    "    #print(i, row['match'])\n",
    "    try:\n",
    "        for item in row['match']:\n",
    "            if item not in indices:\n",
    "                drop_idx.append(item)\n",
    "        df_no_dups = df_no_dups.drop(index=drop_idx, errors=\"ignore\")\n",
    "    except Exception as e:\n",
    "        #print(i, item, row['match'])\n",
    "        print(e, i, item, row['match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24427708-b9e4-4b53-b0f2-0f2ec6962382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1544, 12), (792, 12))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape when we dropped posts with exactly the same post_text against the shape after we dropped text deemed similar by cosine similarity \n",
    "df_exact_txt_dropped.shape, df_no_dups.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625aecfe-7df2-4674-ab98-60f96efa8e1b",
   "metadata": {},
   "source": [
    "### Dropping posts that contained no prices, which aren't helpful for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "434e8abf-7b66-4232-9059-93272966788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the len of price_list to find posts that contained no prices\n",
    "df_no_dups['len_of_price_list'] = df_no_dups['price_list'].apply(lambda x: len(x))\n",
    "\n",
    "# Filter out results that don't have a price and reset indices.\n",
    "df_with_prices = df_no_dups[df_no_dups['len_of_price_list'] > 0]\n",
    "df_with_prices = df_with_prices.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "273eca8b-0205-4458-9536-0cebd167096e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "residential-horse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 4419 posts, there were 792 that were unique, or 17.92%.\n",
      "Out of those, there were 363 posts that had prices included.\n",
      "Only 8.21% of the posts that we scraped remain.\n"
     ]
    }
   ],
   "source": [
    "unique_posts_count = len(df_no_dups)\n",
    "post_with_prices_count = len(df_with_prices)\n",
    "num_posts = len(concat_df)\n",
    "\n",
    "percent_unique = unique_posts_count / num_posts * 100\n",
    "percent_with_prices = post_with_prices_count / num_posts * 100\n",
    "\n",
    "print(F\"Out of {num_posts} posts, there were {unique_posts_count} that were unique, or {percent_unique:.2f}%.\")\n",
    "print(F\"Out of those, there were {post_with_prices_count} posts that had prices included.\")\n",
    "\n",
    "print(F\"Only {percent_with_prices:.2f}% of the posts that we scraped remain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1e238-96b4-4372-85b7-ed1e1f72c711",
   "metadata": {},
   "source": [
    "### Extracting complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd44d13c-b579-42de-90bd-c9607b52b58e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# *Transforming* Craigslist data: Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a50fc12-b7cf-4294-8336-625a662c2109",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Are there any posts that might need manual cleaning?  This would include:\n",
    "* Posts that had 3 or more prices and were marked as null\n",
    "* Posts where the price wasn't able to convert from `str` -> `int` and were marked as null during pre-processing\n",
    "\n",
    "There are the entries that were marked as `Null`.  Let's investigate them manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5118dd4a-b106-4d3c-830b-42db498f7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[25, 30, 50, 50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[40, 40, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[20, 25, 30, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[30, 35, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[50, 65, 80]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[20, 30, 20, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[50, 100, 135]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[30, 45, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[30, 50, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[20, 80, 90, 120]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[65, 55, 55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[40, 80, 40, 10, 40, 30, 40, 80, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[50, 10, 50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[60, 50, 75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[20, 25, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[50, 50, 35, 39, 25, 55, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[30, 30, 60, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 40, 50, 60, 75, 75, 95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[25, 50, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[25, 35, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[30, 30, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 35, 55, 55, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[30, 45, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 50, 65, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[60, 60, 50, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[90, 60, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[25, 40, 55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[40, 40, 45, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[30, 50, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[45, 50, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[10, 20, 60, 170, 10, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[30, 40, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 35, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[40, 75, 35, 65]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[30, 40, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[5, 10, 10, 5, 5, 80, 80, 100, 150]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[100, 115, 130, 65, 30, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[100, 115, 130, 65, 30, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[45, 50, 55, 50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[100, 115, 130, 65, 30, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[45, 45, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[30, 30, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[10, 5, 5, 100, 150]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[15, 20, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[35, 30, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[30, 10, 20, 16, 5, 5, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[196, 50, 105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[40, 50, 50, 65, 70]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price                             price_list\n",
       "6      NaN                       [25, 30, 50, 50]\n",
       "8      NaN                           [40, 40, 40]\n",
       "10     NaN                       [20, 25, 30, 30]\n",
       "11     NaN                           [30, 35, 45]\n",
       "15     NaN                           [50, 65, 80]\n",
       "16     NaN                       [20, 30, 20, 30]\n",
       "18     NaN                         [50, 100, 135]\n",
       "31     NaN                           [30, 45, 60]\n",
       "32     NaN                           [30, 50, 30]\n",
       "39     NaN                      [20, 80, 90, 120]\n",
       "47     NaN                           [65, 55, 55]\n",
       "48     NaN  [40, 80, 40, 10, 40, 30, 40, 80, 100]\n",
       "62     NaN                           [50, 10, 50]\n",
       "66     NaN                           [60, 50, 75]\n",
       "67     NaN                           [20, 25, 30]\n",
       "69     NaN           [50, 50, 35, 39, 25, 55, 30]\n",
       "76     NaN                       [30, 30, 60, 90]\n",
       "79     NaN           [35, 40, 50, 60, 75, 75, 95]\n",
       "84     NaN                           [25, 50, 25]\n",
       "93     NaN                           [25, 35, 20]\n",
       "94     NaN                           [30, 30, 15]\n",
       "97     NaN                   [35, 35, 55, 55, 45]\n",
       "102    NaN                           [30, 45, 60]\n",
       "104    NaN                       [35, 50, 65, 20]\n",
       "112    NaN                       [60, 60, 50, 60]\n",
       "113    NaN                           [90, 60, 40]\n",
       "131    NaN                           [25, 40, 55]\n",
       "134    NaN                       [40, 40, 45, 45]\n",
       "152    NaN                           [30, 50, 60]\n",
       "155    NaN                           [45, 50, 45]\n",
       "169    NaN              [10, 20, 60, 170, 10, 20]\n",
       "180    NaN                           [30, 40, 60]\n",
       "187    NaN                           [35, 35, 35]\n",
       "192    NaN                       [40, 75, 35, 65]\n",
       "197    NaN                           [30, 40, 60]\n",
       "211    NaN    [5, 10, 10, 5, 5, 80, 80, 100, 150]\n",
       "223    NaN            [100, 115, 130, 65, 30, 60]\n",
       "229    NaN            [100, 115, 130, 65, 30, 60]\n",
       "234    NaN                       [45, 50, 55, 50]\n",
       "254    NaN            [100, 115, 130, 65, 30, 60]\n",
       "257    NaN                           [45, 45, 35]\n",
       "270    NaN                           [30, 30, 30]\n",
       "281    NaN                   [10, 5, 5, 100, 150]\n",
       "294    NaN                           [15, 20, 25]\n",
       "304    NaN                           [35, 30, 20]\n",
       "317    NaN              [30, 10, 20, 16, 5, 5, 5]\n",
       "338    NaN                         [196, 50, 105]\n",
       "347    NaN                   [40, 50, 50, 65, 70]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_null_prices = df_with_prices[df_with_prices['price'].isnull()==True]\n",
    "df_null_prices[['price', 'price_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbfb0dec-46fb-4693-b660-10214d8f6b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 48 posts with price marked null.\n"
     ]
    }
   ],
   "source": [
    "posts_with_mult_prices = df_null_prices.shape[0]\n",
    "print(F\"There were {posts_with_mult_prices} posts with price marked null.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6106d30-41ee-47f0-9695-22b95ad7e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store posts with null prices to CSV to manually inspect later\n",
    "df_null_prices = df_null_prices.drop(columns=['len_of_price_list', 'match'])\n",
    "df_null_prices.to_csv('./posts_to_investigate/{}_posts_with_null_prices.csv'.format(date_of_html_request), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "930b77ec-483e-4b34-803b-3032be8e5b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://phoenix.craigslist.org/nph/lss/d/phoenix-math-chemistry-physics-biology/7440436663.html'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect links manually, one by one, to decide what to do about price information\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "  x=3\n",
    "  #display(df_with_prices.iloc[x]['post_text'])\n",
    "  display(df_with_prices.iloc[x]['link'])\n",
    "  display(df_with_prices.iloc[x]['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b77b7-bd3e-4660-8454-eb6feeee2de3",
   "metadata": {},
   "source": [
    "### Cleaning posts with three or more prices manually - distilling down to one price\n",
    "\n",
    "We distill posts that had more complicated text that involved three or more prices, such as :\n",
    "\n",
    "* $40$/hr, $50$/1.5hr, $60$/2hr\n",
    "  * Complicated pricing schedule\n",
    "* $40$/hr but $10$ additional per person, if a group session is desired\n",
    "  * Group rates\n",
    "* $30$/hr Science, $40$/hr math, come and try a first session for the reduced price of $20$.\n",
    "  * Special offers\n",
    "\n",
    "into a single price.  Other posts repeated their prices multiple times, so we distill those down to a single price as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "raised-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_col_idx = df_with_prices.columns.get_loc('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5484075c-56c5-4c45-a037-4a0d7320078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says $40 for in person, or $45 for at home, so I took the average.\n",
    "san_mateo_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('I mainly tutor, in person, at the Downtown Redwood City, downtown San Mateo')].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[san_mateo_tutor_idx,price_col_idx] = 42.5\n",
    "\n",
    "except:\n",
    "    print(\"Issue with san_mateo_tutor and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "musical-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the ad says $90 in person, $60 for online, and Corona Virus pricing of\n",
    "# $40 for online weekdays, I'm using the $40 per hour rate because it seems the\n",
    "# most reasonable and is most similar to what I'm competing against.\n",
    "kenari_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('kenaritutor.com')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[kenari_tutor_idx,price_col_idx] = 40\n",
    "except:\n",
    "    print('Issue with kenari_tutor_idx and iloc.')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "511ec79c-4a71-4cbf-9efd-466b286386b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad mentions several prices for different subjects, but explicitly says $30 for math.\n",
    "la_honda_idx = df_with_prices[df_with_prices['post_text'].str.contains('909-640-3570')].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[la_honda_idx,price_col_idx] = 30\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with la_honda_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14ca5d7e-f730-4fc3-841a-c70205c847a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says #60 per hour.\n",
    "glasses_lady_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"offering virtual one-on-one Math tutoring via Zoom\")==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[glasses_lady_idx, price_col_idx] = 60\n",
    "except:\n",
    "    print(\"Issue with glasses_lady_idx and iloc.\")\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1402316-6126-4b99-ab97-5ed93f0238bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says #60 per hour.\n",
    "UC_Davis_data_scientist = df_with_prices[df_with_prices['post_text'].str.contains(\"PhD in Engineering from UC Davis\")==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[UC_Davis_data_scientist, price_col_idx] = 60\n",
    "except:\n",
    "    print(\"Issue with UC_Davis_data_scientist and iloc.\")\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "286df5e3-4fcb-481e-b8b1-238ecc789fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This guy has weird price structuring, but I used his hourly rate for each time interval, $100 for 80 minutes, $115 for 100 minutes, $130 for 120 minutes, then averaged those hourly rates to estimate what a single hour would cost.\n",
    "oakland_exp_tutor_online_idx = df_with_prices[df_with_prices['post_text'].str.contains('I received a full scholarship to University of Cincinnati and held a 3.8 GPA through my masters program in aerospace')==True].index\n",
    "\n",
    "oakland_tutor_avg_rate = ((100/80) + (115/100) + (130/120)) * 60 / 3\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[oakland_exp_tutor_online_idx, price_col_idx] = oakland_tutor_avg_rate\n",
    "\n",
    "except:\n",
    "    print(\"Issue with oakland_exp_tutor_online_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "competitive-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ad repeats the price of $40 over and over, so I'm replacing the price with \n",
    "# a single instance.\n",
    "star_star_college_math_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('https://www.youtube.com/channel/UCqhFZRmUqOAAPMQpo58TV7g'\n",
    "                   ) == True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[star_star_college_math_tutor_idx, price_col_idx] = 40\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with star_star_college_math_tutor_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75bacbee-fda4-40d8-b864-f086777b76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says $50/hr    \n",
    "trevor_skelly_idx = df_with_prices[df_with_prices['post_text'].str.contains('trevorskelly')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[trevor_skelly_idx,price_col_idx] = 50\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with trevor_skelly_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sophisticated-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charges $50 per hour for sessions under 3 hours\n",
    "spss_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('datameer', case=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[spss_tutor_idx, price_col_idx] = 50\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with spss_tutor_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6f8a00e-df48-4e40-9b18-886f989c6488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charges $50 per hour\n",
    "tutor_sam_idx = df_with_prices[df_with_prices['post_text'].str.contains('thetutorsam')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[tutor_sam_idx, price_col_idx] = 50\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with tutor_sam_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "nonprofit-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charges $40 per hour\n",
    "peter_d_idx = df_with_prices[df_with_prices['post_text'].str.contains('Peter D.')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[peter_d_idx, price_col_idx] = 40\n",
    "except:\n",
    "    print(\"Issue with peter_d_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "289270da-cd1d-4aac-b1cb-a4070238e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charges $45 per hour for individual lessons\n",
    "algebra_exclusively_idx = df_with_prices[df_with_prices['post_text'].str.contains('algebra EXCLUSIVELY')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[algebra_exclusively_idx, price_col_idx] = 45\n",
    "except:\n",
    "    print(\"Issue with algebra_exclusively_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "improving-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post includes many prices, but states $55/hr for Precalc and $80/hr for Calculus, which are primarily what I help with, so I took the average of those prices\n",
    "aerospace_engineer_idx = df_with_prices[df_with_prices['post_text'].str.contains('in the aerospace industry looking', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[aerospace_engineer_idx, price_col_idx] = (55 + 80)/2\n",
    "\n",
    "except:\n",
    "    print(\"Issue with aerospace_engineer_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "careful-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad mentions $45 for lower division college courses, which are a large segment of the subjects I help with, so I'm using that price to compare myself against.\n",
    "ucb_phd_student_and_ta_idx = df_with_prices[df_with_prices['post_text'].str.contains('Former UC-Berkeley economics Ph.D. student and TA')].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[ucb_phd_student_and_ta_idx, price_col_idx] = 45\n",
    "\n",
    "except:\n",
    "    print(\"Issue with ucb_phd_student_and_ta_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "identical-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The add says $55/hr for K-12, then $65/hr for AP/Honors, as well as Pre-calc, \n",
    "# etc., I'm going to average the two prices.\n",
    "park_academy_idx = df_with_prices[df_with_prices['post_text'].str.contains('(949) 490-0872', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[park_academy_idx, price_col_idx] = 60\n",
    "\n",
    "except:\n",
    "    print(\"Issue with park_academy_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "explicit-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says $25/hr for high school, $30/hr for college, just went with $30/hr\n",
    "sharp_mind_idx = df_with_prices[df_with_prices['post_text'].str.contains('(650) 398-9490', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[sharp_mind_idx, price_col_idx] = 30\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with sharp_mind_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d4988ca4-9ad0-4703-a94a-ed4065e4523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says $50/hr if travelling, $30-35/hr if virtual, so I took the average of 50 and 35\n",
    "stock_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('714.425.3828', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[stock_tutor_idx, price_col_idx] = (35 + 50)/2\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with stock_tutor_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "formal-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post says $30/hr for Precalc/Trig and $50/hr for Calculus, so I took the average\n",
    "lonzo_tutoring_idx = df_with_prices[df_with_prices['post_text'].str.contains('951-795-5027', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[lonzo_tutoring_idx, price_col_idx] = 40\n",
    "\n",
    "except:\n",
    "    print(\"Issue with lonzo_tutoring_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "smoking-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad says $30 for one hour.\n",
    "poway_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('(619)735-2579', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[poway_tutor_idx, price_col_idx] = 30\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with poway_tutor_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "average-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $20/hr online, $30/hr in person, split the difference at $25\n",
    "austin_sabrina_idx = df_with_prices[df_with_prices['post_text'].str.contains('My girlfriend Sabrina')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[austin_sabrina_idx, price_col_idx] = 25\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with austin_sabrina_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "catholic-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says $25/hr\n",
    "alex_farrell_idx = df_with_prices[df_with_prices['post_text'].str.contains('Alexander Farrell')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[alex_farrell_idx, price_col_idx] = 25\n",
    "\n",
    "except:\n",
    "    print(\"Issue with alex_farrell_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12b76bc0-85a3-495c-b385-4972b767534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $25/hr if meeting near CSU Sac, $35/hr if they drive to you, $20/hr for online.\n",
    "# I chose $30/hr to split the difference between the in person prices.\n",
    "best_math_idx = df_with_prices[df_with_prices['post_text'].str.contains('bestmathtutoring.com')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[best_math_idx, price_col_idx] = 30\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with best_math_idx and iloc.\")\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "internal-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucla_grad_henry_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"916 390-7923\", regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[ucla_grad_henry_idx, price_col_idx] = 35\n",
    "\n",
    "except:\n",
    "    print(\"Issue with ucla_grad_henry_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5f5de-7684-4c1f-9e92-029f6fffea5d",
   "metadata": {},
   "source": [
    "#### Checking results - Are there any posts that were marked as needing to be cleaned that we missed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "designed-facial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27 posts that need cleaning.\n"
     ]
    }
   ],
   "source": [
    "num_still_null = len(df_with_prices[df_with_prices['price'].isnull()==True])\n",
    "\n",
    "if num_still_null==0:\n",
    "    print(\"There are no posts with null prices still needing cleaning.\")\n",
    "else:\n",
    "    print(F\"There are {num_still_null} posts that need cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9f4d2c-57da-4d35-a331-ff18f8b790d3",
   "metadata": {},
   "source": [
    "### Checking Posts that have two prices listed to see if averaging them is reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72f4dd25-cd1a-4e13-bc8c-4526d76f150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>price_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>[40, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>[29, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37.5</td>\n",
       "      <td>[45, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46.0</td>\n",
       "      <td>[57, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>45.0</td>\n",
       "      <td>[30, 60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>37.5</td>\n",
       "      <td>[30, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>22.5</td>\n",
       "      <td>[20, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>32.5</td>\n",
       "      <td>[60, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>45.0</td>\n",
       "      <td>[40, 50]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>45.0</td>\n",
       "      <td>[50, 40]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     price price_list\n",
       "1     40.0   [40, 40]\n",
       "3     27.0   [29, 25]\n",
       "5     37.5   [45, 30]\n",
       "9     46.0   [57, 35]\n",
       "14    45.0   [30, 60]\n",
       "..     ...        ...\n",
       "346   37.5   [30, 45]\n",
       "354   22.5   [20, 25]\n",
       "356   32.5    [60, 5]\n",
       "359   45.0   [40, 50]\n",
       "362   45.0   [50, 40]\n",
       "\n",
       "[107 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_prices[df_with_prices['len_of_price_list']==2][['price','price_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc8e2d5d-7df4-43e0-b914-9be1a1967153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://sfbay.craigslist.org/sby/lss/d/sunnyvale-math-tutor/7428999436.html'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\nHi,\\n\\nMath has always been my strong suit. I have tutored various leveled students from Pre Algebra to Calculus. I am familiar with the curriculum of home schooling and have worked with students who do their courses in an online school or University. I teach and encourage them to find the solutions to math problems step-by-step. I teach and/or review concepts with basic, easy-to-understand explanations, delving deeper if needed. \\n\\nI tutor the following subjects: \\nPre-algebra, Algebra 1 and 2, Geometry, Trigonometry, Pre -Calculus, and Calculus.\\n\\nI usually charge $35 to $45 per hour. Please contact me for more details. \\n\\n\\n\\n\\n\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect posts manually, one by one\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "  x=136\n",
    "  #display(df_with_prices.iloc[x]['post_text'])\n",
    "  display(df_with_prices.iloc[x]['link'])\n",
    "  display(df_with_prices.iloc[x]['post_text'])\n",
    "  display(df_with_prices.iloc[x]['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22beb0e4-8b3b-49fb-894c-82f3e9c598b9",
   "metadata": {},
   "source": [
    "#### Ads where averaging doesn't make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc06f34c-357f-4508-88ff-7cf515eef0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says 35$/half hour, but explicitly says $57 per hour, so averaging doesn't make sense.  \n",
    "blake_tutoring_idx = df_with_prices[df_with_prices['post_text'].str.contains('BlakeTutoring.com', case=False)==True].index\n",
    "\n",
    "df_with_prices.iloc[blake_tutoring_idx, price_col_idx] = 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "allied-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad says $84/hr but then mentions a $125 for 1.5 hours.  Since these are the only two prices in the post, our code averages them, so we set the correct price to $84\n",
    "test_trainer_inc_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"TestTrainerinc\", regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[test_trainer_inc_idx, price_col_idx] = 84\n",
    "\n",
    "except:\n",
    "    print(\"Issue with test_trainer_inc_idx and iloc.\")\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ab8ea92-15a6-43b2-b913-a86880a2f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $60/45mins, but $80 per hour.  Either price comes out to the same hourly rate, so averaging doesn't make sense.\n",
    "hiro_kobayashi_idx = df_with_prices[df_with_prices['post_text'].str.contains('415-250-4831', case=False)==True].index\n",
    "\n",
    "df_with_prices.iloc[hiro_kobayashi_idx, price_col_idx] = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb557fbe-9c04-4f3b-a253-44be8dbcceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $40/1hr, $70/2hr, so averaging doesn't make sense\n",
    "guy_with_suit_idx = df_with_prices[df_with_prices['post_text'].str.contains('trained mathematician with about 20 years experience')==True].index\n",
    "\n",
    "df_with_prices.iloc[guy_with_suit_idx, price_col_idx] = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "74a848a8-b063-4cce-9aef-4fd838551210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $25/1hr, $40/2hr, so averaging doesn't make sense\n",
    "christian_cerritos_college_idx = df_with_prices[df_with_prices['post_text'].str.contains('trained mathematician with about 20 years experience')==True].index\n",
    "\n",
    "df_with_prices.iloc[christian_cerritos_college_idx, price_col_idx] = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04b6fe95-7589-4650-b38f-ca229bdb16e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $30/half hr, $50/1hr, so averaging doesn't make sense\n",
    "dustin_csu_long_beach_idx = df_with_prices[df_with_prices['post_text'].str.contains('International Society of Automation')==True].index\n",
    "\n",
    "df_with_prices.iloc[dustin_csu_long_beach_idx, price_col_idx] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7298c75-8a00-4705-90a4-0b3e7ae5a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $65/hr for subject tutoring, $100/hr for standardized tests.  I'm primarily competing against subject tutoring, so I'll use that price\n",
    "smarter_than_you_think_idx = df_with_prices[df_with_prices['post_text'].str.contains('guarantee you are smarter than you think')==True].index\n",
    "\n",
    "df_with_prices.iloc[smarter_than_you_think_idx, price_col_idx] = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01101fb3-221a-482e-9e36-0280d415e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $50/hr or $160/4hr, so it doesn't make sense to average.\n",
    "dead_in_ditch_idx = df_with_prices[df_with_prices['post_text'].str.contains('dead in a ditch')==True].index\n",
    "\n",
    "df_with_prices.iloc[dead_in_ditch_idx, price_col_idx] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "124abde4-be0f-4d62-b675-417fa672cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $45/hr +$10 more per student, so it doesn't make sense to average.\n",
    "distinguished_teacher_idx = df_with_prices[df_with_prices['post_text'].str.contains('\"Distinguished Teacher\"')==True].index\n",
    "\n",
    "df_with_prices.iloc[distinguished_teacher_idx, price_col_idx] = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad1a8716-a2ef-4661-b162-d3e959f92b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $40/hr +$10 more for each additional person, so it doesn't make sense to average.\n",
    "vahab_idx = df_with_prices[df_with_prices['post_text'].str.contains('vababtaghizade@gmail.com')==True].index\n",
    "\n",
    "df_with_prices.iloc[vahab_idx, price_col_idx] = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "25252b56-959e-46de-9b52-95834da63513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $30/hr for trial session, then $60/hr afterwards, so it doesn't make sense to average.\n",
    "myles_ahead_idx = df_with_prices[df_with_prices['post_text'].str.contains('mylesaheadtutoring')==True].index\n",
    "\n",
    "df_with_prices.iloc[myles_ahead_idx, price_col_idx] = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11aa0f22-d46b-4295-b318-94fb14053bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $45/hr, then talks about selling a workbook for $30, so it doesn't make sense to average.\n",
    "john_the_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('480-343-2212')==True].index\n",
    "\n",
    "df_with_prices.iloc[john_the_tutor_idx, price_col_idx] = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab450bff-f1f1-40c4-9601-bd4dbbbfe6fd",
   "metadata": {},
   "source": [
    "Conclusion: Averaging doesn't make sense for a good chunk of these posts, but averaging is helpful for others.  I need to come up with a better process here, but will leave that for later..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372c281c-e1e6-4167-8512-54a8a13bfb04",
   "metadata": {},
   "source": [
    "## Investigating posts with extreme prices.  Are there any price outliers that we need to clean?\n",
    "\n",
    "Prices >= 100 or <= 20 are what I would consider to be extreme prices.  Let's investigate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58751ba1-6c7d-40b7-b22f-62db9a52a2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>post_text</th>\n",
       "      <th>price_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nText 2133408660 or register at peerl...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>120.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nHello! My name is Connor and I've be...</td>\n",
       "      <td>[120]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>100.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nLovely to meet you! My name is Frank...</td>\n",
       "      <td>[100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>120.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nG'day! My name's Daniel, and I'm a f...</td>\n",
       "      <td>[120]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>150.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nG'day! My name is Daniel. I graduate...</td>\n",
       "      <td>[200, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nIf you are struggling in math or phy...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nHello, my name is Isaac Walters, I'm...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nUC Irvine educated math and science ...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nI look forward to helping you be suc...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nHi everyone, do you need math, physi...</td>\n",
       "      <td>[15, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>120.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nHomeschool Groups, please contact me...</td>\n",
       "      <td>[200, 40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nI look forward to helping you succee...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>120.0</td>\n",
       "      <td>\\n\\n\\n\\n\\n*****I am currently offering both Zo...</td>\n",
       "      <td>[120]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>100.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nMy name is Sameer Tyagi, former Harv...</td>\n",
       "      <td>[80, 120]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>125.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nI'm a software developer with a B.S....</td>\n",
       "      <td>[100, 150]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>200.0</td>\n",
       "      <td>\\n\\n\\n\\n\\ncheck out my website!\\nmd-maker.com\\...</td>\n",
       "      <td>[200]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nI enjoy tutoring and want my student...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\nAre you ready for some in-person...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>19.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nHi! \\nI am a certified teacher with ...</td>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nHAPPY NEW YEAR!!!\\n\\nYes, you read r...</td>\n",
       "      <td>[20, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>17.5</td>\n",
       "      <td>\\n\\n\\n\\n\\nMaths Tutor \\n\\nElementary, Middle a...</td>\n",
       "      <td>[0, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>120.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nHello,\\nI have been a high school ma...</td>\n",
       "      <td>[120]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nHi! My name is Sher. I have a Bachel...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nRetired public school math teacher w...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nI have 5 years of experience tutorin...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>5.0</td>\n",
       "      <td>\\n\\n\\n\\n\\n14 plus years of experience\\nRecent ...</td>\n",
       "      <td>[5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nWelcome to Family 2 Family Learning ...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nUniversity Student looking to provid...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>100.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nAn experienced, energetic, effective...</td>\n",
       "      <td>[100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nMy name is Alex Houssney and I am  a...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nHi,\\n\\nMy name is Jason and I am an ...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nExperienced math tutor/teacher.  I t...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nI am an experienced math tutor/teach...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>100.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nReady to achieve seemingly impossibl...</td>\n",
       "      <td>[100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>100.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nWEBSITE: ROMEGATUTORING.COM\\n\\nHello...</td>\n",
       "      <td>[100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>100.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nIf you would like your K-through-5th...</td>\n",
       "      <td>[115, 85]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nWhy I am an exceptional tutor: \\n\\nF...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nLooking For A Tutor?\\n\\nPrivate Tuto...</td>\n",
       "      <td>[30, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nSometimes things don't click, and th...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>17.5</td>\n",
       "      <td>\\n\\n\\n\\n\\nHi, my name is Alicia. I'm available...</td>\n",
       "      <td>[30, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nI am a semi-retired teacher, eager t...</td>\n",
       "      <td>[20, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nLet me help your child do better in ...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nI'm a teacher with over 20 years of ...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nWhy gamble with your future? Get exe...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nLooking for a math tutor? My name is...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>15.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nHello,\\n\\nI am an expert amateur wri...</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>17.5</td>\n",
       "      <td>\\n\\n\\n\\n\\nAlg. I/ Geom. /Alg. II/ Pre-Cal/ Cal...</td>\n",
       "      <td>[20, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>20.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nHello. I am a college student and I ...</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>14.0</td>\n",
       "      <td>\\n\\n\\n\\n\\nI have accumulated 14 years of teach...</td>\n",
       "      <td>[14]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price                                          post_text  price_list\n",
       "34    20.0  \\n\\n\\n\\n\\nText 2133408660 or register at peerl...        [20]\n",
       "50   120.0  \\n\\n\\n\\n\\nHello! My name is Connor and I've be...       [120]\n",
       "52   100.0  \\n\\n\\n\\n\\nLovely to meet you! My name is Frank...       [100]\n",
       "56   120.0  \\n\\n\\n\\n\\nG'day! My name's Daniel, and I'm a f...       [120]\n",
       "57   150.0  \\n\\n\\n\\n\\nG'day! My name is Daniel. I graduate...  [200, 100]\n",
       "71    15.0  \\n\\n\\n\\n\\nIf you are struggling in math or phy...        [15]\n",
       "72    15.0  \\n\\n\\n\\n\\nHello, my name is Isaac Walters, I'm...        [15]\n",
       "77    20.0  \\n\\n\\n\\n\\nUC Irvine educated math and science ...        [20]\n",
       "91    15.0  \\n\\n\\n\\n\\nI look forward to helping you be suc...        [15]\n",
       "96    20.0  \\n\\n\\n\\n\\nHi everyone, do you need math, physi...    [15, 25]\n",
       "110  120.0  \\n\\n\\n\\n\\nHomeschool Groups, please contact me...   [200, 40]\n",
       "120   15.0  \\n\\n\\n\\n\\nI look forward to helping you succee...        [15]\n",
       "135  120.0  \\n\\n\\n\\n\\n*****I am currently offering both Zo...       [120]\n",
       "137  100.0  \\n\\n\\n\\n\\nMy name is Sameer Tyagi, former Harv...   [80, 120]\n",
       "142  125.0  \\n\\n\\n\\n\\nI'm a software developer with a B.S....  [100, 150]\n",
       "146  200.0  \\n\\n\\n\\n\\ncheck out my website!\\nmd-maker.com\\...       [200]\n",
       "159   20.0  \\n\\n\\n\\n\\nI enjoy tutoring and want my student...        [20]\n",
       "165   20.0  \\n\\n\\n\\n\\n\\n\\nAre you ready for some in-person...        [20]\n",
       "173   19.0  \\n\\n\\n\\n\\nHi! \\nI am a certified teacher with ...        [19]\n",
       "175   20.0  \\n\\n\\n\\n\\nHAPPY NEW YEAR!!!\\n\\nYes, you read r...    [20, 20]\n",
       "177   17.5  \\n\\n\\n\\n\\nMaths Tutor \\n\\nElementary, Middle a...     [0, 35]\n",
       "181  120.0  \\n\\n\\n\\n\\nHello,\\nI have been a high school ma...       [120]\n",
       "194   15.0  \\n\\n\\n\\n\\nHi! My name is Sher. I have a Bachel...        [15]\n",
       "196   15.0  \\n\\n\\n\\n\\nRetired public school math teacher w...        [15]\n",
       "203   15.0  \\n\\n\\n\\n\\nI have 5 years of experience tutorin...        [15]\n",
       "212    5.0  \\n\\n\\n\\n\\n14 plus years of experience\\nRecent ...         [5]\n",
       "214   15.0  \\n\\n\\n\\n\\nWelcome to Family 2 Family Learning ...        [15]\n",
       "222   20.0  \\n\\n\\n\\n\\nUniversity Student looking to provid...        [20]\n",
       "230  100.0  \\n\\n\\n\\n\\nAn experienced, energetic, effective...       [100]\n",
       "238   20.0  \\n\\n\\n\\n\\nMy name is Alex Houssney and I am  a...        [20]\n",
       "239   20.0  \\n\\n\\n\\n\\nHi,\\n\\nMy name is Jason and I am an ...        [20]\n",
       "242   20.0  \\n\\n\\n\\n\\nExperienced math tutor/teacher.  I t...        [20]\n",
       "243   20.0  \\n\\n\\n\\n\\nI am an experienced math tutor/teach...        [20]\n",
       "255  100.0  \\n\\n\\n\\n\\nReady to achieve seemingly impossibl...       [100]\n",
       "275  100.0  \\n\\n\\n\\n\\nWEBSITE: ROMEGATUTORING.COM\\n\\nHello...       [100]\n",
       "285  100.0  \\n\\n\\n\\n\\nIf you would like your K-through-5th...   [115, 85]\n",
       "286   20.0  \\n\\n\\n\\n\\nWhy I am an exceptional tutor: \\n\\nF...        [20]\n",
       "287   20.0  \\n\\n\\n\\n\\nLooking For A Tutor?\\n\\nPrivate Tuto...    [30, 10]\n",
       "306   15.0  \\n\\n\\n\\n\\nSometimes things don't click, and th...        [15]\n",
       "307   17.5  \\n\\n\\n\\n\\nHi, my name is Alicia. I'm available...     [30, 5]\n",
       "308   15.0  \\n\\n\\n\\n\\nI am a semi-retired teacher, eager t...    [20, 10]\n",
       "313   20.0  \\n\\n\\n\\n\\nLet me help your child do better in ...        [20]\n",
       "314   20.0  \\n\\n\\n\\n\\nI'm a teacher with over 20 years of ...        [20]\n",
       "316   15.0  \\n\\n\\n\\n\\nWhy gamble with your future? Get exe...        [15]\n",
       "321   20.0  \\n\\n\\n\\n\\nLooking for a math tutor? My name is...        [20]\n",
       "324   15.0  \\n\\n\\n\\n\\nHello,\\n\\nI am an expert amateur wri...        [15]\n",
       "337   17.5  \\n\\n\\n\\n\\nAlg. I/ Geom. /Alg. II/ Pre-Cal/ Cal...    [20, 15]\n",
       "342   20.0  \\n\\n\\n\\n\\nHello. I am a college student and I ...        [20]\n",
       "348   14.0  \\n\\n\\n\\n\\nI have accumulated 14 years of teach...        [14]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_prices[(df_with_prices['price']>=100) | (df_with_prices['price']<=20)][['price', 'post_text', 'price_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a4892b0-a385-4119-9897-659036333b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://losangeles.craigslist.org/sgv/lss/d/pasadena-tutor-available-for-math-engr/7435920671.html'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\nDegreed Engineer (BSEE/MSEE) available to aid you in multiple areas which you may need help with while we all try to recover from the lockdown disaster.\\n\\nClasses are =finally= beginning to startup again and, sadly, many people are WAY behind in their studies.  Thus, this is a good time to catch up with all that missed school work and studying for tests.\\n\\nI usually look for tutoring gigs for Adult / College / High-School (with parental approval) for misc MATH classes ranging from pre-algebra through trigonometry and calculus with a smattering of linear algebra, statistics and other things - you will need to ask.  I can also tutor other topics in the Engineering curriculum - for special classes please let me know the class and book ahead of time.\\n\\nAlso available for possible Testing, Debugging and Troubleshooting of your Electronic Design or your pet project if it is within my wheelhouse.  Good at thinking logically and tracking down intricate problems.  I can layout a professionally made PCB and generate the GERBER plots for more advanced projects or for companies needing that service. \\n\\nCan also help building various Electronic kits for young adults who are old enough to work with tools and soldering irons.  I can bring by my own tools, solder irons, power supplies, multimeter, etc. if you don't have these things and may also be able to give you some free parts since i have tons lying around in storage.\\n\\nI can also perform misc tedious tasks which you may simply have no desire to do (data entry for medical records, sorting parts and the like) for your business, take pics for eBay listings (for =your= account), etc.\\n\\n------------------------------------------------------\\n\\nI am currently only available in the evenings during the week, starting at 7pm and at various times on the weekend all depending on who contacts me first.\\n\\nLocated in the SGV/Pasadena area and would need to either meet at a local Carl's Jr. (which are thankfully now open again for indoor seating) or travel to YOUR location if not too far away (else i may need to add a travel fee).\\n\\nI am able to work for multiple consecutive hour sessions if needed.  Very reliable, timely and honest.\\n\\nI charge in the $35/hr to $65/hr range (tutoring at the bottom end, Engineering related on the top end), depending on what the job is and how far i need to travel.\\n\\nI am also a card carrying Registered Professional Engineer in the State of California, if that matters.\\n\\nLet me know if you have any interest for current or future projects.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Manually inspect these posts one by one\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "  x=40\n",
    "  #display(df_with_prices.iloc[x]['post_text'])\n",
    "  display(df_with_prices.iloc[x]['link'])\n",
    "  display(df_with_prices.iloc[x]['post_text'])\n",
    "  display(df_with_prices.iloc[x]['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc9c8c4-053c-4065-84c4-b5e2c7f221cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dropping posts with extreme prices that aren't relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "green-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad is for poker tutoring/coaching, not really what I'm competing against, so we drop it.  He also mentions he tutors math in this post, but he has a separate post, that we've captured, which has his math tutoring pricing information.\n",
    "australia_daniel_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"I'm available as a dealer if you need one\", regex=False)==True].index\n",
    "\n",
    "df_with_prices.drop(labels=australia_daniel_idx, inplace=True)\n",
    "df_with_prices = df_with_prices.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb89cbc-1b96-4110-a724-a4a375e2da25",
   "metadata": {},
   "source": [
    "### Correcting pricing information for posts with extreme prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "radical-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad says $50/hr but then mentions a prepay plan for $160 for 4 hours.  Since these are the only two prices in the post, our code averages them, so we set the correct price to $50\n",
    "google_maps_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"willing to travel if Google Maps\", regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[google_maps_idx, price_col_idx] = 50\n",
    "\n",
    "except:\n",
    "    print(\"Issue with google_maps_idx and iloc.\")\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "nutritional-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad says $45/hr for high school or college, but then mentions a $35 for middle school.  Since these are the only two prices in the post, our code averages them, so we set the correct price to $45, since I primarily tutor high school or college students.\n",
    "rancho_penasquitos_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"Rancho Penasquitos (Park Village Neighborhood)\", regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[rancho_penasquitos_idx, price_col_idx] = 45\n",
    "\n",
    "except:\n",
    "    print(\"Issue with rancho_penasquitos_idx and iloc.\")\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5845cf-2131-4c99-a7a9-5ea9f2b06025",
   "metadata": {},
   "source": [
    "### Transforming Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86885d2-afe0-413b-8bb1-dd77270c438b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# *Load* - Saving results\n",
    "\n",
    "### Store results locally as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45ec8df9-162d-488e-9398-802af285f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns.\n",
    "df_for_sql = df_with_prices.drop(labels=['link', 'price_list', 'len_of_price_list', 'match'], axis=1)\n",
    "\n",
    "# In order for psycopg2 to parse our CSV file correctly later, we need to escape all new line characters by adding an additional \\ in front of \\n.\n",
    "df_for_sql['post_text'] = df_for_sql['post_text'].str.replace('\\n', '\\\\n')\n",
    "\n",
    "# Store cleaned data as CSV file in preparation for importing to SQL database\n",
    "df_for_sql.to_csv(\"./csv_files/{}_all_regions_with_prices.csv\".format(date_of_html_request), index=False, sep=';')\n",
    "\n",
    "# Store original data, before we applied any cleaning to it, in case it's needed for something later on.\n",
    "concat_df.to_csv(\"./csv_files/{}_all_regions_posts.csv\".format(date_of_html_request), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a8345366-1da1-4faf-b682-7639d0e83a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_dups.to_csv('./csv_files/{}_all_regions_no_dups.csv'.format(date_of_html_request), index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3316f-3491-4d57-8cf0-69a03c3f2bab",
   "metadata": {},
   "source": [
    "### Importing into PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f2c8850-c39b-438e-943b-f87626e2ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection to PSQL database\n",
    "conn = psycopg2.connect(\"host=localhost dbname=rancher user=rancher port=5430\")\n",
    "\n",
    "# Instantiate a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Use cursor object to create a database for storing the information we scraped and cleaned, if one doesn't already exist.\n",
    "cur.execute(\"\"\"    \n",
    "    CREATE TABLE IF NOT EXISTS cl_tutoring(\n",
    "    id SERIAL primary key,\n",
    "    date_scraped date,\n",
    "    price decimal,\n",
    "    city text,\n",
    "    subregion text,\n",
    "    region text,\n",
    "    state text,\n",
    "    post_text text,\n",
    "    date_posted timestamp\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Commit changes to database\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c7e8dd7c-60f9-40d4-baa6-5fed6e38094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a new cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Copy data from our CSV file into database.  \n",
    "### Note, we can use the ; separator freely because we replaced all instances of semicolons in post_text to commas during the preprocessing stage, ensuring that psycopg2 won't misinterpret a semicolon in the body of a post as a separator.\n",
    "### Also, we must specify null=\"\" because Python represents null values as an empty string when writing to a CSV file and psycopg2 needs to know how null values are represented in the CSV file in order to properly insert null values into the database\n",
    "with open('./csv_files/' + str(date_of_html_request) + '_all_regions_with_prices.csv', 'r') as file:\n",
    "    next(file) # Skip the header row\n",
    "    cur.copy_from(file, 'cl_tutoring', sep=';', null=\"\", columns=('date_posted', 'price', 'city', 'subregion', 'region', 'state', 'post_text', 'date_scraped'))\n",
    "    \n",
    "# Commit changes to database\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f1d2b-9697-48ff-8337-7f73bcfe3b36",
   "metadata": {},
   "source": [
    "### Done!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4544953-347c-47fa-aae0-dd6bab89f814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
