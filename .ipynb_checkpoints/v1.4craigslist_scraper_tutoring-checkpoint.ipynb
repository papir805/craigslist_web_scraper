{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdea0012-7b13-44ca-bf01-dac6cc92eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "import requests\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import csv \n",
    "import psycopg2\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1912ec53-d232-41f0-9926-c414e7d485bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Session and Retry object to manage the quota Craigslist imposes on HTTP get requests within a certain time period \n",
    "session = requests.Session()\n",
    "retry = Retry(connect=5, backoff_factor=0.5)\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount('http://', adapter)\n",
    "session.mount('https://', adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba00c0-7b51-478a-8720-48940971bc4c",
   "metadata": {},
   "source": [
    "# Extracting Craigslist Data\n",
    "## Get all state/region names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9f8229-77d3-471d-9ea9-8dc4b134260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse URL that contains all regions of Craigslist\n",
    "all_sites_response = session.get('https://craigslist.org/about/sites')\n",
    "all_sites_soup = BeautifulSoup(all_sites_response.text, 'html.parser')\n",
    "\n",
    "# Extract part of webpage corresponding to regions in the US\n",
    "us_sites = all_sites_soup.body.section.div.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling\n",
    "\n",
    "# Extract HTML tags corresponding to the state name and region\n",
    "states_tags = us_sites.find_all('h4')\n",
    "regions_tags = us_sites.find_all('ul')\n",
    "\n",
    "states_and_regions = list(zip(states_tags, regions_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a8ddf0-62f7-44cc-9d00-494f9807a94d",
   "metadata": {},
   "source": [
    "## Get URL for each region of Craigslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df75c464-c95f-4562-bcaa-ee6db0a4aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the HTML tags, we get the text of which state the region belonged to and the text of the region's name.  We now have a dictionary with keys as states that map to a list of regions in that state\n",
    "state_dict = {}\n",
    "\n",
    "for ele in states_and_regions:\n",
    "    current_state = ele[0].text\n",
    "    href_list = ele[1].find_all('li')\n",
    "    temp_region_list = []\n",
    "    for href in href_list:\n",
    "        region = href.a['href'].replace('https://','').replace('.craigslist.org/','')\n",
    "        temp_region_list.append(region)\n",
    "        state_dict[current_state]=temp_region_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fff7c9-da51-45c8-a7d2-3b1030b313da",
   "metadata": {},
   "source": [
    "## Crawl each state/region of Craigslist\n",
    "Get the URL that corresponds to a search of the services section for \"math tutor.\"  Craigslist is limited to showing 120 results per page, so if a region has more than 120 postings, we extract URLs corresponding to the next page of results, until there is no next button anymore and we've extracted all URLs for that region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8dd7bb-6675-4a70-bef5-9803df93d6af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response #1 for Alabama: auburn received.\n",
      "Last response for auburn received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: bham received.\n",
      "Last response for bham received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: dothan received.\n",
      "Last response for dothan received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: shoals received.\n",
      "Last response for shoals received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: gadsden received.\n",
      "Last response for gadsden received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: huntsville received.\n",
      "Last response for huntsville received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: mobile received.\n",
      "Last response for mobile received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: montgomery received.\n",
      "Last response for montgomery received.  Process completed.\n",
      "\n",
      "Response #1 for Alabama: tuscaloosa received.\n",
      "Last response for tuscaloosa received.  Process completed.\n",
      "\n",
      "Response #1 for Alaska: anchorage received.\n",
      "Last response for anchorage received.  Process completed.\n",
      "\n",
      "Response #1 for Alaska: fairbanks received.\n",
      "Last response for fairbanks received.  Process completed.\n",
      "\n",
      "Response #1 for Alaska: kenai received.\n",
      "Last response for kenai received.  Process completed.\n",
      "\n",
      "Response #1 for Alaska: juneau received.\n",
      "Last response for juneau received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: flagstaff received.\n",
      "Last response for flagstaff received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: mohave received.\n",
      "Last response for mohave received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: phoenix received.\n",
      "Last response for phoenix received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: prescott received.\n",
      "Last response for prescott received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: showlow received.\n",
      "Last response for showlow received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: sierravista received.\n",
      "Last response for sierravista received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: tucson received.\n",
      "Last response for tucson received.  Process completed.\n",
      "\n",
      "Response #1 for Arizona: yuma received.\n",
      "Last response for yuma received.  Process completed.\n",
      "\n",
      "Response #1 for Arkansas: fayar received.\n",
      "Last response for fayar received.  Process completed.\n",
      "\n",
      "Response #1 for Arkansas: fortsmith received.\n",
      "Last response for fortsmith received.  Process completed.\n",
      "\n",
      "Response #1 for Arkansas: jonesboro received.\n",
      "Last response for jonesboro received.  Process completed.\n",
      "\n",
      "Response #1 for Arkansas: littlerock received.\n",
      "Last response for littlerock received.  Process completed.\n",
      "\n",
      "Response #1 for Arkansas: texarkana received.\n",
      "Last response for texarkana received.  Process completed.\n",
      "\n",
      "Response #1 for California: bakersfield received.\n",
      "Last response for bakersfield received.  Process completed.\n",
      "\n",
      "Response #1 for California: chico received.\n",
      "Last response for chico received.  Process completed.\n",
      "\n",
      "Response #1 for California: fresno received.\n",
      "Last response for fresno received.  Process completed.\n",
      "\n",
      "Response #1 for California: goldcountry received.\n",
      "Last response for goldcountry received.  Process completed.\n",
      "\n",
      "Response #1 for California: hanford received.\n",
      "Last response for hanford received.  Process completed.\n",
      "\n",
      "Response #1 for California: humboldt received.\n",
      "Last response for humboldt received.  Process completed.\n",
      "\n",
      "Response #1 for California: imperial received.\n",
      "Last response for imperial received.  Process completed.\n",
      "\n",
      "Response #1 for California: inlandempire received.\n",
      "Last response for inlandempire received.  Process completed.\n",
      "\n",
      "Response #1 for California: losangeles received.\n",
      "losangeles 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "losangeles 3 response received.\n",
      "Waiting 3 seconds...\n",
      "\n",
      "Last response for losangeles received.  Process completed.\n",
      "\n",
      "Response #1 for California: mendocino received.\n",
      "Last response for mendocino received.  Process completed.\n",
      "\n",
      "Response #1 for California: merced received.\n",
      "Last response for merced received.  Process completed.\n",
      "\n",
      "Response #1 for California: modesto received.\n",
      "Last response for modesto received.  Process completed.\n",
      "\n",
      "Response #1 for California: monterey received.\n",
      "Last response for monterey received.  Process completed.\n",
      "\n",
      "Response #1 for California: orangecounty received.\n",
      "orangecounty 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for orangecounty received.  Process completed.\n",
      "\n",
      "Response #1 for California: palmsprings received.\n",
      "Last response for palmsprings received.  Process completed.\n",
      "\n",
      "Response #1 for California: redding received.\n",
      "Last response for redding received.  Process completed.\n",
      "\n",
      "Response #1 for California: sacramento received.\n",
      "Last response for sacramento received.  Process completed.\n",
      "\n",
      "Response #1 for California: sandiego received.\n",
      "sandiego 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for sandiego received.  Process completed.\n",
      "\n",
      "Response #1 for California: sfbay received.\n",
      "sfbay 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "sfbay 3 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "sfbay 4 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for sfbay received.  Process completed.\n",
      "\n",
      "Response #1 for California: slo received.\n",
      "Last response for slo received.  Process completed.\n",
      "\n",
      "Response #1 for California: santabarbara received.\n",
      "Last response for santabarbara received.  Process completed.\n",
      "\n",
      "Response #1 for California: santamaria received.\n",
      "Last response for santamaria received.  Process completed.\n",
      "\n",
      "Response #1 for California: siskiyou received.\n",
      "Last response for siskiyou received.  Process completed.\n",
      "\n",
      "Response #1 for California: stockton received.\n",
      "Last response for stockton received.  Process completed.\n",
      "\n",
      "Response #1 for California: susanville received.\n",
      "Last response for susanville received.  Process completed.\n",
      "\n",
      "Response #1 for California: ventura received.\n",
      "Last response for ventura received.  Process completed.\n",
      "\n",
      "Response #1 for California: visalia received.\n",
      "Last response for visalia received.  Process completed.\n",
      "\n",
      "Response #1 for California: yubasutter received.\n",
      "Last response for yubasutter received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: boulder received.\n",
      "Last response for boulder received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: cosprings received.\n",
      "Last response for cosprings received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: denver received.\n",
      "Last response for denver received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: eastco received.\n",
      "Last response for eastco received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: fortcollins received.\n",
      "Last response for fortcollins received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: rockies received.\n",
      "Last response for rockies received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: pueblo received.\n",
      "Last response for pueblo received.  Process completed.\n",
      "\n",
      "Response #1 for Colorado: westslope received.\n",
      "Last response for westslope received.  Process completed.\n",
      "\n",
      "Response #1 for Connecticut: newlondon received.\n",
      "Last response for newlondon received.  Process completed.\n",
      "\n",
      "Response #1 for Connecticut: hartford received.\n",
      "Last response for hartford received.  Process completed.\n",
      "\n",
      "Response #1 for Connecticut: newhaven received.\n",
      "Last response for newhaven received.  Process completed.\n",
      "\n",
      "Response #1 for Connecticut: nwct received.\n",
      "Last response for nwct received.  Process completed.\n",
      "\n",
      "Response #1 for Delaware: delaware received.\n",
      "Last response for delaware received.  Process completed.\n",
      "\n",
      "Response #1 for District of Columbia: washingtondc received.\n",
      "washingtondc 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for washingtondc received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: miami received.\n",
      "miami 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for miami received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: daytona received.\n",
      "Last response for daytona received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: keys received.\n",
      "Last response for keys received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: miami received.\n",
      "miami 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for miami received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: fortmyers received.\n",
      "Last response for fortmyers received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: gainesville received.\n",
      "Last response for gainesville received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: cfl received.\n",
      "Last response for cfl received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: jacksonville received.\n",
      "Last response for jacksonville received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: lakeland received.\n",
      "Last response for lakeland received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: miami received.\n",
      "miami 2 response received.\n",
      "Waiting 3 seconds...\n",
      "\n",
      "Last response for miami received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: lakecity received.\n",
      "Last response for lakecity received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: ocala received.\n",
      "Last response for ocala received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: okaloosa received.\n",
      "Last response for okaloosa received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: orlando received.\n",
      "Last response for orlando received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: panamacity received.\n",
      "Last response for panamacity received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: pensacola received.\n",
      "Last response for pensacola received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: sarasota received.\n",
      "Last response for sarasota received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: miami received.\n",
      "miami 2 response received.\n",
      "Waiting 3 seconds...\n",
      "\n",
      "Last response for miami received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: spacecoast received.\n",
      "Last response for spacecoast received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: staugustine received.\n",
      "Last response for staugustine received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: tallahassee received.\n",
      "Last response for tallahassee received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: tampa received.\n",
      "Last response for tampa received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: treasure received.\n",
      "Last response for treasure received.  Process completed.\n",
      "\n",
      "Response #1 for Florida: miami received.\n",
      "miami 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "Last response for miami received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: albanyga received.\n",
      "Last response for albanyga received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: athensga received.\n",
      "Last response for athensga received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: atlanta received.\n",
      "atlanta 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "Last response for atlanta received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: augusta received.\n",
      "Last response for augusta received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: brunswick received.\n",
      "Last response for brunswick received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: columbusga received.\n",
      "Last response for columbusga received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: macon received.\n",
      "Last response for macon received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: nwga received.\n",
      "Last response for nwga received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: savannah received.\n",
      "Last response for savannah received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: statesboro received.\n",
      "Last response for statesboro received.  Process completed.\n",
      "\n",
      "Response #1 for Georgia: valdosta received.\n",
      "Last response for valdosta received.  Process completed.\n",
      "\n",
      "Response #1 for Hawaii: honolulu received.\n",
      "Last response for honolulu received.  Process completed.\n",
      "\n",
      "Response #1 for Idaho: boise received.\n",
      "Last response for boise received.  Process completed.\n",
      "\n",
      "Response #1 for Idaho: eastidaho received.\n",
      "Last response for eastidaho received.  Process completed.\n",
      "\n",
      "Response #1 for Idaho: lewiston received.\n",
      "Last response for lewiston received.  Process completed.\n",
      "\n",
      "Response #1 for Idaho: twinfalls received.\n",
      "Last response for twinfalls received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: bn received.\n",
      "Last response for bn received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: chambana received.\n",
      "Last response for chambana received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: chicago received.\n",
      "Last response for chicago received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: decatur received.\n",
      "Last response for decatur received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: lasalle received.\n",
      "Last response for lasalle received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: mattoon received.\n",
      "Last response for mattoon received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: peoria received.\n",
      "Last response for peoria received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: rockford received.\n",
      "Last response for rockford received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: carbondale received.\n",
      "Last response for carbondale received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: springfieldil received.\n",
      "Last response for springfieldil received.  Process completed.\n",
      "\n",
      "Response #1 for Illinois: quincy received.\n",
      "Last response for quincy received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: bloomington received.\n",
      "Last response for bloomington received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: evansville received.\n",
      "Last response for evansville received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: fortwayne received.\n",
      "Last response for fortwayne received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: indianapolis received.\n",
      "Last response for indianapolis received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: kokomo received.\n",
      "Last response for kokomo received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: tippecanoe received.\n",
      "Last response for tippecanoe received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: muncie received.\n",
      "Last response for muncie received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: richmondin received.\n",
      "Last response for richmondin received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: southbend received.\n",
      "Last response for southbend received.  Process completed.\n",
      "\n",
      "Response #1 for Indiana: terrehaute received.\n",
      "Last response for terrehaute received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: ames received.\n",
      "Last response for ames received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: cedarrapids received.\n",
      "Last response for cedarrapids received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: desmoines received.\n",
      "Last response for desmoines received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: dubuque received.\n",
      "Last response for dubuque received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: fortdodge received.\n",
      "Last response for fortdodge received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: iowacity received.\n",
      "Last response for iowacity received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: masoncity received.\n",
      "Last response for masoncity received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: quadcities received.\n",
      "Last response for quadcities received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: siouxcity received.\n",
      "Last response for siouxcity received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: ottumwa received.\n",
      "Last response for ottumwa received.  Process completed.\n",
      "\n",
      "Response #1 for Iowa: waterloo received.\n",
      "Last response for waterloo received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: lawrence received.\n",
      "Last response for lawrence received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: ksu received.\n",
      "Last response for ksu received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: nwks received.\n",
      "Last response for nwks received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: salina received.\n",
      "Last response for salina received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: seks received.\n",
      "Last response for seks received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: swks received.\n",
      "Last response for swks received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: topeka received.\n",
      "Last response for topeka received.  Process completed.\n",
      "\n",
      "Response #1 for Kansas: wichita received.\n",
      "Last response for wichita received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: bgky received.\n",
      "Last response for bgky received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: eastky received.\n",
      "Last response for eastky received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: lexington received.\n",
      "Last response for lexington received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: louisville received.\n",
      "Last response for louisville received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: owensboro received.\n",
      "Last response for owensboro received.  Process completed.\n",
      "\n",
      "Response #1 for Kentucky: westky received.\n",
      "Last response for westky received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: batonrouge received.\n",
      "Last response for batonrouge received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: cenla received.\n",
      "Last response for cenla received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: houma received.\n",
      "Last response for houma received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: lafayette received.\n",
      "Last response for lafayette received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: lakecharles received.\n",
      "Last response for lakecharles received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: monroe received.\n",
      "Last response for monroe received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: neworleans received.\n",
      "Last response for neworleans received.  Process completed.\n",
      "\n",
      "Response #1 for Louisiana: shreveport received.\n",
      "Last response for shreveport received.  Process completed.\n",
      "\n",
      "Response #1 for Maine: maine received.\n",
      "Last response for maine received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: annapolis received.\n",
      "Last response for annapolis received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: baltimore received.\n",
      "Last response for baltimore received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: easternshore received.\n",
      "Last response for easternshore received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: frederick received.\n",
      "Last response for frederick received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: smd received.\n",
      "Last response for smd received.  Process completed.\n",
      "\n",
      "Response #1 for Maryland: westmd received.\n",
      "Last response for westmd received.  Process completed.\n",
      "\n",
      "Response #1 for Massachusetts: boston received.\n",
      "boston 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "Last response for boston received.  Process completed.\n",
      "\n",
      "Response #1 for Massachusetts: capecod received.\n",
      "Last response for capecod received.  Process completed.\n",
      "\n",
      "Response #1 for Massachusetts: southcoast received.\n",
      "Last response for southcoast received.  Process completed.\n",
      "\n",
      "Response #1 for Massachusetts: westernmass received.\n",
      "Last response for westernmass received.  Process completed.\n",
      "\n",
      "Response #1 for Massachusetts: worcester received.\n",
      "Last response for worcester received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: annarbor received.\n",
      "Last response for annarbor received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: battlecreek received.\n",
      "Last response for battlecreek received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: centralmich received.\n",
      "Last response for centralmich received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: detroit received.\n",
      "Last response for detroit received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: flint received.\n",
      "Last response for flint received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: grandrapids received.\n",
      "Last response for grandrapids received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: holland received.\n",
      "Last response for holland received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: jxn received.\n",
      "Last response for jxn received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: kalamazoo received.\n",
      "Last response for kalamazoo received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: lansing received.\n",
      "Last response for lansing received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: monroemi received.\n",
      "Last response for monroemi received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: muskegon received.\n",
      "Last response for muskegon received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: nmi received.\n",
      "Last response for nmi received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: porthuron received.\n",
      "Last response for porthuron received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: saginaw received.\n",
      "Last response for saginaw received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: swmi received.\n",
      "Last response for swmi received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: thumb received.\n",
      "Last response for thumb received.  Process completed.\n",
      "\n",
      "Response #1 for Michigan: up received.\n",
      "Last response for up received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: bemidji received.\n",
      "Last response for bemidji received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: brainerd received.\n",
      "Last response for brainerd received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: duluth received.\n",
      "Last response for duluth received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: mankato received.\n",
      "Last response for mankato received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: minneapolis received.\n",
      "Last response for minneapolis received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: rmn received.\n",
      "Last response for rmn received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: marshall received.\n",
      "Last response for marshall received.  Process completed.\n",
      "\n",
      "Response #1 for Minnesota: stcloud received.\n",
      "Last response for stcloud received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: gulfport received.\n",
      "Last response for gulfport received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: hattiesburg received.\n",
      "Last response for hattiesburg received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: jackson received.\n",
      "Last response for jackson received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: meridian received.\n",
      "Last response for meridian received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: northmiss received.\n",
      "Last response for northmiss received.  Process completed.\n",
      "\n",
      "Response #1 for Mississippi: natchez received.\n",
      "Last response for natchez received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: columbiamo received.\n",
      "Last response for columbiamo received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: joplin received.\n",
      "Last response for joplin received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: kansascity received.\n",
      "Last response for kansascity received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: kirksville received.\n",
      "Last response for kirksville received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: loz received.\n",
      "Last response for loz received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: semo received.\n",
      "Last response for semo received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: springfield received.\n",
      "Last response for springfield received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: stjoseph received.\n",
      "Last response for stjoseph received.  Process completed.\n",
      "\n",
      "Response #1 for Missouri: stlouis received.\n",
      "Last response for stlouis received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: billings received.\n",
      "Last response for billings received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: bozeman received.\n",
      "Last response for bozeman received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: butte received.\n",
      "Last response for butte received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: greatfalls received.\n",
      "Last response for greatfalls received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: helena received.\n",
      "Last response for helena received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: kalispell received.\n",
      "Last response for kalispell received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: missoula received.\n",
      "Last response for missoula received.  Process completed.\n",
      "\n",
      "Response #1 for Montana: montana received.\n",
      "Last response for montana received.  Process completed.\n",
      "\n",
      "Response #1 for Nebraska: grandisland received.\n",
      "Last response for grandisland received.  Process completed.\n",
      "\n",
      "Response #1 for Nebraska: lincoln received.\n",
      "Last response for lincoln received.  Process completed.\n",
      "\n",
      "Response #1 for Nebraska: northplatte received.\n",
      "Last response for northplatte received.  Process completed.\n",
      "\n",
      "Response #1 for Nebraska: omaha received.\n",
      "Last response for omaha received.  Process completed.\n",
      "\n",
      "Response #1 for Nebraska: scottsbluff received.\n",
      "Last response for scottsbluff received.  Process completed.\n",
      "\n",
      "Response #1 for Nevada: elko received.\n",
      "Last response for elko received.  Process completed.\n",
      "\n",
      "Response #1 for Nevada: lasvegas received.\n",
      "Last response for lasvegas received.  Process completed.\n",
      "\n",
      "Response #1 for Nevada: reno received.\n",
      "Last response for reno received.  Process completed.\n",
      "\n",
      "Response #1 for New Hampshire: nh received.\n",
      "Last response for nh received.  Process completed.\n",
      "\n",
      "Response #1 for New Jersey: cnj received.\n",
      "Last response for cnj received.  Process completed.\n",
      "\n",
      "Response #1 for New Jersey: jerseyshore received.\n",
      "Last response for jerseyshore received.  Process completed.\n",
      "\n",
      "Response #1 for New Jersey: newjersey received.\n",
      "Last response for newjersey received.  Process completed.\n",
      "\n",
      "Response #1 for New Jersey: southjersey received.\n",
      "Last response for southjersey received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: albuquerque received.\n",
      "Last response for albuquerque received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: clovis received.\n",
      "Last response for clovis received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: farmington received.\n",
      "Last response for farmington received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: lascruces received.\n",
      "Last response for lascruces received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: roswell received.\n",
      "Last response for roswell received.  Process completed.\n",
      "\n",
      "Response #1 for New Mexico: santafe received.\n",
      "Last response for santafe received.  Process completed.\n",
      "\n",
      "Response #1 for New York: albany received.\n",
      "Last response for albany received.  Process completed.\n",
      "\n",
      "Response #1 for New York: binghamton received.\n",
      "Last response for binghamton received.  Process completed.\n",
      "\n",
      "Response #1 for New York: buffalo received.\n",
      "Last response for buffalo received.  Process completed.\n",
      "\n",
      "Response #1 for New York: catskills received.\n",
      "Last response for catskills received.  Process completed.\n",
      "\n",
      "Response #1 for New York: chautauqua received.\n",
      "Last response for chautauqua received.  Process completed.\n",
      "\n",
      "Response #1 for New York: elmira received.\n",
      "Last response for elmira received.  Process completed.\n",
      "\n",
      "Response #1 for New York: fingerlakes received.\n",
      "Last response for fingerlakes received.  Process completed.\n",
      "\n",
      "Response #1 for New York: glensfalls received.\n",
      "Last response for glensfalls received.  Process completed.\n",
      "\n",
      "Response #1 for New York: hudsonvalley received.\n",
      "Last response for hudsonvalley received.  Process completed.\n",
      "\n",
      "Response #1 for New York: ithaca received.\n",
      "Last response for ithaca received.  Process completed.\n",
      "\n",
      "Response #1 for New York: longisland received.\n",
      "Last response for longisland received.  Process completed.\n",
      "\n",
      "Response #1 for New York: newyork received.\n",
      "newyork 2 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "newyork 3 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "newyork 4 response received.\n",
      "Waiting 2 seconds...\n",
      "\n",
      "Last response for newyork received.  Process completed.\n",
      "\n",
      "Response #1 for New York: oneonta received.\n",
      "Last response for oneonta received.  Process completed.\n",
      "\n",
      "Response #1 for New York: plattsburgh received.\n",
      "Last response for plattsburgh received.  Process completed.\n",
      "\n",
      "Response #1 for New York: potsdam received.\n",
      "Last response for potsdam received.  Process completed.\n",
      "\n",
      "Response #1 for New York: rochester received.\n",
      "Last response for rochester received.  Process completed.\n",
      "\n",
      "Response #1 for New York: syracuse received.\n",
      "Last response for syracuse received.  Process completed.\n",
      "\n",
      "Response #1 for New York: twintiers received.\n",
      "Last response for twintiers received.  Process completed.\n",
      "\n",
      "Response #1 for New York: utica received.\n",
      "Last response for utica received.  Process completed.\n",
      "\n",
      "Response #1 for New York: watertown received.\n",
      "Last response for watertown received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: asheville received.\n",
      "Last response for asheville received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: boone received.\n",
      "Last response for boone received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: charlotte received.\n",
      "Last response for charlotte received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: eastnc received.\n",
      "Last response for eastnc received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: fayetteville received.\n",
      "Last response for fayetteville received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: greensboro received.\n",
      "Last response for greensboro received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: hickory received.\n",
      "Last response for hickory received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: onslow received.\n",
      "Last response for onslow received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: outerbanks received.\n",
      "Last response for outerbanks received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: raleigh received.\n",
      "Last response for raleigh received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: wilmington received.\n",
      "Last response for wilmington received.  Process completed.\n",
      "\n",
      "Response #1 for North Carolina: winstonsalem received.\n",
      "Last response for winstonsalem received.  Process completed.\n",
      "\n",
      "Response #1 for North Dakota: bismarck received.\n",
      "Last response for bismarck received.  Process completed.\n",
      "\n",
      "Response #1 for North Dakota: fargo received.\n",
      "Last response for fargo received.  Process completed.\n",
      "\n",
      "Response #1 for North Dakota: grandforks received.\n",
      "Last response for grandforks received.  Process completed.\n",
      "\n",
      "Response #1 for North Dakota: nd received.\n",
      "Last response for nd received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: akroncanton received.\n",
      "Last response for akroncanton received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: ashtabula received.\n",
      "Last response for ashtabula received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: athensohio received.\n",
      "Last response for athensohio received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: chillicothe received.\n",
      "Last response for chillicothe received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: cincinnati received.\n",
      "Last response for cincinnati received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: cleveland received.\n",
      "Last response for cleveland received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: columbus received.\n",
      "Last response for columbus received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: dayton received.\n",
      "Last response for dayton received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: limaohio received.\n",
      "Last response for limaohio received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: mansfield received.\n",
      "Last response for mansfield received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: sandusky received.\n",
      "Last response for sandusky received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: toledo received.\n",
      "Last response for toledo received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: tuscarawas received.\n",
      "Last response for tuscarawas received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: youngstown received.\n",
      "Last response for youngstown received.  Process completed.\n",
      "\n",
      "Response #1 for Ohio: zanesville received.\n",
      "Last response for zanesville received.  Process completed.\n",
      "\n",
      "Response #1 for Oklahoma: lawton received.\n",
      "Last response for lawton received.  Process completed.\n",
      "\n",
      "Response #1 for Oklahoma: enid received.\n",
      "Last response for enid received.  Process completed.\n",
      "\n",
      "Response #1 for Oklahoma: oklahomacity received.\n",
      "Last response for oklahomacity received.  Process completed.\n",
      "\n",
      "Response #1 for Oklahoma: stillwater received.\n",
      "Last response for stillwater received.  Process completed.\n",
      "\n",
      "Response #1 for Oklahoma: tulsa received.\n",
      "Last response for tulsa received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: bend received.\n",
      "Last response for bend received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: corvallis received.\n",
      "Last response for corvallis received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: eastoregon received.\n",
      "Last response for eastoregon received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: eugene received.\n",
      "Last response for eugene received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: klamath received.\n",
      "Last response for klamath received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: medford received.\n",
      "Last response for medford received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: oregoncoast received.\n",
      "Last response for oregoncoast received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: portland received.\n",
      "Last response for portland received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: roseburg received.\n",
      "Last response for roseburg received.  Process completed.\n",
      "\n",
      "Response #1 for Oregon: salem received.\n",
      "Last response for salem received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: altoona received.\n",
      "Last response for altoona received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: chambersburg received.\n",
      "Last response for chambersburg received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: erie received.\n",
      "Last response for erie received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: harrisburg received.\n",
      "Last response for harrisburg received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: lancaster received.\n",
      "Last response for lancaster received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: allentown received.\n",
      "Last response for allentown received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: meadville received.\n",
      "Last response for meadville received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: philadelphia received.\n",
      "Last response for philadelphia received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: pittsburgh received.\n",
      "Last response for pittsburgh received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: poconos received.\n",
      "Last response for poconos received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: reading received.\n",
      "Last response for reading received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: scranton received.\n",
      "Last response for scranton received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: pennstate received.\n",
      "Last response for pennstate received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: williamsport received.\n",
      "Last response for williamsport received.  Process completed.\n",
      "\n",
      "Response #1 for Pennsylvania: york received.\n",
      "Last response for york received.  Process completed.\n",
      "\n",
      "Response #1 for Rhode Island: providence received.\n",
      "Last response for providence received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: charleston received.\n",
      "Last response for charleston received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: columbia received.\n",
      "Last response for columbia received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: florencesc received.\n",
      "Last response for florencesc received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: greenville received.\n",
      "Last response for greenville received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: hiltonhead received.\n",
      "Last response for hiltonhead received.  Process completed.\n",
      "\n",
      "Response #1 for South Carolina: myrtlebeach received.\n",
      "Last response for myrtlebeach received.  Process completed.\n",
      "\n",
      "Response #1 for South Dakota: nesd received.\n",
      "Last response for nesd received.  Process completed.\n",
      "\n",
      "Response #1 for South Dakota: csd received.\n",
      "Last response for csd received.  Process completed.\n",
      "\n",
      "Response #1 for South Dakota: rapidcity received.\n",
      "Last response for rapidcity received.  Process completed.\n",
      "\n",
      "Response #1 for South Dakota: siouxfalls received.\n",
      "Last response for siouxfalls received.  Process completed.\n",
      "\n",
      "Response #1 for South Dakota: sd received.\n",
      "Last response for sd received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: chattanooga received.\n",
      "Last response for chattanooga received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: clarksville received.\n",
      "Last response for clarksville received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: cookeville received.\n",
      "Last response for cookeville received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: jacksontn received.\n",
      "Last response for jacksontn received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: knoxville received.\n",
      "Last response for knoxville received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: memphis received.\n",
      "Last response for memphis received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: nashville received.\n",
      "Last response for nashville received.  Process completed.\n",
      "\n",
      "Response #1 for Tennessee: tricities received.\n",
      "Last response for tricities received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: abilene received.\n",
      "Last response for abilene received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: amarillo received.\n",
      "Last response for amarillo received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: austin received.\n",
      "Last response for austin received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: beaumont received.\n",
      "Last response for beaumont received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: brownsville received.\n",
      "Last response for brownsville received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: collegestation received.\n",
      "Last response for collegestation received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: corpuschristi received.\n",
      "Last response for corpuschristi received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: dallas received.\n",
      "dallas 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "Last response for dallas received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: nacogdoches received.\n",
      "Last response for nacogdoches received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: delrio received.\n",
      "Last response for delrio received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: elpaso received.\n",
      "Last response for elpaso received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: galveston received.\n",
      "Last response for galveston received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: houston received.\n",
      "Last response for houston received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: killeen received.\n",
      "Last response for killeen received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: laredo received.\n",
      "Last response for laredo received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: lubbock received.\n",
      "Last response for lubbock received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: mcallen received.\n",
      "Last response for mcallen received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: odessa received.\n",
      "Last response for odessa received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: sanangelo received.\n",
      "Last response for sanangelo received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: sanantonio received.\n",
      "Last response for sanantonio received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: sanmarcos received.\n",
      "Last response for sanmarcos received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: bigbend received.\n",
      "Last response for bigbend received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: texoma received.\n",
      "Last response for texoma received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: easttexas received.\n",
      "Last response for easttexas received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: victoriatx received.\n",
      "Last response for victoriatx received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: waco received.\n",
      "Last response for waco received.  Process completed.\n",
      "\n",
      "Response #1 for Texas: wichitafalls received.\n",
      "Last response for wichitafalls received.  Process completed.\n",
      "\n",
      "Response #1 for Utah: logan received.\n",
      "Last response for logan received.  Process completed.\n",
      "\n",
      "Response #1 for Utah: ogden received.\n",
      "Last response for ogden received.  Process completed.\n",
      "\n",
      "Response #1 for Utah: provo received.\n",
      "Last response for provo received.  Process completed.\n",
      "\n",
      "Response #1 for Utah: saltlakecity received.\n",
      "Last response for saltlakecity received.  Process completed.\n",
      "\n",
      "Response #1 for Utah: stgeorge received.\n",
      "Last response for stgeorge received.  Process completed.\n",
      "\n",
      "Response #1 for Vermont: vermont received.\n",
      "Last response for vermont received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: charlottesville received.\n",
      "Last response for charlottesville received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: danville received.\n",
      "Last response for danville received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: fredericksburg received.\n",
      "Last response for fredericksburg received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: norfolk received.\n",
      "Last response for norfolk received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: harrisonburg received.\n",
      "Last response for harrisonburg received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: lynchburg received.\n",
      "Last response for lynchburg received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: blacksburg received.\n",
      "Last response for blacksburg received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: richmond received.\n",
      "Last response for richmond received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: roanoke received.\n",
      "Last response for roanoke received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: swva received.\n",
      "Last response for swva received.  Process completed.\n",
      "\n",
      "Response #1 for Virginia: winchester received.\n",
      "Last response for winchester received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: bellingham received.\n",
      "Last response for bellingham received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: kpr received.\n",
      "Last response for kpr received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: moseslake received.\n",
      "Last response for moseslake received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: olympic received.\n",
      "Last response for olympic received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: pullman received.\n",
      "Last response for pullman received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: seattle received.\n",
      "seattle 2 response received.\n",
      "Waiting 4 seconds...\n",
      "\n",
      "Last response for seattle received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: skagit received.\n",
      "Last response for skagit received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: spokane received.\n",
      "Last response for spokane received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: wenatchee received.\n",
      "Last response for wenatchee received.  Process completed.\n",
      "\n",
      "Response #1 for Washington: yakima received.\n",
      "Last response for yakima received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: charlestonwv received.\n",
      "Last response for charlestonwv received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: martinsburg received.\n",
      "Last response for martinsburg received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: huntington received.\n",
      "Last response for huntington received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: morgantown received.\n",
      "Last response for morgantown received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: wheeling received.\n",
      "Last response for wheeling received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: parkersburg received.\n",
      "Last response for parkersburg received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: swv received.\n",
      "Last response for swv received.  Process completed.\n",
      "\n",
      "Response #1 for West Virginia: wv received.\n",
      "Last response for wv received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: appleton received.\n",
      "Last response for appleton received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: eauclaire received.\n",
      "Last response for eauclaire received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: greenbay received.\n",
      "Last response for greenbay received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: janesville received.\n",
      "Last response for janesville received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: racine received.\n",
      "Last response for racine received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: lacrosse received.\n",
      "Last response for lacrosse received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: madison received.\n",
      "Last response for madison received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: milwaukee received.\n",
      "Last response for milwaukee received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: northernwi received.\n",
      "Last response for northernwi received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: sheboygan received.\n",
      "Last response for sheboygan received.  Process completed.\n",
      "\n",
      "Response #1 for Wisconsin: wausau received.\n",
      "Last response for wausau received.  Process completed.\n",
      "\n",
      "Response #1 for Wyoming: wyoming received.\n",
      "Last response for wyoming received.  Process completed.\n",
      "\n",
      "Response #1 for Territories: micronesia received.\n",
      "Last response for micronesia received.  Process completed.\n",
      "\n",
      "Response #1 for Territories: puertorico received.\n",
      "Last response for puertorico received.  Process completed.\n",
      "\n",
      "Response #1 for Territories: virgin received.\n",
      "Last response for virgin received.  Process completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Walk through each state in our state_Dict to get the HTML page corresponding to a search for \"math tutor\" in the services section\n",
    "response_dict = {}\n",
    "\n",
    "for state in state_dict.keys():\n",
    "\n",
    "    for region in state_dict[state]:\n",
    "        # This gets the first page of search results\n",
    "        i=1\n",
    "        \n",
    "        current_response = session.get('https://' + region + '.craigslist.org/d/services/search/bbb?query=math%20tutor&sort=rel')\n",
    "        \n",
    "        sleep_timer = random.randint(2,4)\n",
    "        time.sleep(sleep_timer)\n",
    "        \n",
    "        print(F\"Response #{i} for {state}: {region} received.\")\n",
    "        #print(F\"Waiting {sleep_timer} seconds...\")\n",
    "        #print()\n",
    "        \n",
    "        region_response_list = []\n",
    "        region_response_list.append(current_response)\n",
    "\n",
    "        # This gets all subsequent pages, using the next button from the search page\n",
    "        is_next_button = True\n",
    "        while is_next_button:\n",
    "            try:\n",
    "                next_response = current_response\n",
    "                next_soup = BeautifulSoup(next_response.text, 'html.parser')\n",
    "                \n",
    "# CL search pages have one of the following:\n",
    "    # 1) A next button:\n",
    "        # - when the region contains more than 120 posts for a given search\n",
    "    # 2) A greyed out next button:\n",
    "        # - when you've reached the last page of search results and there are no more\n",
    "        # OR\n",
    "        # - when a page has less than 120 results.\n",
    "    # 3) No next button:\n",
    "        # - when a page has less than 120 results\n",
    "# html suffix is None type when a next button isn't shown\n",
    "# html suffix is '' when the next button is greyed out.  This can happen in either case 2) or 3) from above\n",
    "# The while loop only needs to be peformed in case 1) when there is a next button you can click\n",
    "                html_suffix = next_soup.find(class_='button next')\n",
    "                #print(html_suffix)\n",
    "                if html_suffix is not None:\n",
    "                    html_suffix = html_suffix.get('href')\n",
    "                    #print(\"html_suffix is not none\")\n",
    "                    if html_suffix != '':\n",
    "                        i += 1\n",
    "                        #print(i, html_suffix)\n",
    "                        #print('html_suffix is not blank')\n",
    "                        new_button = 'https://' + region + '.craigslist.org' + html_suffix\n",
    "                        current_response = session.get(new_button)\n",
    "                        region_response_list.append(current_response)\n",
    "\n",
    "                        sleep_timer = random.randint(2,4)\n",
    "                        time.sleep(sleep_timer)\n",
    "                        print(F\"{region} {i} response received.\")\n",
    "                        print(F\"Waiting {sleep_timer} seconds...\")\n",
    "                        print()\n",
    "                    else:\n",
    "                        is_next_button = False\n",
    "                        #print('html_suffix is blank')\n",
    "                        print(F\"Last response for {region} received.  Process completed.\")\n",
    "                        print()\n",
    "                else:\n",
    "                    is_next_button = False\n",
    "                    #print('next_button is None')\n",
    "                    print(F\"Last response for {region} received.  Process completed.\")\n",
    "                    print()\n",
    "                    pass\n",
    "            except:\n",
    "                is_next_button = False\n",
    "                pass\n",
    "\n",
    "        # Store all search pages for math tutor\n",
    "        response_dict[(state, region)] = region_response_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb10f8b-f041-4af6-affb-ac25ba061207",
   "metadata": {},
   "source": [
    "## Get URL for each individual posting in a state/region combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0510527-c07e-4dc9-8401-62b375917a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk through each state/region combo to get a list of all individual postings for math tutoring in the results pages we searched up earlier.\n",
    "posts_dict = {}\n",
    "for key, responses in response_dict.items():\n",
    "    state = key[0]\n",
    "    region = key[1]\n",
    "    #current_region = region\n",
    "    region_posts = []\n",
    "    for response in responses:\n",
    "        current_html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        current_posts = current_html_soup.find_all('li', class_='result-row')\n",
    "        wanted_posts = []\n",
    "        for post in current_posts:\n",
    "# Many CL pages have \"results from nearby areas\", for instance some results for sandiego.craigslist.org show up in the losangeles.craigslist.org.  By comparing the region that we're currently scraping from against the URL of the posts, we can detect if it's from a nearby region or not.  To avoid duplicates and make the script finish more quickly, We only want to include posts where the URL of the post matches the region we're scraping from\n",
    "            if post.a.get('href').replace('https://','').split('.')[0] == region:\n",
    "                wanted_posts.append(post)\n",
    "        region_posts.extend(wanted_posts)\n",
    "    posts_dict[(state,region)] = region_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec63701-abcd-4878-af83-fc7c3a38c865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many posts in total are to be scraped for countdown timer\n",
    "\n",
    "num_regions = len(posts_dict)\n",
    "\n",
    "num_posts = 0\n",
    "for region in posts_dict:\n",
    "    num_posts += len(posts_dict[region])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef209c4b-6e29-4707-8b69-d1cea179b9a9",
   "metadata": {},
   "source": [
    "## Getting soup object response for each individual post in a state/region combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e60e4c-018d-4599-9eae-41604def20d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time is 23:13:10\n",
      "Process estimated to finish before 04:07:46\n",
      "\n",
      "Soup objects for Alabama:auburn acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:25\n",
      "\n",
      "Soup objects for Alabama:bham acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:20\n",
      "\n",
      "Soup objects for Alabama:dothan acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:20\n",
      "\n",
      "Soup objects for Alabama:shoals acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:20\n",
      "\n",
      "Soup objects for Alabama:gadsden acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:20\n",
      "\n",
      "Soup objects for Alabama:huntsville acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:18\n",
      "\n",
      "Soup objects for Alabama:mobile acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:18\n",
      "\n",
      "Soup objects for Alabama:montgomery acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:16\n",
      "\n",
      "Soup objects for Alabama:tuscaloosa acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:16\n",
      "\n",
      "Soup objects for Alaska:anchorage acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:08\n",
      "\n",
      "Soup objects for Alaska:fairbanks acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:08\n",
      "\n",
      "Soup objects for Alaska:kenai acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:08\n",
      "\n",
      "Soup objects for Alaska:juneau acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:08\n",
      "\n",
      "Soup objects for Arizona:flagstaff acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:01\n",
      "\n",
      "Soup objects for Arizona:mohave acquired.  Waiting for next region...\n",
      "Process will now finish by 05:21:01\n",
      "\n",
      "Post number 10 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 20 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 30 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 40 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 50 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 60 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 70 in ('Arizona', 'phoenix') is being extracted.\n",
      "Post number 80 in ('Arizona', 'phoenix') is being extracted.\n",
      "Soup objects for Arizona:phoenix acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:23\n",
      "\n",
      "Soup objects for Arizona:prescott acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:23\n",
      "\n",
      "Soup objects for Arizona:showlow acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:23\n",
      "\n",
      "Soup objects for Arizona:sierravista acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:23\n",
      "\n",
      "Post number 10 in ('Arizona', 'tucson') is being extracted.\n",
      "Soup objects for Arizona:tucson acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:02\n",
      "\n",
      "Soup objects for Arizona:yuma acquired.  Waiting for next region...\n",
      "Process will now finish by 05:18:00\n",
      "\n",
      "Soup objects for Arkansas:fayar acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:57\n",
      "\n",
      "Soup objects for Arkansas:fortsmith acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:57\n",
      "\n",
      "Soup objects for Arkansas:jonesboro acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:55\n",
      "\n",
      "Soup objects for Arkansas:littlerock acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:55\n",
      "\n",
      "Soup objects for Arkansas:texarkana acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:55\n",
      "\n",
      "Soup objects for California:bakersfield acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:47\n",
      "\n",
      "Soup objects for California:chico acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:40\n",
      "\n",
      "Soup objects for California:fresno acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:28\n",
      "\n",
      "Soup objects for California:goldcountry acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:25\n",
      "\n",
      "Soup objects for California:hanford acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:25\n",
      "\n",
      "Soup objects for California:humboldt acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:23\n",
      "\n",
      "Soup objects for California:imperial acquired.  Waiting for next region...\n",
      "Process will now finish by 05:17:23\n",
      "\n",
      "Post number 10 in ('California', 'inlandempire') is being extracted.\n",
      "Post number 20 in ('California', 'inlandempire') is being extracted.\n",
      "Post number 30 in ('California', 'inlandempire') is being extracted.\n",
      "Post number 40 in ('California', 'inlandempire') is being extracted.\n",
      "Post number 50 in ('California', 'inlandempire') is being extracted.\n",
      "Soup objects for California:inlandempire acquired.  Waiting for next region...\n",
      "Process will now finish by 05:15:45\n",
      "\n",
      "Post number 10 in ('California', 'losangeles') is being extracted.\n",
      "Post number 20 in ('California', 'losangeles') is being extracted.\n",
      "Post number 30 in ('California', 'losangeles') is being extracted.\n",
      "Post number 40 in ('California', 'losangeles') is being extracted.\n",
      "Post number 50 in ('California', 'losangeles') is being extracted.\n",
      "Post number 60 in ('California', 'losangeles') is being extracted.\n",
      "Post number 70 in ('California', 'losangeles') is being extracted.\n",
      "Post number 80 in ('California', 'losangeles') is being extracted.\n",
      "Post number 90 in ('California', 'losangeles') is being extracted.\n",
      "Post number 100 in ('California', 'losangeles') is being extracted.\n",
      "Post number 110 in ('California', 'losangeles') is being extracted.\n",
      "Post number 120 in ('California', 'losangeles') is being extracted.\n",
      "Post number 130 in ('California', 'losangeles') is being extracted.\n",
      "Post number 140 in ('California', 'losangeles') is being extracted.\n",
      "Post number 150 in ('California', 'losangeles') is being extracted.\n",
      "Post number 160 in ('California', 'losangeles') is being extracted.\n",
      "Post number 170 in ('California', 'losangeles') is being extracted.\n",
      "Post number 180 in ('California', 'losangeles') is being extracted.\n",
      "Post number 190 in ('California', 'losangeles') is being extracted.\n",
      "Post number 200 in ('California', 'losangeles') is being extracted.\n",
      "Post number 210 in ('California', 'losangeles') is being extracted.\n",
      "Post number 220 in ('California', 'losangeles') is being extracted.\n",
      "Post number 230 in ('California', 'losangeles') is being extracted.\n",
      "Post number 240 in ('California', 'losangeles') is being extracted.\n",
      "Post number 250 in ('California', 'losangeles') is being extracted.\n",
      "Post number 260 in ('California', 'losangeles') is being extracted.\n",
      "Post number 270 in ('California', 'losangeles') is being extracted.\n",
      "Post number 280 in ('California', 'losangeles') is being extracted.\n",
      "Post number 290 in ('California', 'losangeles') is being extracted.\n",
      "Post number 300 in ('California', 'losangeles') is being extracted.\n",
      "Post number 310 in ('California', 'losangeles') is being extracted.\n",
      "Post number 320 in ('California', 'losangeles') is being extracted.\n",
      "Post number 330 in ('California', 'losangeles') is being extracted.\n",
      "Soup objects for California:losangeles acquired.  Waiting for next region...\n",
      "Process will now finish by 05:04:53\n",
      "\n",
      "Soup objects for California:mendocino acquired.  Waiting for next region...\n",
      "Process will now finish by 05:04:53\n",
      "\n",
      "Soup objects for California:merced acquired.  Waiting for next region...\n",
      "Process will now finish by 05:04:50\n",
      "\n",
      "Soup objects for California:modesto acquired.  Waiting for next region...\n",
      "Process will now finish by 05:04:44\n",
      "\n",
      "Soup objects for California:monterey acquired.  Waiting for next region...\n",
      "Process will now finish by 05:04:42\n",
      "\n",
      "Post number 10 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 20 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 30 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 40 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 50 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 60 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 70 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 80 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 90 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 100 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 110 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 120 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 130 in ('California', 'orangecounty') is being extracted.\n",
      "Post number 140 in ('California', 'orangecounty') is being extracted.\n",
      "Soup objects for California:orangecounty acquired.  Waiting for next region...\n",
      "Process will now finish by 04:59:55\n",
      "\n",
      "Soup objects for California:palmsprings acquired.  Waiting for next region...\n",
      "Process will now finish by 04:59:46\n",
      "\n",
      "Soup objects for California:redding acquired.  Waiting for next region...\n",
      "Process will now finish by 04:59:44\n",
      "\n",
      "Post number 10 in ('California', 'sacramento') is being extracted.\n",
      "Post number 20 in ('California', 'sacramento') is being extracted.\n",
      "Post number 30 in ('California', 'sacramento') is being extracted.\n",
      "Post number 40 in ('California', 'sacramento') is being extracted.\n",
      "Post number 50 in ('California', 'sacramento') is being extracted.\n",
      "Post number 60 in ('California', 'sacramento') is being extracted.\n",
      "Post number 70 in ('California', 'sacramento') is being extracted.\n",
      "Post number 80 in ('California', 'sacramento') is being extracted.\n",
      "Soup objects for California:sacramento acquired.  Waiting for next region...\n",
      "Process will now finish by 04:56:54\n",
      "\n",
      "Post number 10 in ('California', 'sandiego') is being extracted.\n",
      "Post number 20 in ('California', 'sandiego') is being extracted.\n",
      "Post number 30 in ('California', 'sandiego') is being extracted.\n",
      "Post number 40 in ('California', 'sandiego') is being extracted.\n",
      "Post number 50 in ('California', 'sandiego') is being extracted.\n",
      "Post number 60 in ('California', 'sandiego') is being extracted.\n",
      "Post number 70 in ('California', 'sandiego') is being extracted.\n",
      "Post number 80 in ('California', 'sandiego') is being extracted.\n",
      "Post number 90 in ('California', 'sandiego') is being extracted.\n",
      "Post number 100 in ('California', 'sandiego') is being extracted.\n",
      "Post number 110 in ('California', 'sandiego') is being extracted.\n",
      "Post number 120 in ('California', 'sandiego') is being extracted.\n",
      "Post number 130 in ('California', 'sandiego') is being extracted.\n",
      "Post number 140 in ('California', 'sandiego') is being extracted.\n",
      "Post number 150 in ('California', 'sandiego') is being extracted.\n",
      "Post number 160 in ('California', 'sandiego') is being extracted.\n",
      "Soup objects for California:sandiego acquired.  Waiting for next region...\n",
      "Process will now finish by 04:51:43\n",
      "\n",
      "Post number 10 in ('California', 'sfbay') is being extracted.\n",
      "Post number 20 in ('California', 'sfbay') is being extracted.\n",
      "Post number 30 in ('California', 'sfbay') is being extracted.\n",
      "Post number 40 in ('California', 'sfbay') is being extracted.\n",
      "Post number 50 in ('California', 'sfbay') is being extracted.\n",
      "Post number 60 in ('California', 'sfbay') is being extracted.\n",
      "Post number 70 in ('California', 'sfbay') is being extracted.\n",
      "Post number 80 in ('California', 'sfbay') is being extracted.\n",
      "Post number 90 in ('California', 'sfbay') is being extracted.\n",
      "Post number 100 in ('California', 'sfbay') is being extracted.\n",
      "Post number 110 in ('California', 'sfbay') is being extracted.\n",
      "Post number 120 in ('California', 'sfbay') is being extracted.\n",
      "Post number 130 in ('California', 'sfbay') is being extracted.\n",
      "Post number 140 in ('California', 'sfbay') is being extracted.\n",
      "Post number 150 in ('California', 'sfbay') is being extracted.\n",
      "Post number 160 in ('California', 'sfbay') is being extracted.\n",
      "Post number 170 in ('California', 'sfbay') is being extracted.\n",
      "Post number 180 in ('California', 'sfbay') is being extracted.\n",
      "Post number 190 in ('California', 'sfbay') is being extracted.\n",
      "Post number 200 in ('California', 'sfbay') is being extracted.\n",
      "Post number 210 in ('California', 'sfbay') is being extracted.\n",
      "Post number 220 in ('California', 'sfbay') is being extracted.\n",
      "Post number 230 in ('California', 'sfbay') is being extracted.\n",
      "Post number 240 in ('California', 'sfbay') is being extracted.\n",
      "Post number 250 in ('California', 'sfbay') is being extracted.\n",
      "Post number 260 in ('California', 'sfbay') is being extracted.\n",
      "Post number 270 in ('California', 'sfbay') is being extracted.\n",
      "Post number 280 in ('California', 'sfbay') is being extracted.\n",
      "Post number 290 in ('California', 'sfbay') is being extracted.\n",
      "Post number 300 in ('California', 'sfbay') is being extracted.\n",
      "Post number 310 in ('California', 'sfbay') is being extracted.\n",
      "Post number 320 in ('California', 'sfbay') is being extracted.\n",
      "Post number 330 in ('California', 'sfbay') is being extracted.\n",
      "Post number 340 in ('California', 'sfbay') is being extracted.\n",
      "Post number 350 in ('California', 'sfbay') is being extracted.\n",
      "Post number 360 in ('California', 'sfbay') is being extracted.\n",
      "Post number 370 in ('California', 'sfbay') is being extracted.\n",
      "Post number 380 in ('California', 'sfbay') is being extracted.\n",
      "Post number 390 in ('California', 'sfbay') is being extracted.\n",
      "Post number 400 in ('California', 'sfbay') is being extracted.\n",
      "Soup objects for California:sfbay acquired.  Waiting for next region...\n",
      "Process will now finish by 04:38:43\n",
      "\n",
      "Soup objects for California:slo acquired.  Waiting for next region...\n",
      "Process will now finish by 04:38:37\n",
      "\n",
      "Post number 10 in ('California', 'santabarbara') is being extracted.\n",
      "Soup objects for California:santabarbara acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:58\n",
      "\n",
      "Soup objects for California:santamaria acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:58\n",
      "\n",
      "Soup objects for California:siskiyou acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:58\n",
      "\n",
      "Soup objects for California:stockton acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:56\n",
      "\n",
      "Soup objects for California:susanville acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:56\n",
      "\n",
      "Post number 10 in ('California', 'ventura') is being extracted.\n",
      "Soup objects for California:ventura acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:36\n",
      "\n",
      "Soup objects for California:visalia acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:36\n",
      "\n",
      "Soup objects for California:yubasutter acquired.  Waiting for next region...\n",
      "Process will now finish by 04:37:35\n",
      "\n",
      "Post number 10 in ('Colorado', 'boulder') is being extracted.\n",
      "Post number 20 in ('Colorado', 'boulder') is being extracted.\n",
      "Soup objects for Colorado:boulder acquired.  Waiting for next region...\n",
      "Process will now finish by 04:36:56\n",
      "\n",
      "Soup objects for Colorado:cosprings acquired.  Waiting for next region...\n",
      "Process will now finish by 04:36:37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup_objects_dict = {}\n",
    "\n",
    "num_posts_remaining = num_posts\n",
    "current_time = dt.datetime.now()\n",
    "max_seconds_until_finish = num_posts * 4\n",
    "max_finish_time = current_time + dt.timedelta(seconds=max_seconds_until_finish)\n",
    "\n",
    "print(F\"Current time is {current_time.strftime('%H:%M:%S')}\")\n",
    "print(F\"Process estimated to finish before {max_finish_time.strftime('%H:%M:%S')}\")\n",
    "print()\n",
    "\n",
    "for count, key in enumerate(posts_dict, start=1):\n",
    "    # Walk through each region and create a list of soup_objects to scrape from by storing them into memory.  This way we only have to send these get requests once and Craigslist doesn't ban us for sending the same https requests over and over\n",
    "    soup_objects_list = []\n",
    "    for i, post in enumerate(posts_dict[key]):\n",
    "        \n",
    "        # Impose a timer to help prevent from getting banned for too many HTTP requests in too short a time period.\n",
    "        random_int = random.randint(2,4)\n",
    "        time.sleep(random_int)\n",
    "        current_link = post.a.get('href')\n",
    "        response_object = session.get(current_link)\n",
    "        soup_object = BeautifulSoup(response_object.text, 'html.parser')\n",
    "        soup_objects_list.append(soup_object) \n",
    "        \n",
    "        # Impose condition that every 10th post will trigger something printed to the screen.  This part of the code is a long process and I wanted something to help keep track of how much progress has been made\n",
    "        if (i !=0) and ((i-1) % 10 == 9):\n",
    "            print(F\"Post number {i} in {key} is being extracted.\")\n",
    "    \n",
    "    soup_objects_dict[key] = soup_objects_list\n",
    "    if count != len(posts_dict):\n",
    "        num_posts_remaining -= len(posts_dict[key])\n",
    "        current_time = dt.datetime.now()\n",
    "        new_seconds_until_finish = num_posts_remaining * 5\n",
    "        new_max_finish_time = current_time + dt.timedelta(seconds=new_seconds_until_finish)\n",
    "        \n",
    "        state = key[0]\n",
    "        region = key[1]\n",
    "        \n",
    "        print(F\"Soup objects for {state}: {region} acquired.  Waiting for next region...\")\n",
    "        print(F\"Process will now finish by {new_max_finish_time.strftime('%H:%M:%S')}\")\n",
    "        print()\n",
    "    else:\n",
    "        print()\n",
    "        print(F\"Soup objects for {key} acquired.  Process complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde867cd-6852-41e5-ab1b-33894c159a75",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "### Extracting information from each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0923e6-8d92-46f9-afd5-fcde738a3803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "error_list_text = []\n",
    "error_list_links = []\n",
    "\n",
    "# Walk through lists of soup objects corresponding to an individual posting for a math tutor in a given search_region.\n",
    "for search_region in soup_objects_dict:\n",
    "    # Initialize several lists to store relevant information for analysis\n",
    "    price_list = []\n",
    "    city_list = []\n",
    "    datetime_list = []\n",
    "    body_text_list = []\n",
    "    subregion_list = []\n",
    "    region_list = []\n",
    "    link_list = []\n",
    "    search_region_price_list = []\n",
    "    state_list = []\n",
    "    \n",
    "    # Walk through each soup object in the list corresponding to the search region\n",
    "    for soup in soup_objects_dict[search_region]:\n",
    "        try:\n",
    "            # Get link of post\n",
    "            link = soup.find(\"meta\", property=\"og:url\")['content']\n",
    "        except:\n",
    "            # In case a link can't be found, we add the soup object to a list to inspect later and set link to 'None', which we'll use as a filter later so Python doesn't try to scrape from them.  Without a link, we don't want to scrape though, so we pass to the next iteration of the loop.\n",
    "            link = 'None'\n",
    "            error_list_links.append(soup)\n",
    "            pass\n",
    "            #print(\"Couldn't get link\")\n",
    "            \n",
    "        try:\n",
    "            # Extract region of post from Craigslist\n",
    "            post_region = soup.find_all('li',class_='crumb area')[0].find('a').get_text()\n",
    "            if post_region=='sf bay area':\n",
    "                post_region = 'sfbay'\n",
    "            else:\n",
    "                post_region = post_region.replace(' ', '')\n",
    "            post_region = post_region.lower()\n",
    "            \n",
    "        except:\n",
    "            post_region = 'region not found'\n",
    "        \n",
    "        # Get text of postingbody of the post and remove unwanted text.\n",
    "        try:\n",
    "            text = soup.find('section', id='postingbody').get_text()\n",
    "            text = text.replace(u'\\xa0', u' ')\n",
    "            # We do this so that we can use ; as a delimiter when copying data from a CSV file into a SQL database later.\n",
    "            text = text.replace(';', ',') \n",
    "            # We do this because one post in particular had this text and was giving me trouble.  The best way I could find to handle it was to remove the text.\n",
    "            text = text.replace('QR Code Link to This Post', '') \n",
    "\n",
    "        except:\n",
    "            error_list_text.append(soup)\n",
    "            text = 'text not found'\n",
    "            #body_text_list.append(text)\n",
    "            #print(\"Couldn't get text\")\n",
    "            \n",
    "        state = search_region[0]\n",
    "        state_list.append(state)\n",
    "        region_list.append(post_region)\n",
    "        link_list.append(link)\n",
    "        body_text_list.append(text)\n",
    "\n",
    "        # Use regular expressions to find all instances of prices in the text\n",
    "        #old_prices = re.findall('(?:[\\$]{1}[,\\d]+.?\\d*)', text)\n",
    "        old_prices = re.findall('(?:[\\$]{1}[,\\d]+\\d*)', text)\n",
    "        # Alternative, if trying to capture decimals \n",
    "        # ^(?:\\${1}\\d+(?:,\\d{3})*(?:\\.{1}\\d{2}){0,1})?$\n",
    "\n",
    "        # Intialize empty list to store the new prices after processing old prices.\n",
    "        new_prices = []\n",
    "        #print(F\"Initialized new_prices: {new_prices}\")\n",
    "        \n",
    "        #Walk through each price in the post.\n",
    "        for price in old_prices:\n",
    "            # Clean unwanted characters.\n",
    "            price = price.replace('$', '')\n",
    "            price = price.replace('/', '')\n",
    "            price = price.replace('!', '')\n",
    "            price = price.replace('h', '')\n",
    "            price = price.replace('.', '')\n",
    "            price = price.replace(')', '')\n",
    "            price = price.replace(',', '')\n",
    "            price = price.replace('>', '')\n",
    "            price = price.rstrip()   \n",
    "            # Some tutors give prices as a range ie '$30-40'.  In order to work with this data, I split based on the hyphen, then I can use each price individually.\n",
    "            split_prices = price.split('-')\n",
    "        #print(F\"Here are the old_prices: {old_prices}\")\n",
    "        #print(F\"Here are the split_prices: {split_prices}\")\n",
    "\n",
    "            # Walk through the split price, if a price had no hypen, the split_prices has one price in it that we perform processing on.  If a hyphen was present, then we have multiple prices that we iterate over and process\n",
    "            for p in split_prices:\n",
    "                # Only proceed if the post contained prices, ie if p is a non-empty string.\n",
    "                if len(p)!=0:\n",
    "                    try:\n",
    "                        # Convert string price to int.\n",
    "                        new_int = int(p)\n",
    "                        # Ignore prices which are too high to be reasonable.  Some posts included scholarship amounts as ways for a tutor to boast about their abilities, but this will only allow dollar amounts that are reasonable through.\n",
    "                        if new_int <= 200:\n",
    "                            new_prices.append(new_int)\n",
    "\n",
    "                    except:\n",
    "                        # Show which prices aren't able to convert to an int and the post they came from so we can isolate and fix the issue if need be.\n",
    "                        print(F'Error converting this price: {p}')\n",
    "                        print(split_prices)\n",
    "                        print()\n",
    "                        print('Here is the text of the post:')\n",
    "                        print()\n",
    "                        print(text)\n",
    "                        print('-'*50)\n",
    "                        print()\n",
    "                        # Set prices that can't be covered to NaN so the process can finish.\n",
    "                        new_prices.append(np.nan) \n",
    "        #print(F\"Here are the processed new_prices: {new_prices}\")\n",
    "                #print(len(new_prices))\n",
    "\n",
    "\n",
    "        # Append all prices from the post to a separate list, in case we need to isolate issues and fix them later.\n",
    "\n",
    "        search_region_price_list.append(new_prices)\n",
    "\n",
    "        # For posts that had no prices listed, we use null\n",
    "        if len(new_prices)==0:\n",
    "            price_list.append(np.nan)\n",
    "        # For posts that had a single price, we use it.\n",
    "        elif len(new_prices)==1:\n",
    "            price_list.append(new_prices[0])\n",
    "        # For posts that contained two prices, we average them.  This isn't a perfect system but is mainly targeted to posts that give a range of prices (ie $25-30).\n",
    "        elif len(new_prices)==2:\n",
    "            avg_price_2 = np.average(new_prices)\n",
    "            price_list.append(avg_price_2)\n",
    "        # If a post has more than 3 prices, we append null.  We'll have to inspect these posts manually and deal with them later.\n",
    "        else:\n",
    "            price_list.append(np.nan)\n",
    "        #print(price_list)\n",
    "\n",
    "\n",
    "        # Get city information for each posting.\n",
    "        try:\n",
    "            city = soup.find(class_='postingtitletext').small.get_text()\n",
    "\n",
    "            # Because of the way CL operates, one has to choose a city from a radio button list, that CL provides, when one creates a post to offer a service, however later, there's a field where they can type in any city they want.  Many people will randomly choose a city from the radio button list, but then  post their city as \"online\".  This makes sure we capture them. \n",
    "            re_pattern = re.compile('online')\n",
    "            online_flag = re.search(re_pattern, city.lower())\n",
    "            if online_flag:\n",
    "                city_list.append('Online')\n",
    "            else:\n",
    "                # Strip out leading and trailing white spaces, replace parentheses, and capitalize each word in the str.\n",
    "                city = city.strip()\n",
    "                city = city.replace('(', '').replace(')', '')        \n",
    "                city = city.title()\n",
    "                city_list.append(city)\n",
    "        except:\n",
    "            # If a post has no city information, use None\n",
    "            city_list.append('no city found')\n",
    "\n",
    "        # Extract subregion of Craigslist that the post was made in. This will allow for comparison of prices across different cities within the same metropolitan sub_region.\n",
    "        try:\n",
    "            subregion = soup.find_all('li', class_='crumb subarea')[0].find('a').get_text()\n",
    "            subregion = subregion.title()\n",
    "            subregion_list.append(subregion)\n",
    "        except:\n",
    "            subregion_list.append('no subregion found')\n",
    "\n",
    "\n",
    "        # Extract time the posting was made.\n",
    "        try:\n",
    "            dt_object = soup.find('time')['datetime']\n",
    "            datetime_list.append(dt_object)\n",
    "        except:\n",
    "            datetime_list.append('time of post unavailable')\n",
    "    # else:\n",
    "    #     pass\n",
    "    #print(price_list)\n",
    "    # Create temporary df to store results for each region\n",
    "    temp_df = pd.DataFrame(data=zip(datetime_list,\n",
    "                                    link_list, \n",
    "                                    price_list, \n",
    "                                    city_list, \n",
    "                                    subregion_list, \n",
    "                                    region_list,\n",
    "                                    state_list,\n",
    "                                    body_text_list,\n",
    "                                    search_region_price_list),\n",
    "                        columns=['date_posted', \n",
    "                                 'link', \n",
    "                                 'price', \n",
    "                                 'city', \n",
    "                                 'subregion', \n",
    "                                 'region',\n",
    "                                 'state',\n",
    "                                 'post_text',\n",
    "                                 'price_list']\n",
    "                          )\n",
    "    df_list.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for errors in getting text from a post, or from getting the URL of a post.\n",
    "len(error_list_text), len(error_list_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dfs for each region into one larger df and check its shape.\n",
    "concat_df = pd.concat(df_list, ignore_index=True)\n",
    "concat_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fb5866-a4e4-452f-821d-274763fd9a45",
   "metadata": {},
   "source": [
    "### Dropping Duplicate posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get date of html request to label our output with.\n",
    "date_of_html_request = str(dt.date.today())\n",
    "\n",
    "# Include the date posts were scraped on to track tutoring prices over time.\n",
    "concat_df['posts_scraped_on'] = date_of_html_request\n",
    "\n",
    "# Count duplicates.\n",
    "concat_df['post_text'].duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52774d13-f298-4586-be24-e5f33cf0e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices of rows that have exactly the same post_text, then drop them and reset indices.\n",
    "duplicate_indices = concat_df[concat_df['post_text'].duplicated()==True].index\n",
    "df_exact_txt_dropped = concat_df.drop(index=duplicate_indices)\n",
    "df_exact_txt_dropped = df_exact_txt_dropped.reset_index(drop=True)\n",
    "df_exact_txt_dropped['len_of_price_list']=df_exact_txt_dropped['price_list'].apply(lambda x: len(x))\n",
    "df_exact_txt_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30cd031-8c4b-4907-86b5-77467325ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize each posts' text and calculate the cosine similarity of each post against all other posts to determine which are duplicates\n",
    "## https://kanoki.org/2018/12/27/text-matching-cosine-similarity/\n",
    "text_for_comparison = df_exact_txt_dropped['post_text']\n",
    "vect = TfidfVectorizer(min_df=1, stop_words='english')\n",
    "tfidf = vect.fit_transform(text_for_comparison)\n",
    "pairwise_similarity = tfidf * tfidf.T\n",
    "\n",
    "# Store results in a 2D NumPy array\n",
    "pairwise_array = pairwise_similarity.toarray()\n",
    "\n",
    "# The diagonal of our array is the similarity of a post to itself, which we fill will null so that these are essentially ignored\n",
    "np.fill_diagonal(pairwise_array, np.nan)\n",
    "\n",
    "# Many people on CL will change their posting in ways to avoid CL flagging them as duplicates for removal.  This finds all posts above a certain similarity threshold.\n",
    "argwhere_array = np.argwhere(pairwise_array > 0.63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6737df-7701-4f01-a968-898e60b48476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In order to remove the duplicates, we need to restructure our 2D NumPy array in such a way that the first column is the index of the post that has a duplicate and the second column contains a list of the indices of the duplicate post(s).\n",
    "df_row_idx = []\n",
    "dup_row_idx = []\n",
    "for row in argwhere_array:\n",
    "    current_idx = row[0]\n",
    "    #print(F\"Current row: {row}, Current idx: {current_idx}\")\n",
    "    duplicate_list = []\n",
    "    if current_idx in df_row_idx:\n",
    "        continue\n",
    "    else:\n",
    "        df_row_idx.append(current_idx)\n",
    "    for other_row in argwhere_array:\n",
    "        other_idx = other_row[1]\n",
    "        #print(F\"Here's the other_row: {other_row}, Other idx: {other_idx}\")\n",
    "        if current_idx == other_row[0]:\n",
    "            duplicate_list.append(other_idx)\n",
    "    #print(F\"This is the current dup_list: {duplicate_list}\")\n",
    "    #print()\n",
    "    dup_row_idx.append(duplicate_list)\n",
    "#list(zip(df_row_idx, dup_row_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48949840-611f-496c-b1a3-adf81253b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create match column in our df, which is initialized as a list of all indices in our df.  This means for each row, the value of the match column is the row index.  Convert that index value to a list, so we can iterate over it in future steps\n",
    "df_exact_txt_dropped['match'] = np.array(df_exact_txt_dropped.index.values, dtype='object')\n",
    "df_exact_txt_dropped['match'] = df_exact_txt_dropped['match'].apply(lambda x: [x])\n",
    "\n",
    "# For rows that are duplicate postings, we overwrite the value of match column to contain the indices of all other rows that contain duplicated text\n",
    "match_col_idx = df_exact_txt_dropped.columns.get_loc('match')\n",
    "df_exact_txt_dropped.iloc[df_row_idx, match_col_idx] = dup_row_idx\n",
    "#df_exact_txt_dropped['match'] = df_exact_txt_dropped['match'].apply(lambda x: [x])\n",
    "\n",
    "df_exact_txt_dropped['match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae76bd3-20ac-443b-b254-ad184673580b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "\n",
    "df_no_dups = df_exact_txt_dropped.copy()\n",
    "\n",
    "# Iterate over each row and remove all rows that have duplicated text\n",
    "for i, row in df_no_dups.iterrows():\n",
    "    indices.append(i)\n",
    "    drop_idx = []\n",
    "    #print(i, row['match'])\n",
    "    try:\n",
    "        for item in row['match']:\n",
    "            if item not in indices:\n",
    "                drop_idx.append(item)\n",
    "        df_no_dups = df_no_dups.drop(index=drop_idx, errors=\"ignore\")\n",
    "    except Exception as e:\n",
    "        #print(i, item, row['match'])\n",
    "        print(e, i, item, row['match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24427708-b9e4-4b53-b0f2-0f2ec6962382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape when we dropped posts with exactly the same post_text against the shape after we dropped text deemed similar by cosine similarity \n",
    "df_exact_txt_dropped.shape, df_no_dups.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625aecfe-7df2-4674-ab98-60f96efa8e1b",
   "metadata": {},
   "source": [
    "### Dropping posts that contained no prices, which aren't helpful for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e8abf-7b66-4232-9059-93272966788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the len of price_list to find posts that contained no prices\n",
    "df_no_dups['len_of_price_list'] = df_no_dups['price_list'].apply(lambda x: len(x))\n",
    "\n",
    "# Filter out results that don't have a price and reset indices.\n",
    "df_with_prices = df_no_dups[df_no_dups['len_of_price_list'] > 0]\n",
    "df_with_prices = df_with_prices.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273eca8b-0205-4458-9536-0cebd167096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_posts_count = len(df_no_dups)\n",
    "post_with_prices_count = len(df_with_prices)\n",
    "num_posts = len(concat_df)\n",
    "\n",
    "percent_unique = unique_posts_count / num_posts * 100\n",
    "percent_with_prices = post_with_prices_count / num_posts * 100\n",
    "\n",
    "print(F\"Out of {num_posts} posts, there were {unique_posts_count} that were unique, or {percent_unique:.2f}%.\")\n",
    "print(F\"Out of those, there were {post_with_prices_count} posts that had prices included.\")\n",
    "\n",
    "print(F\"Only {percent_with_prices:.2f}% of the posts that we scraped remain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1e238-96b4-4372-85b7-ed1e1f72c711",
   "metadata": {},
   "source": [
    "### Extracting complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd44d13c-b579-42de-90bd-c9607b52b58e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# *Transforming* Craigslist data: Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a50fc12-b7cf-4294-8336-625a662c2109",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Are there any posts that might need manual cleaning?  This would include:\n",
    "* Posts that had 3 or more prices and were marked as null\n",
    "* Posts where the price wasn't able to convert from `str` -> `int` and were marked as null during pre-processing\n",
    "\n",
    "There are the entries that were marked as `Null`.  Let's investigate them manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118dd4a-b106-4d3c-830b-42db498f7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_prices = df_with_prices[df_with_prices['price'].isnull()==True]\n",
    "df_null_prices[['price', 'price_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfb0dec-46fb-4693-b660-10214d8f6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_with_mult_prices = df_null_prices.shape[0]\n",
    "print(F\"There were {posts_with_mult_prices} posts with price marked null.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6106d30-41ee-47f0-9695-22b95ad7e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store posts with null prices to CSV to manually inspect later\n",
    "df_null_prices = df_null_prices.drop(columns=['len_of_price_list', 'match'])\n",
    "df_null_prices.to_csv('./posts_to_investigate/{}_posts_with_null_prices.csv'.format(date_of_html_request), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b77ec-483e-4b34-803b-3032be8e5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect links manually, one by one, to decide what to do about price information\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "  x=3\n",
    "  #display(df_with_prices.iloc[x]['post_text'])\n",
    "  display(df_with_prices.iloc[x]['link'])\n",
    "  display(df_with_prices.iloc[x]['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b77b7-bd3e-4660-8454-eb6feeee2de3",
   "metadata": {},
   "source": [
    "### Cleaning posts with three or more prices manually - distilling down to one price\n",
    "\n",
    "We distill posts that had more complicated text that involved three or more prices, such as :\n",
    "\n",
    "* $40$/hr, $50$/1.5hr, $60$/2hr\n",
    "  * Complicated pricing schedule\n",
    "* $40$/hr but $10$ additional per person, if a group session is desired\n",
    "  * Group rates\n",
    "* $30$/hr Science, $40$/hr math, come and try a first session for the reduced price of $20$.\n",
    "  * Special offers\n",
    "\n",
    "into a single price.  Other posts repeated their prices multiple times, so we distill those down to a single price as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_col_idx = df_with_prices.columns.get_loc('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5484075c-56c5-4c45-a037-4a0d7320078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says $40 for in person, or $45 for at home, so I took the average.\n",
    "san_mateo_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('I mainly tutor, in person, at the Downtown Redwood City, downtown San Mateo')].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[san_mateo_tutor_idx,price_col_idx] = 42.5\n",
    "\n",
    "except:\n",
    "    print(\"Issue with san_mateo_tutor and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the ad says $90 in person, $60 for online, and Corona Virus pricing of\n",
    "# $40 for online weekdays, I'm using the $40 per hour rate because it seems the\n",
    "# most reasonable and is most similar to what I'm competing against.\n",
    "kenari_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('kenaritutor.com')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[kenari_tutor_idx,price_col_idx] = 40\n",
    "except:\n",
    "    print('Issue with kenari_tutor_idx and iloc.')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511ec79c-4a71-4cbf-9efd-466b286386b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad mentions several prices for different subjects, but explicitly says $30 for math.\n",
    "la_honda_idx = df_with_prices[df_with_prices['post_text'].str.contains('909-640-3570')].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[la_honda_idx,price_col_idx] = 30\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with la_honda_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca5d7e-f730-4fc3-841a-c70205c847a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says #60 per hour.\n",
    "glasses_lady_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"offering virtual one-on-one Math tutoring via Zoom\")==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[glasses_lady_idx, price_col_idx] = 60\n",
    "except:\n",
    "    print(\"Issue with glasses_lady_idx and iloc.\")\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1402316-6126-4b99-ab97-5ed93f0238bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says #60 per hour.\n",
    "UC_Davis_data_scientist = df_with_prices[df_with_prices['post_text'].str.contains(\"PhD in Engineering from UC Davis\")==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[UC_Davis_data_scientist, price_col_idx] = 60\n",
    "except:\n",
    "    print(\"Issue with UC_Davis_data_scientist and iloc.\")\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286df5e3-4fcb-481e-b8b1-238ecc789fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This guy has weird price structuring, but I used his hourly rate for each time interval, $100 for 80 minutes, $115 for 100 minutes, $130 for 120 minutes, then averaged those hourly rates to estimate what a single hour would cost.\n",
    "oakland_exp_tutor_online_idx = df_with_prices[df_with_prices['post_text'].str.contains('I received a full scholarship to University of Cincinnati and held a 3.8 GPA through my masters program in aerospace')==True].index\n",
    "\n",
    "oakland_tutor_avg_rate = ((100/80) + (115/100) + (130/120)) * 60 / 3\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[oakland_exp_tutor_online_idx, price_col_idx] = oakland_tutor_avg_rate\n",
    "\n",
    "except:\n",
    "    print(\"Issue with oakland_exp_tutor_online_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ad repeats the price of $40 over and over, so I'm replacing the price with \n",
    "# a single instance.\n",
    "star_star_college_math_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('https://www.youtube.com/channel/UCqhFZRmUqOAAPMQpo58TV7g'\n",
    "                   ) == True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[star_star_college_math_tutor_idx, price_col_idx] = 40\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with star_star_college_math_tutor_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bacbee-fda4-40d8-b864-f086777b76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says $50/hr    \n",
    "trevor_skelly_idx = df_with_prices[df_with_prices['post_text'].str.contains('trevorskelly')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[trevor_skelly_idx,price_col_idx] = 50\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with trevor_skelly_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charges $50 per hour for sessions under 3 hours\n",
    "spss_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('datameer', case=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[spss_tutor_idx, price_col_idx] = 50\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with spss_tutor_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8a00e-df48-4e40-9b18-886f989c6488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charges $50 per hour\n",
    "tutor_sam_idx = df_with_prices[df_with_prices['post_text'].str.contains('thetutorsam')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[tutor_sam_idx, price_col_idx] = 50\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with tutor_sam_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charges $40 per hour\n",
    "peter_d_idx = df_with_prices[df_with_prices['post_text'].str.contains('Peter D.')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[peter_d_idx, price_col_idx] = 40\n",
    "except:\n",
    "    print(\"Issue with peter_d_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289270da-cd1d-4aac-b1cb-a4070238e259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charges $45 per hour for individual lessons\n",
    "algebra_exclusively_idx = df_with_prices[df_with_prices['post_text'].str.contains('algebra EXCLUSIVELY')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[algebra_exclusively_idx, price_col_idx] = 45\n",
    "except:\n",
    "    print(\"Issue with algebra_exclusively_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post includes many prices, but states $55/hr for Precalc and $80/hr for Calculus, which are primarily what I help with, so I took the average of those prices\n",
    "aerospace_engineer_idx = df_with_prices[df_with_prices['post_text'].str.contains('in the aerospace industry looking', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[aerospace_engineer_idx, price_col_idx] = (55 + 80)/2\n",
    "\n",
    "except:\n",
    "    print(\"Issue with aerospace_engineer_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad mentions $45 for lower division college courses, which are a large segment of the subjects I help with, so I'm using that price to compare myself against.\n",
    "ucb_phd_student_and_ta_idx = df_with_prices[df_with_prices['post_text'].str.contains('Former UC-Berkeley economics Ph.D. student and TA')].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[ucb_phd_student_and_ta_idx, price_col_idx] = 45\n",
    "\n",
    "except:\n",
    "    print(\"Issue with ucb_phd_student_and_ta_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The add says $55/hr for K-12, then $65/hr for AP/Honors, as well as Pre-calc, \n",
    "# etc., I'm going to average the two prices.\n",
    "park_academy_idx = df_with_prices[df_with_prices['post_text'].str.contains('(949) 490-0872', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[park_academy_idx, price_col_idx] = 60\n",
    "\n",
    "except:\n",
    "    print(\"Issue with park_academy_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says $25/hr for high school, $30/hr for college, just went with $30/hr\n",
    "sharp_mind_idx = df_with_prices[df_with_prices['post_text'].str.contains('(650) 398-9490', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[sharp_mind_idx, price_col_idx] = 30\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with sharp_mind_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4988ca4-9ad0-4703-a94a-ed4065e4523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says $50/hr if travelling, $30-35/hr if virtual, so I took the average of 50 and 35\n",
    "stock_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('714.425.3828', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[stock_tutor_idx, price_col_idx] = (35 + 50)/2\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with stock_tutor_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post says $30/hr for Precalc/Trig and $50/hr for Calculus, so I took the average\n",
    "lonzo_tutoring_idx = df_with_prices[df_with_prices['post_text'].str.contains('951-795-5027', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[lonzo_tutoring_idx, price_col_idx] = 40\n",
    "\n",
    "except:\n",
    "    print(\"Issue with lonzo_tutoring_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad says $30 for one hour.\n",
    "poway_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('(619)735-2579', regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[poway_tutor_idx, price_col_idx] = 30\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with poway_tutor_idx and iloc.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $20/hr online, $30/hr in person, split the difference at $25\n",
    "austin_sabrina_idx = df_with_prices[df_with_prices['post_text'].str.contains('My girlfriend Sabrina')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[austin_sabrina_idx, price_col_idx] = 25\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with austin_sabrina_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Says $25/hr\n",
    "alex_farrell_idx = df_with_prices[df_with_prices['post_text'].str.contains('Alexander Farrell')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[alex_farrell_idx, price_col_idx] = 25\n",
    "\n",
    "except:\n",
    "    print(\"Issue with alex_farrell_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b76bc0-85a3-495c-b385-4972b767534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $25/hr if meeting near CSU Sac, $35/hr if they drive to you, $20/hr for online.\n",
    "# I chose $30/hr to split the difference between the in person prices.\n",
    "best_math_idx = df_with_prices[df_with_prices['post_text'].str.contains('bestmathtutoring.com')==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[best_math_idx, price_col_idx] = 30\n",
    "    \n",
    "except:\n",
    "    print(\"Issue with best_math_idx and iloc.\")\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucla_grad_henry_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"916 390-7923\", regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[ucla_grad_henry_idx, price_col_idx] = 35\n",
    "\n",
    "except:\n",
    "    print(\"Issue with ucla_grad_henry_idx and iloc.\")\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5f5de-7684-4c1f-9e92-029f6fffea5d",
   "metadata": {},
   "source": [
    "#### Checking results - Are there any posts that were marked as needing to be cleaned that we missed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_still_null = len(df_with_prices[df_with_prices['price'].isnull()==True])\n",
    "\n",
    "if num_still_null==0:\n",
    "    print(\"There are no posts with null prices still needing cleaning.\")\n",
    "else:\n",
    "    print(F\"There are {num_still_null} posts that need cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9f4d2c-57da-4d35-a331-ff18f8b790d3",
   "metadata": {},
   "source": [
    "### Checking Posts that have two prices listed to see if averaging them is reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4dd25-cd1a-4e13-bc8c-4526d76f150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_prices[df_with_prices['len_of_price_list']==2][['price','price_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8e2d5d-7df4-43e0-b914-9be1a1967153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect posts manually, one by one\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "  x=136\n",
    "  #display(df_with_prices.iloc[x]['post_text'])\n",
    "  display(df_with_prices.iloc[x]['link'])\n",
    "  display(df_with_prices.iloc[x]['post_text'])\n",
    "  display(df_with_prices.iloc[x]['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22beb0e4-8b3b-49fb-894c-82f3e9c598b9",
   "metadata": {},
   "source": [
    "#### Ads where averaging doesn't make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc06f34c-357f-4508-88ff-7cf515eef0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says 35$/half hour, but explicitly says $57 per hour, so averaging doesn't make sense.  \n",
    "blake_tutoring_idx = df_with_prices[df_with_prices['post_text'].str.contains('BlakeTutoring.com', case=False)==True].index\n",
    "\n",
    "df_with_prices.iloc[blake_tutoring_idx, price_col_idx] = 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad says $84/hr but then mentions a $125 for 1.5 hours.  Since these are the only two prices in the post, our code averages them, so we set the correct price to $84\n",
    "test_trainer_inc_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"TestTrainerinc\", regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[test_trainer_inc_idx, price_col_idx] = 84\n",
    "\n",
    "except:\n",
    "    print(\"Issue with test_trainer_inc_idx and iloc.\")\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8ea92-15a6-43b2-b913-a86880a2f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $60/45mins, but $80 per hour.  Either price comes out to the same hourly rate, so averaging doesn't make sense.\n",
    "hiro_kobayashi_idx = df_with_prices[df_with_prices['post_text'].str.contains('415-250-4831', case=False)==True].index\n",
    "\n",
    "df_with_prices.iloc[hiro_kobayashi_idx, price_col_idx] = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb557fbe-9c04-4f3b-a253-44be8dbcceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $40/1hr, $70/2hr, so averaging doesn't make sense\n",
    "guy_with_suit_idx = df_with_prices[df_with_prices['post_text'].str.contains('trained mathematician with about 20 years experience')==True].index\n",
    "\n",
    "df_with_prices.iloc[guy_with_suit_idx, price_col_idx] = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a848a8-b063-4cce-9aef-4fd838551210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $25/1hr, $40/2hr, so averaging doesn't make sense\n",
    "christian_cerritos_college_idx = df_with_prices[df_with_prices['post_text'].str.contains('trained mathematician with about 20 years experience')==True].index\n",
    "\n",
    "df_with_prices.iloc[christian_cerritos_college_idx, price_col_idx] = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6fe95-7589-4650-b38f-ca229bdb16e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $30/half hr, $50/1hr, so averaging doesn't make sense\n",
    "dustin_csu_long_beach_idx = df_with_prices[df_with_prices['post_text'].str.contains('International Society of Automation')==True].index\n",
    "\n",
    "df_with_prices.iloc[dustin_csu_long_beach_idx, price_col_idx] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7298c75-8a00-4705-90a4-0b3e7ae5a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $65/hr for subject tutoring, $100/hr for standardized tests.  I'm primarily competing against subject tutoring, so I'll use that price\n",
    "smarter_than_you_think_idx = df_with_prices[df_with_prices['post_text'].str.contains('guarantee you are smarter than you think')==True].index\n",
    "\n",
    "df_with_prices.iloc[smarter_than_you_think_idx, price_col_idx] = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01101fb3-221a-482e-9e36-0280d415e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $50/hr or $160/4hr, so it doesn't make sense to average.\n",
    "dead_in_ditch_idx = df_with_prices[df_with_prices['post_text'].str.contains('dead in a ditch')==True].index\n",
    "\n",
    "df_with_prices.iloc[dead_in_ditch_idx, price_col_idx] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124abde4-be0f-4d62-b675-417fa672cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $45/hr +$10 more per student, so it doesn't make sense to average.\n",
    "distinguished_teacher_idx = df_with_prices[df_with_prices['post_text'].str.contains('\"Distinguished Teacher\"')==True].index\n",
    "\n",
    "df_with_prices.iloc[distinguished_teacher_idx, price_col_idx] = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a8716-a2ef-4661-b162-d3e959f92b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $40/hr +$10 more for each additional person, so it doesn't make sense to average.\n",
    "vahab_idx = df_with_prices[df_with_prices['post_text'].str.contains('vababtaghizade@gmail.com')==True].index\n",
    "\n",
    "df_with_prices.iloc[vahab_idx, price_col_idx] = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25252b56-959e-46de-9b52-95834da63513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $30/hr for trial session, then $60/hr afterwards, so it doesn't make sense to average.\n",
    "myles_ahead_idx = df_with_prices[df_with_prices['post_text'].str.contains('mylesaheadtutoring')==True].index\n",
    "\n",
    "df_with_prices.iloc[myles_ahead_idx, price_col_idx] = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa0f22-d46b-4295-b318-94fb14053bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This guy's ad says $45/hr, then talks about selling a workbook for $30, so it doesn't make sense to average.\n",
    "john_the_tutor_idx = df_with_prices[df_with_prices['post_text'].str.contains('480-343-2212')==True].index\n",
    "\n",
    "df_with_prices.iloc[john_the_tutor_idx, price_col_idx] = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab450bff-f1f1-40c4-9601-bd4dbbbfe6fd",
   "metadata": {},
   "source": [
    "Conclusion: Averaging doesn't make sense for a good chunk of these posts, but averaging is helpful for others.  I need to come up with a better process here, but will leave that for later..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372c281c-e1e6-4167-8512-54a8a13bfb04",
   "metadata": {},
   "source": [
    "## Investigating posts with extreme prices.  Are there any price outliers that we need to clean?\n",
    "\n",
    "Prices >= 100 or <= 20 are what I would consider to be extreme prices.  Let's investigate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58751ba1-6c7d-40b7-b22f-62db9a52a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_prices[(df_with_prices['price']>=100) | (df_with_prices['price']<=20)][['price', 'post_text', 'price_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4892b0-a385-4119-9897-659036333b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually inspect these posts one by one\n",
    "with pd.option_context('display.max_colwidth', None):\n",
    "  x=40\n",
    "  #display(df_with_prices.iloc[x]['post_text'])\n",
    "  display(df_with_prices.iloc[x]['link'])\n",
    "  display(df_with_prices.iloc[x]['post_text'])\n",
    "  display(df_with_prices.iloc[x]['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc9c8c4-053c-4065-84c4-b5e2c7f221cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dropping posts with extreme prices that aren't relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad is for poker tutoring/coaching, not really what I'm competing against, so we drop it.  He also mentions he tutors math in this post, but he has a separate post, that we've captured, which has his math tutoring pricing information.\n",
    "australia_daniel_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"I'm available as a dealer if you need one\", regex=False)==True].index\n",
    "\n",
    "df_with_prices.drop(labels=australia_daniel_idx, inplace=True)\n",
    "df_with_prices = df_with_prices.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb89cbc-1b96-4110-a724-a4a375e2da25",
   "metadata": {},
   "source": [
    "### Correcting pricing information for posts with extreme prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad says $50/hr but then mentions a prepay plan for $160 for 4 hours.  Since these are the only two prices in the post, our code averages them, so we set the correct price to $50\n",
    "google_maps_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"willing to travel if Google Maps\", regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[google_maps_idx, price_col_idx] = 50\n",
    "\n",
    "except:\n",
    "    print(\"Issue with google_maps_idx and iloc.\")\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ad says $45/hr for high school or college, but then mentions a $35 for middle school.  Since these are the only two prices in the post, our code averages them, so we set the correct price to $45, since I primarily tutor high school or college students.\n",
    "rancho_penasquitos_idx = df_with_prices[df_with_prices['post_text'].str.contains(\"Rancho Penasquitos (Park Village Neighborhood)\", regex=False)==True].index\n",
    "\n",
    "try:\n",
    "    df_with_prices.iloc[rancho_penasquitos_idx, price_col_idx] = 45\n",
    "\n",
    "except:\n",
    "    print(\"Issue with rancho_penasquitos_idx and iloc.\")\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5845cf-2131-4c99-a7a9-5ea9f2b06025",
   "metadata": {},
   "source": [
    "### Transforming Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86885d2-afe0-413b-8bb1-dd77270c438b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# *Load* - Saving results\n",
    "\n",
    "### Store results locally as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ec8df9-162d-488e-9398-802af285f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns.\n",
    "df_for_sql = df_with_prices.drop(labels=['link', 'price_list', 'len_of_price_list', 'match'], axis=1)\n",
    "\n",
    "# In order for psycopg2 to parse our CSV file correctly later, we need to escape all new line characters by adding an additional \\ in front of \\n.\n",
    "df_for_sql['post_text'] = df_for_sql['post_text'].str.replace('\\n', '\\\\n')\n",
    "\n",
    "# Store cleaned data as CSV file in preparation for importing to SQL database\n",
    "df_for_sql.to_csv(\"./csv_files/{}_all_regions_with_prices.csv\".format(date_of_html_request), index=False, sep=';')\n",
    "\n",
    "# Store original data, before we applied any cleaning to it, in case it's needed for something later on.\n",
    "concat_df.to_csv(\"./csv_files/{}_all_regions_posts.csv\".format(date_of_html_request), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8345366-1da1-4faf-b682-7639d0e83a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_dups.to_csv('./csv_files/{}_all_regions_no_dups.csv'.format(date_of_html_request), index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3316f-3491-4d57-8cf0-69a03c3f2bab",
   "metadata": {},
   "source": [
    "### Importing into PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c8850-c39b-438e-943b-f87626e2ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection to PSQL database\n",
    "conn = psycopg2.connect(\"host=localhost dbname=rancher user=rancher\")\n",
    "\n",
    "# Instantiate a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Use cursor object to create a database for storing the information we scraped and cleaned, if one doesn't already exist.\n",
    "cur.execute(\"\"\"    \n",
    "    CREATE TABLE IF NOT EXISTS cl_tutoring(\n",
    "    id SERIAL primary key,\n",
    "    date_scraped date,\n",
    "    price decimal,\n",
    "    city text,\n",
    "    subregion text,\n",
    "    region text,\n",
    "    state text,\n",
    "    post_text text,\n",
    "    date_posted timestamp\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Commit changes to database\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8dd7c-60f9-40d4-baa6-5fed6e38094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a new cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Copy data from our CSV file into database.  \n",
    "### Note, we can use the ; separator freely because we replaced all instances of semicolons in post_text to commas during the preprocessing stage, ensuring that psycopg2 won't misinterpret a semicolon in the body of a post as a separator.\n",
    "### Also, we must specify null=\"\" because Python represents null values as an empty string when writing to a CSV file and psycopg2 needs to know how null values are represented in the CSV file in order to properly insert null values into the database\n",
    "with open('./csv_files/' + str(date_of_html_request) + '_all_regions_with_prices.csv', 'r') as file:\n",
    "    next(file) # Skip the header row\n",
    "    cur.copy_from(file, 'cl_tutoring', sep=';', null=\"\", columns=('date_posted', 'price', 'city', 'subregion', 'region', 'state', 'post_text', 'date_scraped'))\n",
    "    \n",
    "# Commit changes to database\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f1d2b-9697-48ff-8337-7f73bcfe3b36",
   "metadata": {},
   "source": [
    "### Done!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4544953-347c-47fa-aae0-dd6bab89f814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
